{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd91f78b",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html lectures.do.txt --no_mako -->\n",
    "$\\mathbf{A}\\mathbf{x}=\\lambda\\mathbf{x}$ \n",
    "   $\\mathbf{A}=\\mathbf{A}^*$  Conjugate gradient and  Lanczos\n",
    "  $\\mathbf{A}\\ne \\mathbf{A}^*$  GMRES etc           Arnoldi \n",
    "\n",
    "The Numerical Recipes codes have been rewritten in Fortran 90/95 and C/C++ by us.\n",
    "The original source codes are taken from the widely used software\n",
    "package LAPACK, which follows two other popular packages developed in the 1970s, \n",
    "namely EISPACK and LINPACK.\n",
    " * LINPACK: package for linear equations  and least square problems.\n",
    "\n",
    " * LAPACK:package for solving symmetric, unsymmetric and generalized eigenvalue problems. From LAPACK's website <http://www.netlib.org>  it is  possible to download for free all source codes from this library. Both C/C++ and Fortran versions are available.\n",
    "\n",
    " * BLAS (I, II and III): (Basic Linear Algebra Subprograms)  are routines that provide standard building blocks for performing basic vector and matrix operations.   Blas I is vector operations, II vector-matrix operations and III matrix-matrix operations. \n",
    "\n",
    "Consider an  example of an ($n\\times n$) orthogonal transformation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd44f7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S}=\n",
    " \\left( \n",
    "   \\begin{array}{cccccccc}\n",
    "   1  &    0  & \\dots &   0        &    0  & \\dots & 0 &   0       \\\\\n",
    "   0  &    1  & \\dots &   0        &    0  & \\dots & 0 &   0       \\\\\n",
    "\\dots & \\dots & \\dots & \\dots      & \\dots & \\dots & 0 & \\dots     \\\\ \n",
    "   0  &    0  & \\dots & \\cos\\theta  &    0  & \\dots & 0 & \\sin\\theta \\\\\n",
    "   0  &    0  & \\dots &   0        &    1  & \\dots & 0 &   0       \\\\\n",
    "\\dots & \\dots & \\dots & \\dots      & \\dots & \\dots & 1 & \\dots     \\\\\n",
    "   0  &    0  & \\dots &  -\\sin\\theta        &    0  & \\dots & 0 &   \\cos\\theta   \n",
    "   \\end{array}\n",
    " \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd7f2a",
   "metadata": {
    "editable": true
   },
   "source": [
    "with property $\\mathbf{S^{T}} = \\mathbf{S^{-1}}$.\n",
    "It performs a plane rotation around an angle $\\theta$ in the Euclidean \n",
    "$n-$dimensional space. \n",
    "\n",
    "It means that its matrix elements that differ\n",
    "from zero are given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42353dea",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "s_{kk}= s_{ll}=\\cos\\theta, \n",
    "    s_{kl}=-s_{lk}= -\\sin\\theta, \n",
    "    s_{ii}=1\\hspace{0.5cm} i\\ne k \\hspace{0.5cm} i \\ne l,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253bd5d",
   "metadata": {
    "editable": true
   },
   "source": [
    "A similarity transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcdfba3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{B}= \\mathbf{S}^T \\mathbf{A}\\mathbf{S},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd8e969",
   "metadata": {
    "editable": true
   },
   "source": [
    "results in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49544fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "b_{ik} =& a_{ik}\\cos\\theta - a_{il}\\sin\\theta , i \\ne k, i \\ne l \\\\\n",
    "b_{il} =& a_{il}\\cos\\theta + a_{ik}\\sin\\theta , i \\ne k, i \\ne l \\nonumber\\\\\n",
    "b_{kk} =& a_{kk}\\cos^2\\theta - 2a_{kl}\\cos\\theta \\sin\\theta +a_{ll}\\sin^2\\theta\\nonumber\\\\\n",
    "b_{ll} =& a_{ll}\\cos^2\\theta +2a_{kl}\\cos\\theta sin\\theta +a_{kk}\\sin^2\\theta\\nonumber\\\\\n",
    "b_{kl} =& (a_{kk}-a_{ll})\\cos\\theta \\sin\\theta +a_{kl}(\\cos^2\\theta-\\sin^2\\theta)\\nonumber \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d1b8fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "The angle $\\theta$ is  arbitrary. The recipe is to choose  $\\theta$ so that all\n",
    "non-diagonal matrix elements $b_{kl}$ become zero.  \n",
    "\n",
    "The main idea is thus to reduce systematically the \n",
    "norm of the \n",
    "off-diagonal matrix elements  of a matrix  $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881873ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathrm{off}(\\mathbf{A}) = \\sqrt{\\sum_{i=1}^n\\sum_{j=1,j\\ne i}^n a_{ij}^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85001e8",
   "metadata": {
    "editable": true
   },
   "source": [
    "To demonstrate the algorithm, we consider the  simple $2\\times 2$  similarity transformation\n",
    "of the full matrix. The matrix is symmetric, we single out $ 1 \\le k < l \\le n$  and \n",
    "use the abbreviations $c=\\cos\\theta$ and $s=\\sin\\theta$ to obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07436dfb",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left( \\begin{array}{cc} b_{kk} & 0 \\\\\n",
    "                          0 & b_{ll} \\\\\\end{array} \\right)  =  \\left( \\begin{array}{cc} c & -s \\\\\n",
    "                          s &c \\\\\\end{array} \\right)  \\left( \\begin{array}{cc} a_{kk} & a_{kl} \\\\\n",
    "                          a_{lk} &a_{ll} \\\\\\end{array} \\right) \\left( \\begin{array}{cc} c & s \\\\\n",
    "                          -s & c \\\\\\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e4b6b7",
   "metadata": {
    "editable": true
   },
   "source": [
    "We require that the non-diagonal matrix elements $b_{kl}=b_{lk}=0$, implying that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eedfcf4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "a_{kl}(c^2-s^2)+(a_{kk}-a_{ll})cs = b_{kl} = 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc2a89",
   "metadata": {
    "editable": true
   },
   "source": [
    "If $a_{kl}=0$ one sees immediately that $\\cos\\theta = 1$ and $\\sin\\theta=0$.\n",
    "\n",
    "The Frobenius norm of an orthogonal transformation is always preserved. The Frobenius norm is defined\n",
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5b39e6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathrm{norm}(\\mathbf{A})_F =  \\sqrt{\\sum_{i=1}^n\\sum_{j=1}^n |a_{ij}|^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a42cc7",
   "metadata": {
    "editable": true
   },
   "source": [
    "This means that for our $2\\times 2$ case  we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0b2420",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "2a_{kl}^2+a_{kk}^2+a_{ll}^2 = b_{kk}^2+b_{ll}^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5317d7",
   "metadata": {
    "editable": true
   },
   "source": [
    "which leads to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125eed2a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathrm{off}(\\mathbf{B})^2 = \\mathrm{norm}(\\mathbf{B})_F^2-\\sum_{i=1}^nb_{ii}^2=\\mathrm{off}(\\mathbf{A})^2-2a_{kl}^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0547dc1",
   "metadata": {
    "editable": true
   },
   "source": [
    "since"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7de349",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathrm{norm}(\\mathbf{B})_F^2-\\sum_{i=1}^nb_{ii}^2=\\mathrm{norm}(\\mathbf{A})_F^2-\\sum_{i=1}^na_{ii}^2+(a_{kk}^2+a_{ll}^2 -b_{kk}^2-b_{ll}^2).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58204bc9",
   "metadata": {
    "editable": true
   },
   "source": [
    "This results means that  the matrix $\\mathbf{A}$ moves closer to diagonal form  for each transformation.\n",
    "\n",
    "Defining the quantities $\\tan\\theta = t= s/c$ and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc79b3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\cot 2\\theta=\\tau = \\frac{a_{ll}-a_{kk}}{2a_{kl}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a96e080",
   "metadata": {
    "editable": true
   },
   "source": [
    "we obtain the quadratic equation (using $\\cot 2\\theta=1/2(\\cot \\theta-\\tan\\theta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed745ed2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "t^2+2\\tau t-1= 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d1f3d",
   "metadata": {
    "editable": true
   },
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049251a0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "t = -\\tau \\pm \\sqrt{1+\\tau^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbc915",
   "metadata": {
    "editable": true
   },
   "source": [
    "and $c$ and $s$ are easily obtained via"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a987d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "c = \\frac{1}{\\sqrt{1+t^2}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50718f",
   "metadata": {
    "editable": true
   },
   "source": [
    "and $s=tc$.  Convince yourself that we have $|\\theta| \\le \\pi/4$. This has the effect  \n",
    "of minimizing the difference between the matrices $\\mathbf{B}$ and $\\mathbf{A}$ since"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b651d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathrm{norm}(\\mathbf{B}-\\mathbf{A})_F^2=4(1-c)\\sum_{i=1,i\\ne k,l}^n(a_{ik}^2+a_{il}^2) +\\frac{2a_{kl}^2}{c^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c94721",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Choose a tolerance $\\epsilon$, making it a small number, typically $10^{-8}$ or smaller.\n",
    "\n",
    " * Setup a *while* test  where one compares the norm of the newly computed off-diagonal matrix elements  \\[ \\mathrm{off}(\\mathbf{A}) = \\sqrt{\\sum_{i=1}^n\\sum_{j=1,j\\ne i}^n a_{ij}^2}   >  \\epsilon. \\]\n",
    "\n",
    " * Now choose the matrix elements $a_{kl}$ so that we have those with largest value, that is $|a_{kl}|=\\mathrm{max}_{i\\ne j} |a_{ij}|$.\n",
    "\n",
    " * Compute thereafter $\\tau = (a_{ll}-a_{kk})/2a_{kl}$, $\\tan\\theta$, $\\cos\\theta$ and $\\sin\\theta$.\n",
    "\n",
    " * Compute thereafter the similarity transformation for this set of values $(k,l)$, obtaining the new matrix $\\mathbf{B}= \\mathbf{S}(k,l,\\theta)^T \\mathbf{A}\\mathbf{S}(k,l,\\theta)$.\n",
    "\n",
    " * Compute the new norm of the off-diagonal matrix elements and continue till you have satisfied $\\mathrm{off}(\\mathbf{B})  \\le  \\epsilon$\n",
    "\n",
    "The convergence rate of the Jacobi method is however poor, one needs typically $3n^2-5n^2$ rotations and each rotation \n",
    "requires $4n$ operations, resulting in a total of $12n^3-20n^3$ operations in order to zero out non-diagonal matrix elements.\n",
    "\n",
    "We specialize to a symmetric $3\\times 3 $ matrix $\\mathbf{A}$.\n",
    "We start the process as follows (assuming that $a_{23}=a_{32}$ is the largest non-diagonal)\n",
    "with $c=\\cos{\\theta}$ and $s=\\sin{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e7d9f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{B} =\n",
    "      \\left( \\begin{array}{ccc} \n",
    "                1 & 0 & 0    \\\\\n",
    "                0 & c & -s     \\\\\n",
    "                0 & s & c\n",
    "             \\end{array} \\right)\\left( \\begin{array}{ccc} \n",
    "                a_{11} & a_{12} & a_{13}    \\\\\n",
    "                a_{21} & a_{22} & a_{23}     \\\\\n",
    "                a_{31} & a_{32} & a_{33}\n",
    "             \\end{array} \\right)\n",
    "              \\left( \\begin{array}{ccc} \n",
    "                1 & 0 & 0    \\\\\n",
    "                0 & c & s     \\\\\n",
    "                0 & -s & c\n",
    "             \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e37b03",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will choose the angle $\\theta$ in order to have $a_{23}=a_{32}=0$.\n",
    "We get (symmetric matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f131e86",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{B} =\\left( \\begin{array}{ccc} \n",
    "                a_{11} & a_{12}c -a_{13}s& a_{12}s+a_{13}c    \\\\\n",
    "                a_{12}c -a_{13}s & a_{22}c^2+a_{33}s^2 -2a_{23}sc& (a_{22}-a_{33})sc +a_{23}(c^2-s^2)     \\\\\n",
    "                a_{12}s+a_{13}c & (a_{22}-a_{33})sc +a_{23}(c^2-s^2) & a_{22}s^2+a_{33}c^2 +2a_{23}sc\n",
    "             \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8c969",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that $a_{11}$ is unchanged! As it should.\n",
    "\n",
    "We have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6cc7fd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{B} =\\left( \\begin{array}{ccc} \n",
    "                a_{11} & a_{12}c -a_{13}s& a_{12}s+a_{13}c    \\\\\n",
    "                a_{12}c -a_{13}s & a_{22}c^2+a_{33}s^2 -2a_{23}sc& (a_{22}-a_{33})sc +a_{23}(c^2-s^2)     \\\\\n",
    "                a_{12}s+a_{13}c & (a_{22}-a_{33})sc +a_{23}(c^2-s^2) & a_{22}s^2+a_{33}c^2 +2a_{23}sc\n",
    "             \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c666ab3",
   "metadata": {
    "editable": true
   },
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe10b35a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "b_{11} =& a_{11} \\\\\n",
    "b_{12} =& a_{12}\\cos\\theta - a_{13}\\sin\\theta , 1 \\ne 2, 1 \\ne 3 \\\\\n",
    "b_{13} =& a_{13}\\cos\\theta + a_{12}\\sin\\theta , 1 \\ne 2, 1 \\ne 3 \\nonumber\\\\\n",
    "b_{22} =& a_{22}\\cos^2\\theta - 2a_{23}\\cos\\theta \\sin\\theta +a_{33}\\sin^2\\theta\\nonumber\\\\\n",
    "b_{33} =& a_{33}\\cos^2\\theta +2a_{23}\\cos\\theta \\sin\\theta +a_{22}\\sin^2\\theta\\nonumber\\\\\n",
    "b_{23} =& (a_{22}-a_{33})\\cos\\theta \\sin\\theta +a_{23}(\\cos^2\\theta-\\sin^2\\theta)\\nonumber \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56db815",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will fix the angle $\\theta$ so that $b_{23}=0$.\n",
    "\n",
    "We get then a new matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d8901",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{B} =\\left( \\begin{array}{ccc} \n",
    "                b_{11} & b_{12}& b_{13}    \\\\\n",
    "                b_{12}& b_{22}& 0    \\\\\n",
    "                b_{13}& 0& a_{33}\n",
    "             \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e9c33",
   "metadata": {
    "editable": true
   },
   "source": [
    "We repeat then assuming that $b_{12}$ is the largest non-diagonal matrix element and get a\n",
    "new matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74426e4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{C} =\n",
    "      \\left( \\begin{array}{ccc} \n",
    "                c & -s & 0    \\\\\n",
    "                s & c & 0     \\\\\n",
    "                0 & 0 & 1\n",
    "             \\end{array} \\right)\\left( \\begin{array}{ccc} \n",
    "                b_{11} & b_{12} & b_{13}    \\\\\n",
    "                b_{12} & b_{22} & 0     \\\\\n",
    "                b_{13} & 0 & b_{33}\n",
    "             \\end{array} \\right)\n",
    "              \\left( \\begin{array}{ccc} \n",
    "                c & s & 0    \\\\\n",
    "                -s & c & 0     \\\\\n",
    "                0 & 0 & 1\n",
    "             \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb7e27",
   "metadata": {
    "editable": true
   },
   "source": [
    "We continue this process till all non-diagonal matrix elements are zero (ideally).\n",
    "You will notice that performing the above operations that the matrix element \n",
    "$b_{23}$ which was previous zero becomes different from zero.  This is one of the problems which slows\n",
    "down the jacobi procedure.\n",
    "\n",
    "The more general expression for the new matrix elements are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a587e39c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "b_{ii} =& a_{ii}, i \\ne k, i \\ne l \\\\\n",
    "b_{ik} =& a_{ik}\\cos\\theta - a_{il}\\sin\\theta , i \\ne k, i \\ne l \\\\\n",
    "b_{il} =& a_{il}\\cos\\theta + a_{ik}\\sin\\theta , i \\ne k, i \\ne l \\nonumber\\\\\n",
    "b_{kk} =& a_{kk}\\cos^2\\theta - 2a_{kl}\\cos\\theta \\sin\\theta +a_{ll}\\sin^2\\theta\\nonumber\\\\\n",
    "b_{ll} =& a_{ll}\\cos^2\\theta +2a_{kl}\\cos\\theta \\sin\\theta +a_{kk}\\sin^2\\theta\\nonumber\\\\\n",
    "b_{kl} =& (a_{kk}-a_{ll})\\cos\\theta \\sin\\theta +a_{kl}(\\cos^2\\theta-\\sin^2\\theta)\\nonumber \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda50077",
   "metadata": {
    "editable": true
   },
   "source": [
    "This is what we will need to code.\n",
    "\n",
    " Code example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918101e",
   "metadata": {
    "editable": true
   },
   "source": [
    "        //  we have defined a matrix A and a matrix R for the eigenvector, both of dim n x n\n",
    "        //  The final matrix R has the eigenvectors in its row elements, it is set to one\n",
    "        //  for the diagonal elements in the beginning, zero else.\n",
    "        ....\n",
    "        double tolerance = 1.0E-10; \n",
    "        int iterations = 0;\n",
    "        while ( maxnondiag > tolerance && iterations <= maxiter)\n",
    "        {\n",
    "           int p, q;\n",
    "           offdiag(A, &p, &q, n);\n",
    "           Jacobi_rotate(A, R, p, q, n);\n",
    "           iterations++;\n",
    "        }\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25368388",
   "metadata": {
    "editable": true
   },
   "source": [
    "Finding the max nondiagonal element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ab342",
   "metadata": {
    "editable": true
   },
   "source": [
    "        //  the offdiag function, using Armadillo\n",
    "        void offdiag(mat A, int *p, int *q, int n);\n",
    "        {\n",
    "           double max;\n",
    "           for (int i = 0; i < n; ++i)\n",
    "           {\n",
    "               for ( int j = i+1; j < n; ++j)\n",
    "               {\n",
    "                   double aij = fabs(A(i,j));\n",
    "                   if ( aij > max)\n",
    "                   { \n",
    "                      max = aij;  p = i; q = j;\n",
    "                   }\n",
    "               }\n",
    "           }\n",
    "        }\n",
    "        // more statements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9a4b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "Finding the new matrix elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec37da53",
   "metadata": {
    "editable": true
   },
   "source": [
    "        void Jacobi_rotate ( mat A, mat R, int k, int l, int n )\n",
    "        {\n",
    "          double s, c;\n",
    "          if ( A(k,l) != 0.0 ) {\n",
    "            double t, tau;\n",
    "            tau = (A(l,l) - A(k,k))/(2*A(k,l));\n",
    "            \n",
    "            if ( tau >= 0 ) {\n",
    "              t = 1.0/(tau + sqrt(1.0 + tau*tau));\n",
    "            } else {\n",
    "              t = -1.0/(-tau +sqrt(1.0 + tau*tau));\n",
    "            }\n",
    "            \n",
    "            c = 1/sqrt(1+t*t);\n",
    "            s = c*t;\n",
    "          } else {\n",
    "            c = 1.0;\n",
    "            s = 0.0;\n",
    "          }\n",
    "          double a_kk, a_ll, a_ik, a_il, r_ik, r_il;\n",
    "          a_kk = A(k,k);\n",
    "          a_ll = A(l,l);\n",
    "          A(k,k) = c*c*a_kk - 2.0*c*s*A(k,l) + s*s*a_ll;\n",
    "          A(l,l) = s*s*a_kk + 2.0*c*s*A(k,l) + c*c*a_ll;\n",
    "          A(k,l) = 0.0;  // hard-coding non-diagonal elements by hand\n",
    "          A(l,k) = 0.0;  // same here\n",
    "          for ( int i = 0; i < n; i++ ) {\n",
    "            if ( i != k && i != l ) {\n",
    "              a_ik = A(i,k);\n",
    "              a_il = A(i,l);\n",
    "              A(i,k) = c*a_ik - s*a_il;\n",
    "              A(k,i) = A(i,k);\n",
    "              A(i,l) = c*a_il + s*a_ik;\n",
    "              A(l,i) = A(i,l);\n",
    "            }\n",
    "        //  And finally the new eigenvectors\n",
    "            r_ik = R(i,k);\n",
    "            r_il = R(i,l);\n",
    "        \n",
    "            R(i,k) = c*r_ik - s*r_il;\n",
    "            R(i,l) = c*r_il + s*r_ik;\n",
    "          }\n",
    "          return;\n",
    "        } // end of function jacobi_rotate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fd2ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Harmonic oscillator problem with and without interactions\n",
    "\n",
    "In project 1 we rewrote our original differential equation in terms of a discretized equation with approximations to the \n",
    "derivatives as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d1e100",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{u_{i+1} -2u_i +u_{i-i}}{h^2}=f(x_i,u(x_i)),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a3b656",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $i=1,2,\\dots, n$. We need to add to this system the two boundary conditions $u(a) =u_0$ and $u(b) = u_{n+1}$.\n",
    "If we define a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c495fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{A} = \\frac{1}{h^2}\\left(\\begin{array}{cccccc}\n",
    "                          2 & -1 &  &   &  & \\\\\n",
    "                          -1 & 2 & -1 & & & \\\\\n",
    "                           & -1 & 2 & -1 & &  \\\\\n",
    "                           & \\dots   & \\dots &\\dots   &\\dots & \\dots \\\\\n",
    "                           &   &  &-1  &2& -1 \\\\\n",
    "                           &    &  &   &-1 & 2 \\\\\n",
    "                      \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077bf34a",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the corresponding vectors $\\mathbf{u} = (u_1, u_2, \\dots,u_n)^T$ and \n",
    "$\\mathbf{f}(\\mathbf{u}) = f(x_1,x_2,\\dots, x_n,u_1, u_2, \\dots,u_n)^T$  we can rewrite the differential equation\n",
    "including the boundary conditions as a system of linear equations with  a large number of unknowns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147ce273",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{A}\\mathbf{u} = \\mathbf{f}(\\mathbf{u}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5ef184",
   "metadata": {
    "editable": true
   },
   "source": [
    "We are first interested in the solution of the radial part of Schroedinger's equation for one electron. This equation reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25d7e9d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2 m} \\left ( \\frac{1}{r^2} \\frac{d}{dr} r^2\n",
    "  \\frac{d}{dr} - \\frac{l (l + 1)}{r^2} \\right )R(r) \n",
    "     + V(r) R(r) = E R(r).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4c792c",
   "metadata": {
    "editable": true
   },
   "source": [
    "In our case $V(r)$ is the harmonic oscillator potential $(1/2)kr^2$ with\n",
    "$k=m\\omega^2$ and $E$ is\n",
    "the energy of the harmonic oscillator in three dimensions.\n",
    "The oscillator frequency is $\\omega$ and the energies are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e82696a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_{nl}=  \\hbar \\omega \\left(2n+l+\\frac{3}{2}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c96cea",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $n=0,1,2,\\dots$ and $l=0,1,2,\\dots$.\n",
    "\n",
    "Since we have made a transformation to spherical coordinates it means that \n",
    "$r\\in [0,\\infty)$.  \n",
    "The quantum number\n",
    "$l$ is the orbital momentum of the electron.   Then we substitute $R(r) = (1/r) u(r)$ and obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b199923",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2 m} \\frac{d^2}{dr^2} u(r) \n",
    "       + \\left ( V(r) + \\frac{l (l + 1)}{r^2}\\frac{\\hbar^2}{2 m}\n",
    "                                    \\right ) u(r)  = E u(r) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd191e5f",
   "metadata": {
    "editable": true
   },
   "source": [
    "The boundary conditions are $u(0)=0$ and $u(\\infty)=0$.\n",
    "\n",
    "We introduce a dimensionless variable $\\rho = (1/\\alpha) r$\n",
    "where $\\alpha$ is a constant with dimension length and get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74d248",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2 m \\alpha^2} \\frac{d^2}{d\\rho^2} u(\\rho) \n",
    "       + \\left ( V(\\rho) + \\frac{l (l + 1)}{\\rho^2}\n",
    "         \\frac{\\hbar^2}{2 m\\alpha^2} \\right ) u(\\rho)  = E u(\\rho) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed30070",
   "metadata": {
    "editable": true
   },
   "source": [
    "In project 2 we choose $l=0$.\n",
    "Inserting $V(\\rho) = (1/2) k \\alpha^2\\rho^2$ we end up with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd1cc9e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2 m \\alpha^2} \\frac{d^2}{d\\rho^2} u(\\rho) \n",
    "       + \\frac{k}{2} \\alpha^2\\rho^2u(\\rho)  = E u(\\rho) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd85e53",
   "metadata": {
    "editable": true
   },
   "source": [
    "We multiply thereafter with $2m\\alpha^2/\\hbar^2$ on both sides and obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54140dd0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{d^2}{d\\rho^2} u(\\rho) \n",
    "       + \\frac{mk}{\\hbar^2} \\alpha^4\\rho^2u(\\rho)  = \\frac{2m\\alpha^2}{\\hbar^2}E u(\\rho) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c16cf",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have thus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c93da40",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{d^2}{d\\rho^2} u(\\rho) \n",
    "       + \\frac{mk}{\\hbar^2} \\alpha^4\\rho^2u(\\rho)  = \\frac{2m\\alpha^2}{\\hbar^2}E u(\\rho) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52b6f1",
   "metadata": {
    "editable": true
   },
   "source": [
    "The constant $\\alpha$ can now be fixed\n",
    "so that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70f3edd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{mk}{\\hbar^2} \\alpha^4 = 1,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb94a4c0",
   "metadata": {
    "editable": true
   },
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd709b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\alpha = \\left(\\frac{\\hbar^2}{mk}\\right)^{1/4}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b75f37",
   "metadata": {
    "editable": true
   },
   "source": [
    "Defining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c1ddb0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\lambda = \\frac{2m\\alpha^2}{\\hbar^2}E,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454f94a8",
   "metadata": {
    "editable": true
   },
   "source": [
    "we can rewrite Schroedinger's equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cba4fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{d^2}{d\\rho^2} u(\\rho) + \\rho^2u(\\rho)  = \\lambda u(\\rho) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6791efe",
   "metadata": {
    "editable": true
   },
   "source": [
    "This is the first equation to solve numerically. In three dimensions \n",
    "the eigenvalues for $l=0$ are \n",
    "$\\lambda_0=3,\\lambda_1=7,\\lambda_2=11,\\dots .$\n",
    "\n",
    "We use the by now standard\n",
    "expression for the second derivative of a function $u$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e3547",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:diffoperation\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    u''=\\frac{u(\\rho+h) -2u(\\rho) +u(\\rho-h)}{h^2} +O(h^2),\n",
    "\\label{eq:diffoperation} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf4d3d",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $h$ is our step.\n",
    "Next we define minimum and maximum values for the variable $\\rho$,\n",
    "$\\rho_{\\mathrm{min}}=0$  and $\\rho_{\\mathrm{max}}$, respectively.\n",
    "You need to check your results for the energies against different values\n",
    "$\\rho_{\\mathrm{max}}$, since we cannot set\n",
    "$\\rho_{\\mathrm{max}}=\\infty$. \n",
    "\n",
    "With a given number of steps, $n_{\\mathrm{step}}$, we then \n",
    "define the step $h$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892a9e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "h=\\frac{\\rho_{\\mathrm{max}}-\\rho_{\\mathrm{min}} }{n_{\\mathrm{step}}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c009d1e",
   "metadata": {
    "editable": true
   },
   "source": [
    "Define an arbitrary value of $\\rho$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fb77d5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\rho_i= \\rho_{\\mathrm{min}} + ih \\hspace{1cm} i=0,1,2,\\dots , n_{\\mathrm{step}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50975ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "we can rewrite the Schr\\\"odinger equation for $\\rho_i$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c2350",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{u(\\rho_i+h) -2u(\\rho_i) +u(\\rho_i-h)}{h^2}+\\rho_i^2u(\\rho_i)  = \\lambda u(\\rho_i),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00456100",
   "metadata": {
    "editable": true
   },
   "source": [
    "or in  a more compact way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b5ae2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{u_{i+1} -2u_i +u_{i-1}}{h^2}+\\rho_i^2u_i=-\\frac{u_{i+1} -2u_i +u_{i-1} }{h^2}+V_iu_i  = \\lambda u_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b1d75",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $V_i=\\rho_i^2$ is the harmonic oscillator potential.\n",
    "\n",
    "Define first the diagonal matrix element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508a384b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "d_i=\\frac{2}{h^2}+V_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9da06",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the non-diagonal matrix element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b349fe9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "e_i=-\\frac{1}{h^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c35c0",
   "metadata": {
    "editable": true
   },
   "source": [
    "In this case the non-diagonal matrix elements are given by a mere constant. *All non-diagonal matrix elements are equal*.\n",
    "\n",
    "With these definitions the Schroedinger equation takes the following form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105d2fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "d_iu_i+e_{i-1}u_{i-1}+e_{i+1}u_{i+1}  = \\lambda u_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84499d81",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $u_i$ is unknown. We can write the \n",
    "latter equation as a matrix eigenvalue problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98b75a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:sematrix\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\left( \\begin{array}{ccccccc} d_1 & e_1 & 0   & 0    & \\dots  &0     & 0 \\\\\n",
    "                                e_1 & d_2 & e_2 & 0    & \\dots  &0     &0 \\\\\n",
    "                                0   & e_2 & d_3 & e_3  &0       &\\dots & 0\\\\\n",
    "                                \\dots  & \\dots & \\dots & \\dots  &\\dots      &\\dots & \\dots\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &d_{n_{\\mathrm{step}}-2} & e_{n_{\\mathrm{step}}-1}\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &e_{n_{\\mathrm{step}}-1} & d_{n_{\\mathrm{step}}-1}\n",
    "             \\end{array} \\right)      \\left( \\begin{array}{c} u_{1} \\\\\n",
    "                                                              u_{2} \\\\\n",
    "                                                              \\dots\\\\ \\dots\\\\ \\dots\\\\\n",
    "                                                              u_{n_{\\mathrm{step}}-1}\n",
    "             \\end{array} \\right)=\\lambda \\left( \\begin{array}{c} u_{1} \\\\\n",
    "                                                              u_{2} \\\\\n",
    "                                                              \\dots\\\\ \\dots\\\\ \\dots\\\\\n",
    "                                                              u_{n_{\\mathrm{step}}-1}\n",
    "             \\end{array} \\right) \n",
    "\\label{eq:sematrix} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e98c6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "or if we wish to be more detailed, we can write the tridiagonal matrix as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff7bf7",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:matrixse\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\left( \\begin{array}{ccccccc} \\frac{2}{h^2}+V_1 & -\\frac{1}{h^2} & 0   & 0    & \\dots  &0     & 0 \\\\\n",
    "                                -\\frac{1}{h^2} & \\frac{2}{h^2}+V_2 & -\\frac{1}{h^2} & 0    & \\dots  &0     &0 \\\\\n",
    "                                0   & -\\frac{1}{h^2} & \\frac{2}{h^2}+V_3 & -\\frac{1}{h^2}  &0       &\\dots & 0\\\\\n",
    "                                \\dots  & \\dots & \\dots & \\dots  &\\dots      &\\dots & \\dots\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &\\frac{2}{h^2}+V_{n_{\\mathrm{step}}-2} & -\\frac{1}{h^2}\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &-\\frac{1}{h^2} & \\frac{2}{h^2}+V_{n_{\\mathrm{step}}-1}\n",
    "             \\end{array} \\right)  \n",
    "\\label{eq:matrixse} \\tag{3} \n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33d879",
   "metadata": {
    "editable": true
   },
   "source": [
    "Recall that the solutions are known via the boundary conditions at\n",
    "$i=n_{\\mathrm{step}}$ and at the other end point, that is for  $\\rho_0$.\n",
    "The solution is zero in both cases.\n",
    "\n",
    "We are going to study two electrons in a harmonic oscillator well which\n",
    "also interact via a repulsive Coulomb interaction.\n",
    "Let us start with the single-electron equation written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2870748",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2 m} \\frac{d^2}{dr^2} u(r) \n",
    "       + \\frac{1}{2}k r^2u(r)  = E^{(1)} u(r),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7c302",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $E^{(1)}$ stands for the energy with one electron only.\n",
    "For two electrons with no repulsive Coulomb interaction, we have the following \n",
    "Schroedinger equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c5c1c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left(  -\\frac{\\hbar^2}{2 m} \\frac{d^2}{dr_1^2} -\\frac{\\hbar^2}{2 m} \\frac{d^2}{dr_2^2}+ \\frac{1}{2}k r_1^2+ \\frac{1}{2}k r_2^2\\right)u(r_1,r_2)  = E^{(2)} u(r_1,r_2) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6daa8b",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that we deal with a two-electron wave function $u(r_1,r_2)$ and \n",
    "two-electron energy $E^{(2)}$.\n",
    "\n",
    "With no interaction this can be written out as the product of two\n",
    "single-electron wave functions, that is we have a solution on closed form.\n",
    "\n",
    "We introduce the relative coordinate $\\mathbf{r} = \\mathbf{r}_1-\\mathbf{r}_2$\n",
    "and the center-of-mass coordinate $\\mathbf{R} = 1/2(\\mathbf{r}_1+\\mathbf{r}_2)$.\n",
    "With these new coordinates, the radial Schroedinger equation reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e473d876",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left(  -\\frac{\\hbar^2}{m} \\frac{d^2}{dr^2} -\\frac{\\hbar^2}{4 m} \\frac{d^2}{dR^2}+ \\frac{1}{4} k r^2+  kR^2\\right)u(r,R)  = E^{(2)} u(r,R).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fed0cf",
   "metadata": {
    "editable": true
   },
   "source": [
    "The equations for $r$ and $R$ can be separated via the ansatz for the \n",
    "wave function $u(r,R) = \\psi(r)\\phi(R)$ and the energy is given by the sum\n",
    "of the relative energy $E_r$ and the center-of-mass energy $E_R$, that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897da28",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E^{(2)}=E_r+E_R.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a87367b",
   "metadata": {
    "editable": true
   },
   "source": [
    "We add then the repulsive Coulomb interaction between two electrons,\n",
    "namely a term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca2d97c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "V(r_1,r_2) = \\frac{\\beta e^2}{|\\mathbf{r}_1-\\mathbf{r}_2|}=\\frac{\\beta e^2}{r},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e59575",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\beta e^2=1.44$ eVnm.\n",
    "\n",
    "Adding this term, the $r$-dependent Schroedinger equation becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecaa8bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left(  -\\frac{\\hbar^2}{m} \\frac{d^2}{dr^2}+ \\frac{1}{4}k r^2+\\frac{\\beta e^2}{r}\\right)\\psi(r)  = E_r \\psi(r).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a951211f",
   "metadata": {
    "editable": true
   },
   "source": [
    "This equation is similar to the one we had previously in parts (a) and (b) \n",
    "and we introduce\n",
    "again a dimensionless variable $\\rho = r/\\alpha$. Repeating the same\n",
    "steps, we arrive at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4c897",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{d^2}{d\\rho^2} \\psi(\\rho) \n",
    "       + \\frac{mk}{4\\hbar^2} \\alpha^4\\rho^2\\psi(\\rho)+\\frac{m\\alpha \\beta e^2}{\\rho\\hbar^2}\\psi(\\rho)  = \n",
    "\\frac{m\\alpha^2}{\\hbar^2}E_r \\psi(\\rho) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db133a",
   "metadata": {
    "editable": true
   },
   "source": [
    "We want to manipulate this equation further to make it as similar to that in (a)\n",
    "as possible. We define a 'frequency'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04651fce",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\omega_r^2=\\frac{1}{4}\\frac{mk}{\\hbar^2} \\alpha^4,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1499d4",
   "metadata": {
    "editable": true
   },
   "source": [
    "and fix the constant $\\alpha$ by requiring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1978d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{m\\alpha \\beta e^2}{\\hbar^2}=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab5b6e",
   "metadata": {
    "editable": true
   },
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7b93c5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\alpha = \\frac{\\hbar^2}{m\\beta e^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f5203",
   "metadata": {
    "editable": true
   },
   "source": [
    "Defining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b0ea92",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\lambda = \\frac{m\\alpha^2}{\\hbar^2}E,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c2038",
   "metadata": {
    "editable": true
   },
   "source": [
    "we can rewrite Schroedinger's equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665ae92d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{d^2}{d\\rho^2} \\psi(\\rho) + \\omega_r^2\\rho^2\\psi(\\rho) +\\frac{1}{\\rho}\\psi(\\rho) = \\lambda \\psi(\\rho).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55c7e2",
   "metadata": {
    "editable": true
   },
   "source": [
    "We treat $\\omega_r$ as a parameter which reflects the strength of the oscillator potential.\n",
    "\n",
    "Here we will study the cases $\\omega_r = 0.01$, $\\omega_r = 0.5$, $\\omega_r =1$,\n",
    "and $\\omega_r = 5$   \n",
    "for the ground state only, that is the lowest-lying state.\n",
    "\n",
    "With no repulsive Coulomb interaction \n",
    "you should get a result which corresponds to \n",
    "the relative energy of a non-interacting system.   \n",
    "Make sure your results are \n",
    "stable as functions of $\\rho_{\\mathrm{max}}$ and the number of steps.\n",
    "\n",
    "We are only interested in the ground state with $l=0$. We omit the \n",
    "center-of-mass energy.\n",
    "\n",
    "For specific oscillator frequencies, the above equation has analytic answers,\n",
    "see the article by M. Taut, Phys. Rev. A 48, 3561 - 3566 (1993).\n",
    "The article can be retrieved from the following web address <http://prola.aps.org/abstract/PRA/v48/i5/p3561_1>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd6795c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Simple program for one particle in a harmonic oscillator trap\n",
    "\n",
    "The following program uses the eigenvalue solver provided by Armadillo and returns the eigenvalues for the lowest states. You can run this code interactively if you use ipython notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069f6f1e",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%install_ext https://raw.github.com/dragly/cppmagic/master/cppmagic.py\n",
    "%load_ext cppmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898c34c2",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%cpp -I/usr/local/include -L/usr/local/lib -llapack -lblas -larmadillo\n",
    "/*\n",
    "  Solves the one-particle Schrodinger equation\n",
    "  for a potential specified in function\n",
    "  potential(). This example is for the harmonic oscillator in 3d\n",
    "*/\n",
    "#include <cmath>\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <iomanip>\n",
    "#include <armadillo>\n",
    "\n",
    "using namespace  std;\n",
    "using namespace  arma;\n",
    "\n",
    "double potential(double);\n",
    "void output(double, double, int, vec& );\n",
    "\n",
    "\n",
    "// Begin of main program   \n",
    "\n",
    "int main(int argc, char* argv[])\n",
    "{\n",
    "  int       i, j, Dim, lOrbital;\n",
    "  double    RMin, RMax, Step, DiagConst, NondiagConst, OrbitalFactor; \n",
    "  // With spherical coordinates RMin = 0 always\n",
    "  RMin = 0.0;\n",
    "\n",
    "  RMax = 8.0;  lOrbital = 0;  Dim =2000;  \n",
    "  mat Hamiltonian = zeros<mat>(Dim,Dim);\n",
    "  // Integration step length\n",
    "  Step    = RMax/ Dim;\n",
    "  DiagConst = 2.0 / (Step*Step);\n",
    "  NondiagConst =  -1.0 / (Step*Step);\n",
    "  OrbitalFactor = lOrbital * (lOrbital + 1.0);\n",
    "  \n",
    "  // local memory for r and the potential w[r] \n",
    "  vec r(Dim); vec w(Dim);\n",
    "  for(i = 0; i < Dim; i++) {\n",
    "    r(i) = RMin + (i+1) * Step;\n",
    "    w(i) = potential(r(i)) + OrbitalFactor/(r(i) * r(i));\n",
    "  }\n",
    "\n",
    "\n",
    "  // Setting up tridiagonal matrix and brute diagonalization using Armadillo\n",
    "  Hamiltonian(0,0) = DiagConst + w(0);\n",
    "  Hamiltonian(0,1) = NondiagConst;\n",
    "  for(i = 1; i < Dim-1; i++) {\n",
    "    Hamiltonian(i,i-1)    = NondiagConst;\n",
    "    Hamiltonian(i,i)    = DiagConst + w(i);\n",
    "    Hamiltonian(i,i+1)    = NondiagConst;\n",
    "  }\n",
    "  Hamiltonian(Dim-1,Dim-2) = NondiagConst;\n",
    "  Hamiltonian(Dim-1,Dim-1) = DiagConst + w(Dim-1);\n",
    "  // diagonalize and obtain eigenvalues\n",
    "  vec Eigval(Dim);\n",
    "  eig_sym(Eigval, Hamiltonian);\n",
    "  output(RMin , RMax, Dim, Eigval);\n",
    "\n",
    "  return 0;\n",
    "}  //  end of main function\n",
    "\n",
    "\n",
    "/*\n",
    "  The function potential()\n",
    "  calculates and return the value of the \n",
    "  potential for a given argument x.\n",
    "  The potential here is for the hydrogen atom\n",
    "*/        \n",
    "\n",
    "double potential(double x)\n",
    "{\n",
    "  return x*x;\n",
    "\n",
    "} // End: function potential()  \n",
    "\n",
    "\n",
    "void output(double RMin , double RMax, int Dim, vec& d)\n",
    "{\n",
    "  int i;\n",
    "  cout << \"RESULTS:\" << endl;\n",
    "  cout << setiosflags(ios::showpoint | ios::uppercase);\n",
    "  cout <<\"Rmin = \" << setw(15) << setprecision(8) << RMin << endl;  \n",
    "  cout <<\"Rmax = \" << setw(15) << setprecision(8) << RMax << endl;  \n",
    "  cout <<\"Number of steps = \" << setw(15) << Dim << endl;  \n",
    "  cout << \"Five lowest eigenvalues:\" << endl;\n",
    "  for(i = 0; i < 5; i++) {\n",
    "    cout << setw(15) << setprecision(8) << d[i] << endl;\n",
    "  }\n",
    "}  // end of function output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca72d76",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Unit Testing\n",
    "\n",
    "Unit Testing is the practice of testing the smallest testable parts,\n",
    "called units, of an application individually and independently to\n",
    "determine if they behave exactly as expected. \n",
    "\n",
    "Unit tests (short code\n",
    "fragments) are usually written such that they can be preformed at any\n",
    "time during the development to continually verify the behavior of the\n",
    "code. \n",
    "\n",
    "In this way, possible bugs will be identified early in the\n",
    "development cycle, making the debugging at later stages much\n",
    "easier. \n",
    "\n",
    "There are many benefits associated with Unit Testing, such as\n",
    "  * It increases confidence in changing and maintaining code. Big changes can be made to the code quickly, since the tests will ensure that everything still is working properly.\n",
    "\n",
    "  * Since the code needs to be modular to make Unit Testing possible, the code will be easier to reuse. This improves the code design.\n",
    "\n",
    "  * Debugging is easier, since when a test fails, only the latest changes need to be debugged.\n",
    "\n",
    "   * Different parts of a project can be tested without the need to wait for the other parts to be available.\n",
    "\n",
    "  * A unit test can serve as a documentation on the functionality of a unit of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4630d89",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Simple example of unit test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab6c34",
   "metadata": {
    "editable": true
   },
   "source": [
    "        #include <unittest++/UnitTest++.h>\n",
    "        \n",
    "        class MyMultiplyClass{\n",
    "        public:\n",
    "            double multiply(double x, double y) {\n",
    "                return x * y;\n",
    "            }\n",
    "        };\n",
    "        \n",
    "        TEST(MyMath) {\n",
    "            MyMultiplyClass my;\n",
    "            CHECK_EQUAL(56, my.multiply(7,8));\n",
    "        }\n",
    "        \n",
    "        int main()\n",
    "        {\n",
    "            return UnitTest::RunAllTests();\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c6770",
   "metadata": {
    "editable": true
   },
   "source": [
    "And without classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d8d4d",
   "metadata": {
    "editable": true
   },
   "source": [
    "        #include <unittest++/UnitTest++.h>\n",
    "        \n",
    "        \n",
    "        double multiply(double x, double y) {\n",
    "            return x * y;\n",
    "        }\n",
    "        \n",
    "        TEST(MyMath) {\n",
    "            CHECK_EQUAL(56, multiply(7,8));\n",
    "        }\n",
    "        \n",
    "        int main()\n",
    "        {\n",
    "            return UnitTest::RunAllTests();\n",
    "        } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9b35a",
   "metadata": {
    "editable": true
   },
   "source": [
    "For Fortran users, the link at <http://sourceforge.net/projects/fortranxunit/> contains a similar\n",
    "software for unit testing. \n",
    "\n",
    "There are many types of **unit test** libraries. One which is very popular with C++ programmers is [Catch](https://github.com/philsquared/Catch/blob/master/docs/tutorial.md)\n",
    "\n",
    "Catch is header only. All you need to do is drop the file(s) somewhere reachable from your project - either in some central location you can set your header search path to find, or directly into your project tree itself! \n",
    "\n",
    "This is a particularly good option for other Open-Source projects that want to use Catch for their test suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534d6d6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Examples\n",
    "\n",
    "Computing factorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e80f0",
   "metadata": {
    "editable": true
   },
   "source": [
    "        inline unsigned int Factorial( unsigned int number ) {\n",
    "          return number > 1 ? Factorial(number-1)*number : 1;\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af01065",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Factorial Example\n",
    "\n",
    "Simple test where we put everything in a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757fc577",
   "metadata": {
    "editable": true
   },
   "source": [
    "        #define CATCH_CONFIG_MAIN  // This tells Catch to provide a main()\n",
    "        #include \"catch.hpp\"\n",
    "        inline unsigned int Factorial( unsigned int number ) {\n",
    "          return number > 1 ? Factorial(number-1)*number : 1;\n",
    "        }\n",
    "        \n",
    "        TEST_CASE( \"Factorials are computed\", \"[factorial]\" ) {\n",
    "            REQUIRE( Factorial(0) == 1 );\n",
    "            REQUIRE( Factorial(1) == 1 );\n",
    "            REQUIRE( Factorial(2) == 2 );\n",
    "            REQUIRE( Factorial(3) == 6 );\n",
    "            REQUIRE( Factorial(10) == 3628800 );\n",
    "        }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a67ec3",
   "metadata": {
    "editable": true
   },
   "source": [
    "This will compile to a complete executable which responds to command line arguments. If you just run it with no arguments it will execute all test cases (in this case there is just one), report any failures, report a summary of how many tests passed and failed and return the number of failed tests.\n",
    "\n",
    "All we did was"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfce4d5",
   "metadata": {
    "editable": true
   },
   "source": [
    "        #define \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c654dd",
   "metadata": {
    "editable": true
   },
   "source": [
    "one identifier and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823cf275",
   "metadata": {
    "editable": true
   },
   "source": [
    "        #include \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edd441",
   "metadata": {
    "editable": true
   },
   "source": [
    "one header and we got everything - even an implementation of main() that will respond to command line arguments. \n",
    "Once you have more than one file with unit tests in you'll just need to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036a2c43",
   "metadata": {
    "editable": true
   },
   "source": [
    "        #include \"catch.hpp\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e02d96",
   "metadata": {
    "editable": true
   },
   "source": [
    "and go. Usually it's a good idea to have a dedicated implementation file that just has"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a47781",
   "metadata": {
    "editable": true
   },
   "source": [
    "        #define CATCH_CONFIG_MAIN \n",
    "        #include \"catch.hpp\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1056ad",
   "metadata": {
    "editable": true
   },
   "source": [
    "You can also provide your own implementation of main and drive Catch yourself.\n",
    "\n",
    "We introduce test cases with the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba01f6b",
   "metadata": {
    "editable": true
   },
   "source": [
    "        TEST_CASE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c0760",
   "metadata": {
    "editable": true
   },
   "source": [
    "macro.\n",
    "\n",
    "The test name must be unique. You can run sets of tests by specifying a wildcarded test name or a tag expression. \n",
    "All we did was **define** one identifier and **include** one header and we got everything.\n",
    "\n",
    "We write our individual test assertions using the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f989d9",
   "metadata": {
    "editable": true
   },
   "source": [
    "        REQUIRE \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fbc1c0",
   "metadata": {
    "editable": true
   },
   "source": [
    "macro.\n",
    "\n",
    "Three levels of tests\n",
    "1. Microscopic level: testing small parts of code, use often unit test libraries\n",
    "\n",
    "2. Mesoscopic level: testing the integration of various parts  of your code\n",
    "\n",
    "3. Macroscopic level: testing that the final result is ok"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e1a4e5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Discussion of Householder's method for eigenvalues\n",
    "\n",
    "The drawbacks with Jacobi's method are rather obvious, with perhaps the most negative feature being the fact that we cannot tell * a priori* how many transformations are needed. Can we do better?  \n",
    "The answer to this is yes and is given by a clever algorithm outlined by Householder. It was ranked among the top ten algorithms in the previous century.  We will discuss this algorithm in more detail below.\n",
    "\n",
    "The first step  consists in finding\n",
    "an orthogonal  matrix $\\mathbf{S}$ which is the product of $(n-2)$ orthogonal matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45712388",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S}=\\mathbf{S}_1\\mathbf{S}_2\\dots\\mathbf{S}_{n-2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdde31a",
   "metadata": {
    "editable": true
   },
   "source": [
    "each of which successively transforms one row and one column of $\\mathbf{A}$ into the \n",
    "required tridiagonal form. Only $n-2$ transformations are required, since the last two\n",
    "elements are already in tridiagonal form. \n",
    "\n",
    "In order to determine each $\\mathbf{S}_i$ let us\n",
    "see what happens after the first multiplication, namely,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be08e264",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S}_1^T\\mathbf{A}\\mathbf{S}_1=    \\left( \\begin{array}{ccccccc} a_{11} & e_1 & 0   & 0    & \\dots  &0     & 0 \\\\\n",
    "                                e_1 & a'_{22} &a'_{23}  & \\dots    & \\dots  &\\dots &a'_{2n} \\\\\n",
    "                                0   & a'_{32} &a'_{33}  & \\dots    & \\dots  &\\dots &a'_{3n} \\\\\n",
    "                                0   & \\dots &\\dots & \\dots    & \\dots  &\\dots & \\\\\n",
    "                                0   & a'_{n2} &a'_{n3}  & \\dots    & \\dots  &\\dots &a'_{nn} \\\\\n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700b120",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the primed quantities represent a matrix $\\mathbf{A}'$ of dimension\n",
    "$n-1$ which will subsequentely be transformed by $\\mathbf{S}_2$.\n",
    "\n",
    "The factor  $e_1$ is a possibly non-vanishing element. The next\n",
    "transformation produced by $\\mathbf{S}_2$ has the same effect as  $\\mathbf{S}s$ but now on the submatirx $\\mathbf{A^{'}}$ only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c277e3f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left (\\mathbf{S}_{1}\\mathbf{S}_{2} \\right )^{T} \\mathbf{A}\\mathbf{S}_{1} \\mathbf{S}_{2}\n",
    " = \\left( \\begin{array}{ccccccc} a_{11} & e_1 & 0   & 0    & \\dots  &0     & 0 \\\\\n",
    "                                e_1 & a'_{22} &e_2  & 0   & \\dots  &\\dots &0 \\\\\n",
    "                                0   & e_2 &a''_{33}  & \\dots    & \\dots  &\\dots &a''_{3n} \\\\\n",
    "                                0   & \\dots &\\dots & \\dots    & \\dots  &\\dots & \\\\\n",
    "                                0   & 0 &a''_{n3}  & \\dots    & \\dots  &\\dots &a''_{nn} \\\\\n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810f9ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "*Note that the effective size of the matrix on which we apply the transformation reduces for every new step. In the previous Jacobi method each similarity transformation is in principle performed on the full size of the original matrix*.\n",
    "\n",
    "After a series of such transformations, we end with a set of diagonal\n",
    "matrix elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28777f26",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "a_{11}, a'_{22}, a''_{33}\\dots a^{n-1}_{nn},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff2e98",
   "metadata": {
    "editable": true
   },
   "source": [
    "and off-diagonal matrix elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ee9c4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "e_1, e_2,e_3,  \\dots, e_{n-1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3886115",
   "metadata": {
    "editable": true
   },
   "source": [
    "The resulting matrix reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e586e0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S}^{T} \\mathbf{A} \\mathbf{S} = \n",
    "    \\left( \\begin{array}{ccccccc} a_{11} & e_1 & 0   & 0    & \\dots  &0     & 0 \\\\\n",
    "                                e_1 & a'_{22} & e_2 & 0    & \\dots  &0     &0 \\\\\n",
    "                                0   & e_2 & a''_{33} & e_3  &0       &\\dots & 0\\\\\n",
    "                                \\dots  & \\dots & \\dots & \\dots  &\\dots      &\\dots & \\dots\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &a^{(n-1)}_{n-2} & e_{n-1}\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &e_{n-1} & a^{(n-1)}_{nn}\n",
    "             \\end{array} \\right) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe9641c",
   "metadata": {
    "editable": true
   },
   "source": [
    "It remains to find a recipe for determining the transformation $\\mathbf{S}_n$.\n",
    "We illustrate the method for $\\mathbf{S}_1$ which we assume takes the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60173201",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S_{1}} = \\left( \\begin{array}{cc} 1 & \\mathbf{0^{T}} \\\\\n",
    "                              \\mathbf{0}& \\mathbf{P} \\end{array} \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fa565",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\mathbf{0^{T}}$ being a zero row vector, $\\mathbf{0^{T}} = \\{0,0,\\cdots\\}$\n",
    "of dimension $(n-1)$. The matrix $\\mathbf{P}$  is symmetric \n",
    "with dimension ($(n-1) \\times (n-1)$) satisfying\n",
    "$\\mathbf{P}^2=\\mathbf{I}$  and $\\mathbf{P}^T=\\mathbf{P}$. \n",
    "A possible choice which fullfils the latter two requirements is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a2c15",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{P}=\\mathbf{I}-2\\mathbf{u}\\mathbf{u}^T,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a29b71",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\mathbf{I}$ is the $(n-1)$ unity matrix and $\\mathbf{u}$ is an $n-1$\n",
    "column vector with norm $\\mathbf{u}^T\\mathbf{u}$ (inner product).\n",
    "\n",
    " Note that $\\mathbf{u}\\mathbf{u}^T$ is an outer product giving a\n",
    "matrix of dimension ($(n-1) \\times (n-1)$). \n",
    "Each matrix element of $\\mathbf{P}$ then reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9259d6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P_{ij}=\\delta_{ij}-2u_iu_j,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abf36e",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $i$ and $j$ range from $1$ to $n-1$. Applying the transformation  \n",
    "$\\mathbf{S}_1$ results in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae20063",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S}_1^T\\mathbf{A}\\mathbf{S}_1 =  \\left( \\begin{array}{cc} a_{11} & (\\mathbf{Pv})^T \\\\\n",
    "                              \\mathbf{Pv}& \\mathbf{A}' \\end{array} \\right) ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66ceec7",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\mathbf{v^{T}} = \\{a_{21}, a_{31},\\cdots, a_{n1}\\}$ and $\\mathbf{P}$s\n",
    "must satisfy ($\\mathbf{Pv})^{T} = \\{k, 0, 0,\\cdots \\}$. Then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7810208",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:palpha\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathbf{Pv} = \\mathbf{v} -2\\mathbf{u}( \\mathbf{u}^T\\mathbf{v})= k \\mathbf{e},\n",
    "\\label{eq:palpha} \\tag{4}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2886af95",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\mathbf{e^{T}} = \\{1,0,0,\\dots 0\\}$.\n",
    "\n",
    "Solving the latter equation gives us $\\mathbf{u}$ and thus the needed transformation\n",
    "$\\mathbf{P}$. We do first however need to compute the scalar $k$ by taking the scalar\n",
    "product of the last equation with its transpose and using the fact that $\\mathbf{P}^2=\\mathbf{I}$.\n",
    "We get then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e307d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "(\\mathbf{Pv})^T\\mathbf{Pv} = k^{2} = \\mathbf{v}^T\\mathbf{v}=\n",
    "   |v|^2 = \\sum_{i=2}^{n}a_{i1}^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f667e",
   "metadata": {
    "editable": true
   },
   "source": [
    "which determines the constant $ k = \\pm v$.\n",
    "\n",
    " Now we can rewrite Eq. ([4](#eq:palpha))\n",
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f77e0f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{v} - k\\mathbf{e} = 2\\mathbf{u}( \\mathbf{u}^T\\mathbf{v}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd62f4a",
   "metadata": {
    "editable": true
   },
   "source": [
    "and taking the scalar product of this equation with itself and obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5932f0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:pmalpha\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    2( \\mathbf{u}^T\\mathbf{v})^2=(v^2\\pm a_{21}v),\n",
    "\\label{eq:pmalpha} \\tag{5}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6543d4",
   "metadata": {
    "editable": true
   },
   "source": [
    "which finally determines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb0231",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{u}=\\frac{\\mathbf{v}-k\\mathbf{e}}{2( \\mathbf{u}^T\\mathbf{v})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da8c9b",
   "metadata": {
    "editable": true
   },
   "source": [
    "In solving Eq. ([5](#eq:pmalpha)) great care has to be exercised so as to choose\n",
    "those values which make the right-hand largest in order to avoid loss of numerical\n",
    "precision. \n",
    "The above steps are then repeated for every transformations till we have a \n",
    "tridiagonal matrix suitable for obtaining the eigenvalues.  \n",
    "\n",
    "Our Householder transformation has given us a tridiagonal matrix. We discuss here how one can use\n",
    "Householder's iterative procedure to obtain the eigenvalues. \n",
    "Let us specialize to a $4\\times 4 $ matrix.\n",
    "The tridiagonal matrix takes the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6246d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{A} =\n",
    "      \\left( \\begin{array}{cccc} \n",
    "                d_{1} & e_{1} & 0     &  0    \\\\\n",
    "                e_{1} & d_{2} & e_{2} &  0    \\\\\n",
    "                 0    & e_{2} & d_{3} & e_{3} \\\\\n",
    "                 0    &   0   & e_{3} & d_{4} \n",
    "             \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380a875",
   "metadata": {
    "editable": true
   },
   "source": [
    "As a first observation, if any of the elements $e_{i}$ are zero the\n",
    "matrix can be separated into smaller pieces before\n",
    "diagonalization. Specifically, if $e_{1} = 0$ then $d_{1}$ is an\n",
    "eigenvalue.\n",
    "\n",
    " Thus, let us introduce  a transformation $\\mathbf{S_{1}}$ which operates like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f7e58",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S_{1}} =\n",
    "      \\left( \\begin{array}{cccc} \n",
    "                \\cos \\theta & 0 & 0 & \\sin \\theta\\\\\n",
    "                 0       & 0 & 0 &      0      \\\\\n",
    "                   0        & 0 & 0 &      0      \\\\\n",
    "               \\cos \\theta & 0 & 0 & \\cos \\theta \n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe417a17",
   "metadata": {
    "editable": true
   },
   "source": [
    "Then the similarity transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d411e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S_{1}^{T} A  S_{1}} = \\mathbf{A'} = \n",
    "      \\left( \\begin{array}{cccc}\n",
    "              d'_{1} & e'_{1} &   0    &   0   \\\\\n",
    "              e'_{1}  & d_{2}  & e_{2}  &   0   \\\\\n",
    "                0    & e_{2}  & d_{3}  & e'{3} \\\\\n",
    "                0    &   0    & e'_{3} & d'_{4}\n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54e5e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "produces a matrix where the primed elements in $\\mathbf{A'}$ have been\n",
    "changed by the transformation whereas the unprimed elements are unchanged.\n",
    "If we now choose $\\theta$ to\n",
    "give the element $a_{21}^{'} = e^{'}= 0$ then we have the first\n",
    "eigenvalue  $= a_{11}^{'} = d_{1}^{'}$.\n",
    "(This is actually what you are doing in project 2!!)\n",
    "\n",
    "This procedure can be continued on the remaining three-dimensional\n",
    "submatrix for the next eigenvalue. Thus after few transformations    \n",
    "we have the wanted diagonal form.\n",
    "\n",
    "What we see here is just a special case of the more general procedure \n",
    "developed by Francis in two articles in 1961 and 1962.\n",
    "\n",
    "The algorithm is based on the so-called *QR* method (or just *QR*-algorithm). It follows from a theorem by Schur which states that any square matrix can be written out in terms of an orthogonal matrix $\\mathbf{Q}$ and an upper triangular matrix $\\mathbf{U}$. Historically *R* was used instead of \n",
    "*U* since the wording right triangular matrix was first used.\n",
    "The method is based on an iterative procedure similar to Jacobi's method, by a succession of\n",
    "planar rotations. For a tridiagonal matrix it is simple to carry out in principle, but complicated in detail! We will discuss this in more detail during week 38."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b0768",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Eigenvalues with the *QR* and Lanczos methods\n",
    "\n",
    "Our Householder transformation has given us a tridiagonal matrix. We discuss here how one can use\n",
    "Jacobi's iterative procedure to obtain the eigenvalues, although it may not be the best approach. \n",
    "Let us specialize to a $4\\times 4 $ matrix.\n",
    "The tridiagonal matrix takes the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf48092",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{A} =\n",
    "      \\left( \\begin{array}{cccc} \n",
    "                d_{1} & e_{1} & 0     &  0    \\\\\n",
    "                e_{1} & d_{2} & e_{2} &  0    \\\\\n",
    "                 0    & e_{2} & d_{3} & e_{3} \\\\\n",
    "                 0    &   0   & e_{3} & d_{4} \n",
    "             \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2a60ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "As a first observation, if any of the elements $e_{i}$ are zero the\n",
    "matrix can be separated into smaller pieces before\n",
    "diagonalization. Specifically, if $e_{1} = 0$ then $d_{1}$ is an\n",
    "eigenvalue.\n",
    "\n",
    "Thus, let us introduce  a transformation $\\mathbf{S_{1}}$ which operates like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea96beb",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S_{1}} =\n",
    "      \\left( \\begin{array}{cccc} \n",
    "                \\cos \\theta & 0 & 0 & \\sin \\theta\\\\\n",
    "                 0       & 0 & 0 &      0      \\\\\n",
    "                   0        & 0 & 0 &      0      \\\\\n",
    "               \\cos \\theta & 0 & 0 & \\cos \\theta \n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d338f65",
   "metadata": {
    "editable": true
   },
   "source": [
    "Then the similarity transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074dc07f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{S_{1}^{T} A  S_{1}} = \\mathbf{A'} = \n",
    "      \\left( \\begin{array}{cccc}\n",
    "              d'_{1} & e'_{1} &   0    &   0   \\\\\n",
    "              e'_{1}  & d_{2}  & e_{2}  &   0   \\\\\n",
    "                0    & e_{2}  & d_{3}  & e'{3} \\\\\n",
    "                0    &   0    & e'_{3} & d'_{4}\n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79693420",
   "metadata": {
    "editable": true
   },
   "source": [
    "produces a matrix where the primed elements in $\\mathbf{A'}$ have been\n",
    "changed by the transformation whereas the unprimed elements are unchanged.\n",
    "\n",
    "If we now choose $\\theta$ to\n",
    "give the element $a_{21}^{'} = e^{'}= 0$ then we have the first\n",
    "eigenvalue  $= a_{11}^{'} = d_{1}^{'}$.\n",
    "\n",
    "This procedure can be continued on the remaining three-dimensional\n",
    "submatrix for the next eigenvalue. Thus after few transformations    \n",
    "we have the wanted diagonal form.\n",
    "\n",
    "What we see here is just a special case of the more general procedure \n",
    "developed by Francis in two articles in 1961 and 1962. Using Jacobi's method is not very efficient ether. \n",
    "\n",
    "The algorithm is based on the so-called **QR** method (or just **QR**-algorithm). It follows from a theorem by Schur which states that any square matrix can be written out in terms of an orthogonal matrix $\\hat{Q}$ and an upper triangular matrix $\\hat{U}$. Historically $R$ was used instead of \n",
    "$U$ since the wording right triangular matrix was first used.\n",
    "\n",
    "The method is based on an iterative procedure similar to Jacobi's method, by a succession of\n",
    "planar rotations. For a tridiagonal matrix it is simple to carry out in principle, but complicated in detail!\n",
    "\n",
    "Schur's theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d7752",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A} = \\hat{Q}\\hat{U},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e22dc",
   "metadata": {
    "editable": true
   },
   "source": [
    "is used to rewrite any square matrix into a unitary matrix times an upper triangular matrix.\n",
    "We say that a square matrix is similar to a triangular matrix. \n",
    "\n",
    "Householder's algorithm which we have derived is just a special case of the general Householder algorithm. For a symmetric square matrix we obtain a tridiagonal matrix. \n",
    "\n",
    "There is a corollary to Schur's theorem which states that every Hermitian matrix is unitarily similar to a diagonal matrix.\n",
    "\n",
    "It follows that we can define a new matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1cc0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{Q} = \\hat{Q}\\hat{U}\\hat{Q},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3580be",
   "metadata": {
    "editable": true
   },
   "source": [
    "and multiply from the left with $\\hat{Q}^{-1}$ we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a6446",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{Q}^{-1}\\hat{A}\\hat{Q} = \\hat{B}=\\hat{U}\\hat{Q},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a0e016",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the matrix $\\hat{B}$ is a similarity transformation of $\\hat{A}$ and has the same eigenvalues\n",
    "as $\\hat{B}$. \n",
    "\n",
    "Suppose $\\hat{A}$ is the triangular matrix we obtained after the Householder  transformation,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513b468",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A} = \\hat{Q}\\hat{U},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de592f7",
   "metadata": {
    "editable": true
   },
   "source": [
    "and multiply from the left with $\\hat{Q}^{-1}$ resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122ef5c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{Q}^{-1}\\hat{A} = \\hat{U}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b35ba",
   "metadata": {
    "editable": true
   },
   "source": [
    "Suppose that $\\hat{Q}$ consists of a series of planar Jacobi like rotations acting on sub blocks\n",
    "of $\\hat{A}$ so that all elements below the diagonal are zeroed out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282b67e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{Q}=\\hat{R}_{12}\\hat{R}_{23}\\dots\\hat{R}_{n-1,n}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5638c30",
   "metadata": {
    "editable": true
   },
   "source": [
    "A transformation of the type $\\hat{R}_{12}$ looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8310211",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{R}_{12} =\n",
    "      \\left( \\begin{array}{ccccccccc} \n",
    "                 c&s &0 &0 &0 &  \\dots &0 & 0 & 0\\\\\n",
    "                 -s&c &0 &0 &0 &   \\dots &0 & 0 & 0\\\\\n",
    "                 0&0 &1 &0 &0 &   \\dots &0 & 0 & 0\\\\\n",
    "                 \\dots&\\dots &\\dots &\\dots &\\dots &\\dots      \\\\\n",
    "                 0&0 &0 & 0 & 0 & \\dots &1 &0 &0      \\\\\n",
    "                 0&0 &0 & 0 & 0 & \\dots &0 &1 &0      \\\\\n",
    "                 0&0 &0 & 0 & 0 & \\dots &0 &0 & 1  \n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d97d1",
   "metadata": {
    "editable": true
   },
   "source": [
    "The matrix $\\hat{U}$ takes then the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d40e94",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{U} =\n",
    "      \\left( \\begin{array}{ccccccccc} \n",
    "                 x&x &x &0 &0 &  \\dots &0 & 0 & 0\\\\\n",
    "                 0&x &x &x &0 &   \\dots &0 & 0 & 0\\\\\n",
    "                 0&0 &x &x &x &   \\dots &0 & 0 & 0\\\\\n",
    "                 \\dots&\\dots &\\dots &\\dots &\\dots &\\dots      \\\\\n",
    "                 0&0 &0 & 0 & 0 & \\dots &x &x &x      \\\\\n",
    "                 0&0 &0 & 0 & 0 & \\dots &0 &x &x      \\\\\n",
    "                 0&0 &0 & 0 & 0 & \\dots &0 &0 & x  \n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8625f497",
   "metadata": {
    "editable": true
   },
   "source": [
    "which has a second superdiagonal.\n",
    "\n",
    "We have now found $\\hat{Q}$ and $\\hat{U}$ and this allows us to find the matrix $\\hat{B}$\n",
    "which is, due to Schur's theorem,  unitarily similar to a triangular matrix (upper in our case) \n",
    "since we have that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa289114",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{Q}^{-1}\\hat{A}\\hat{Q} = \\hat{B},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e85056",
   "metadata": {
    "editable": true
   },
   "source": [
    "from Schur's theorem the  matrix $\\hat{B}$ is triangular and the eigenvalues the same as those of \n",
    "$\\hat{A}$ and are given by the diagonal matrix elements of \n",
    "$\\hat{B}$. Why?  \n",
    "\n",
    "Our matrix $\\hat{B}=\\hat{U}\\hat{Q}$. \n",
    "\n",
    "The matrix $\\hat{A}$ is transformed into a tridiagonal form and the last\n",
    "step is to transform it into a diagonal matrix giving the eigenvalues\n",
    "on the diagonal. \n",
    "\n",
    "The eigenvalues of a  matrix can be obtained using the characteristic polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81334ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P(\\lambda) = det(\\lambda\\mathbf{I}-\\mathbf{A})= \\prod_{i=1}^{n}\\left(\\lambda_i-\\lambda\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e5c86",
   "metadata": {
    "editable": true
   },
   "source": [
    "which rewritten in matrix form reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ae3d8",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P(\\lambda)= \\left( \\begin{array}{ccccccc} d_1-\\lambda & e_1 & 0   & 0    & \\dots  &0     & 0 \\\\\n",
    "                                e_1 & d_2-\\lambda & e_2 & 0    & \\dots  &0     &0 \\\\\n",
    "                                0   & e_2 & d_3-\\lambda & e_3  &0       &\\dots & 0\\\\\n",
    "                                \\dots  & \\dots & \\dots & \\dots  &\\dots      &\\dots & \\dots\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &d_{N_{\\mathrm{step}}-2}-\\lambda & e_{N_{\\mathrm{step}}-1}\\\\\n",
    "                                0   & \\dots & \\dots & \\dots  &\\dots       &e_{N_{\\mathrm{step}}-1} & d_{N_{\\mathrm{step}}-1}-\\lambda\n",
    "             \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f18c9c",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can solve this equation in an iterative manner. \n",
    "We let $P_k(\\lambda)$ be the value of $k$ subdeterminant of the above matrix of dimension\n",
    "$n\\times n$. The polynomial $P_k(\\lambda)$ is clearly a polynomial of degree $k$.\n",
    "Starting with $P_1(\\lambda)$ we have $P_1(\\lambda)=d_1-\\lambda$. The next polynomial reads\n",
    "$P_2(\\lambda)=(d_2-\\lambda)P_1(\\lambda)-e_1^2$. By expanding the determinant for $P_k(\\lambda)$ \n",
    "in terms of the minors of the $n$th column we arrive at the recursion relation\n",
    "\\[ \n",
    "   P_k(\\lambda)=(d_k-\\lambda)P_{k-1}(\\lambda)-e_{k-1}^2P_{k-2}(\\lambda).\n",
    "\\]\n",
    "Together with the starting values $P_1(\\lambda)$ and $P_2(\\lambda)$ and good root searching methods\n",
    "we arrive at an efficient computational scheme for finding the roots of $P_n(\\lambda)$. \n",
    "However, for large matrices this algorithm is rather inefficient and time-consuming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d43825",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Lanczos' method\n",
    "\n",
    "Basic features with a real symmetric matrix (and normally huge $n> 10^6$ and sparse) \n",
    "$\\hat{A}$ of dimension $n\\times n$:\n",
    "\n",
    "* Lanczos' algorithm generates a sequence of real tridiagonal matrices $T_k$ of dimension $k\\times k$ with $k\\le n$, with the property that the extremal eigenvalues of $T_k$ are progressively better estimates of $\\hat{A}$' extremal eigenvalues.* The method converges to the extremal eigenvalues.\n",
    "\n",
    "* The similarity transformation is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364112d6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{T}= \\hat{Q}^{T}\\hat{A}\\hat{Q},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6e240",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the first vector $\\hat{Q}\\hat{e}_1=\\hat{q}_1$.\n",
    "\n",
    "We are going to solve iteratively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dc16dc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{T}= \\hat{Q}^{T}\\hat{A}\\hat{Q},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92655e4b",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the first vector $\\hat{Q}\\hat{e}_1=\\hat{q}_1$.\n",
    "We can write out the matrix $\\hat{Q}$ in terms of its column vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb42830",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{Q}=\\left[\\hat{q}_1\\hat{q}_2\\dots\\hat{q}_n\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf83a1",
   "metadata": {
    "editable": true
   },
   "source": [
    "The matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7522a73a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{T}= \\hat{Q}^{T}\\hat{A}\\hat{Q},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed17cf12",
   "metadata": {
    "editable": true
   },
   "source": [
    "can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948331e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{T} = \\left(\\begin{array}{cccccc}\n",
    "                           \\alpha_1& \\beta_1 & 0 &\\dots   & \\dots &0 \\\\\n",
    "                           \\beta_1 & \\alpha_2 & \\beta_2 &0 &\\dots &0 \\\\\n",
    "                           0& \\beta_2 & \\alpha_3 & \\beta_3 & \\dots &0 \\\\\n",
    "                           \\dots& \\dots   & \\dots &\\dots   &\\dots & 0 \\\\\n",
    "                           \\dots&   &  &\\beta_{n-2}  &\\alpha_{n-1}& \\beta_{n-1} \\\\\n",
    "                           0&  \\dots  &\\dots  &0   &\\beta_{n-1} & \\alpha_{n} \\\\\n",
    "                      \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273cda54",
   "metadata": {
    "editable": true
   },
   "source": [
    "Using the fact that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838c51c8",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{Q}\\hat{Q}^T=\\hat{I},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f42ec",
   "metadata": {
    "editable": true
   },
   "source": [
    "we can rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd96985",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{T}= \\hat{Q}^{T}\\hat{A}\\hat{Q},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be23fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d15e6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{Q}\\hat{T}= \\hat{A}\\hat{Q}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3eca61",
   "metadata": {
    "editable": true
   },
   "source": [
    "If we equate columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad404c06",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{T} = \\left(\\begin{array}{cccccc}\n",
    "        \\alpha_1& \\beta_1 & 0 &\\dots   & \\dots &0 \\\\\n",
    "        \\beta_1 & \\alpha_2 & \\beta_2 &0 &\\dots &0 \\\\\n",
    "        0& \\beta_2 & \\alpha_3 & \\beta_3 & \\dots &0 \\\\\n",
    "        \\dots& \\dots   & \\dots &\\dots   &\\dots & 0 \\\\\n",
    "        \\dots&   &  &\\beta_{n-2}  &\\alpha_{n-1}& \\beta_{n-1} \\\\\n",
    "        0&  \\dots  &\\dots  &0   &\\beta_{n-1} & \\alpha_{n} \\\\\n",
    "        \\end{array} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3901eb",
   "metadata": {
    "editable": true
   },
   "source": [
    "we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90dbc6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{q}_k=\\beta_{k-1}\\hat{q}_{k-1}+\\alpha_k\\hat{q}_k+\\beta_k\\hat{q}_{k+1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc266d",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have thus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048c6fc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{q}_k=\\beta_{k-1}\\hat{q}_{k-1}+\\alpha_k\\hat{q}_k+\\beta_k\\hat{q}_{k+1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03fb6b",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\beta_0\\hat{q}_0=0$ for $k=1:n-1$. Remember that the vectors $\\hat{q}_k$  are orthornormal and this implies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d695a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\alpha_k=\\hat{q}_k^T\\hat{A}\\hat{q}_k,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57454970",
   "metadata": {
    "editable": true
   },
   "source": [
    "and these vectors are called Lanczos vectors.\n",
    "\n",
    "We have thus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f1f3ab",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{q}_k=\\beta_{k-1}\\hat{q}_{k-1}+\\alpha_k\\hat{q}_k+\\beta_k\\hat{q}_{k+1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e01664",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\beta_0\\hat{q}_0=0$ for $k=1:n-1$ and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a8b66e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\alpha_k=\\hat{q}_k^T\\hat{A}\\hat{q}_k.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a6b3f",
   "metadata": {
    "editable": true
   },
   "source": [
    "If"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff68525",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{r}_k=(\\hat{A}-\\alpha_k\\hat{I})\\hat{q}_k-\\beta_{k-1}\\hat{q}_{k-1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577793b7",
   "metadata": {
    "editable": true
   },
   "source": [
    "is non-zero, then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccfe79",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{q}_{k+1}=\\hat{r}_{k}/\\beta_k,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f0e26f",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\beta_k=\\pm ||\\hat{r}_{k}||_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda21db",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Variational Monte Carlo methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e6b461",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Quantum Monte Carlo Motivation\n",
    "\n",
    "We start with the variational principle.\n",
    "Given a hamiltonian $H$ and a trial wave function $\\Psi_T$, the variational principle states that the expectation value of $\\langle H \\rangle$, defined through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189f831",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E[H]= \\langle H \\rangle =\n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})H(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d37fe7",
   "metadata": {
    "editable": true
   },
   "source": [
    "is an upper bound to the ground state energy $E_0$ of the hamiltonian $H$, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0d0c6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_0 \\le \\langle H \\rangle .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ebff5",
   "metadata": {
    "editable": true
   },
   "source": [
    "In general, the integrals involved in the calculation of various  expectation values  are multi-dimensional ones. Traditional integration methods such as the Gauss-Legendre will not be adequate for say the  computation of the energy of a many-body system.\n",
    "\n",
    "The trial wave function can be expanded in the eigenstates of the hamiltonian since they form a complete set, viz.,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946a808",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_T(\\boldsymbol{R})=\\sum_i a_i\\Psi_i(\\boldsymbol{R}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad911c",
   "metadata": {
    "editable": true
   },
   "source": [
    "and assuming the set of eigenfunctions to be normalized one obtains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ee045d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\sum_{nm}a^*_ma_n \\int d\\boldsymbol{R}\\Psi^{\\ast}_m(\\boldsymbol{R})H(\\boldsymbol{R})\\Psi_n(\\boldsymbol{R})}\n",
    "        {\\sum_{nm}a^*_ma_n \\int d\\boldsymbol{R}\\Psi^{\\ast}_m(\\boldsymbol{R})\\Psi_n(\\boldsymbol{R})} =\\frac{\\sum_{n}a^2_n E_n}\n",
    "        {\\sum_{n}a^2_n} \\ge E_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7543a71",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we used that $H(\\boldsymbol{R})\\Psi_n(\\boldsymbol{R})=E_n\\Psi_n(\\boldsymbol{R})$.\n",
    "In general, the integrals involved in the calculation of various  expectation\n",
    "values  are multi-dimensional ones. \n",
    "The variational principle yields the lowest state of a given symmetry.\n",
    "\n",
    "In most cases, a wave function has only small values in large parts of \n",
    "configuration space, and a straightforward procedure which uses\n",
    "homogenously distributed random points in configuration space \n",
    "will most likely lead to poor results. This may suggest that some kind\n",
    "of importance sampling combined with e.g., the Metropolis algorithm \n",
    "may be  a more efficient way of obtaining the ground state energy.\n",
    "The hope is then that those regions of configurations space where\n",
    "the wave function assumes appreciable values are sampled more \n",
    "efficiently. \n",
    "\n",
    "The tedious part in a VMC calculation is the search for the variational\n",
    "minimum. A good knowledge of the system is required in order to carry out\n",
    "reasonable VMC calculations. This is not always the case, \n",
    "and often VMC calculations \n",
    "serve rather as the starting\n",
    "point for so-called diffusion Monte Carlo calculations (DMC). DMC is a way of\n",
    "solving exactly the many-body Schroedinger equation by means of \n",
    "a stochastic procedure. A good guess on the binding energy\n",
    "and its wave function is however necessary. \n",
    "A carefully performed VMC calculation can aid in this context. \n",
    "\n",
    "The basic recipe in a VMC calculation consists of the following elements:\n",
    "\n",
    "* Construct first a trial wave function $\\psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})$,  for a many-body system consisting of $N$ particles located at positions  $\\boldsymbol{R}=(\\boldsymbol{R}_1,\\dots ,\\boldsymbol{R}_N)$. The trial wave function depends on $\\alpha$ variational parameters $\\boldsymbol{\\alpha}=(\\alpha_1,\\dots ,\\alpha_M)$.\n",
    "\n",
    "* Then we evaluate the expectation value of the hamiltonian $H$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cfdbd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E[H]=\\langle H \\rangle =\n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})H(\\boldsymbol{R})\\Psi_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})\\Psi_{T}(\\boldsymbol{R},\\boldsymbol{\\alpha})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1df6cbf",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Thereafter we vary $\\alpha$ according to some minimization algorithm and return to the first step.\n",
    "\n",
    "With a trial wave function $\\psi_T(\\boldsymbol{R})$ we can in turn construct the quantum mechanical probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39365aee",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P(\\boldsymbol{R})= \\frac{\\left|\\psi_T(\\boldsymbol{R})\\right|^2}{\\int \\left|\\psi_T(\\boldsymbol{R})\\right|^2d\\boldsymbol{R}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1195007",
   "metadata": {
    "editable": true
   },
   "source": [
    "This is our new probability distribution function  (PDF).\n",
    "The approximation to the expectation value of the Hamiltonian is now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e350e862",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E[H(\\boldsymbol{\\alpha})] = \n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R},\\boldsymbol{\\alpha})H(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R},\\boldsymbol{\\alpha})\\Psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a633a38",
   "metadata": {
    "editable": true
   },
   "source": [
    "Define a new quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1df3b",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:locale1\"></div>\n",
    "\n",
    "$$\n",
    "E_L(\\boldsymbol{R},\\boldsymbol{\\alpha})=\\frac{1}{\\psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha})}H\\psi_T(\\boldsymbol{R},\\boldsymbol{\\alpha}),\n",
    "\\label{eq:locale1} \\tag{6}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ebfa0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "called the local energy, which, together with our trial PDF yields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd85632",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:vmc1\"></div>\n",
    "\n",
    "$$\n",
    "E[H(\\boldsymbol{\\alpha})]=\\int P(\\boldsymbol{R})E_L(\\boldsymbol{R}) d\\boldsymbol{R}\\approx \\frac{1}{N}\\sum_{i=1}^NP(\\boldsymbol{R_i},\\boldsymbol{\\alpha})E_L(\\boldsymbol{R_i},\\boldsymbol{\\alpha})\n",
    "\\label{eq:vmc1} \\tag{7}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927e16a",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $N$ being the number of Monte Carlo samples.\n",
    "\n",
    "The Algorithm for performing a variational Monte Carlo calculations runs thus as this\n",
    "\n",
    "   * Initialisation: Fix the number of Monte Carlo steps. Choose an initial $\\boldsymbol{R}$ and variational parameters $\\alpha$ and calculate $\\left|\\psi_T^{\\alpha}(\\boldsymbol{R})\\right|^2$. \n",
    "\n",
    "   * Initialise the energy and the variance and start the Monte Carlo calculation.\n",
    "\n",
    "      * Calculate  a trial position  $\\boldsymbol{R}_p=\\boldsymbol{R}+r*step$ where $r$ is a random variable $r \\in [0,1]$.\n",
    "\n",
    "      * Metropolis algorithm to accept or reject this move  $w = P(\\boldsymbol{R}_p)/P(\\boldsymbol{R})$.\n",
    "\n",
    "      * If the step is accepted, then we set $\\boldsymbol{R}=\\boldsymbol{R}_p$. \n",
    "\n",
    "      * Update averages\n",
    "\n",
    "   * Finish and compute final averages.\n",
    "\n",
    "Observe that the jumping in space is governed by the variable *step*. This is Called brute-force sampling.\n",
    "Need importance sampling to get more relevant sampling, see lectures below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37c0e1",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Quantum Monte Carlo: hydrogen atom\n",
    "\n",
    "The radial Schroedinger equation for the hydrogen atom can be\n",
    "written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92785796",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{\\hbar^2}{2m}\\frac{\\partial^2 u(r)}{\\partial r^2}-\n",
    "\\left(\\frac{ke^2}{r}-\\frac{\\hbar^2l(l+1)}{2mr^2}\\right)u(r)=Eu(r),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168d0e6",
   "metadata": {
    "editable": true
   },
   "source": [
    "or with dimensionless variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7a2db2",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:hydrodimless1\"></div>\n",
    "\n",
    "$$\n",
    "-\\frac{1}{2}\\frac{\\partial^2 u(\\rho)}{\\partial \\rho^2}-\n",
    "\\frac{u(\\rho)}{\\rho}+\\frac{l(l+1)}{2\\rho^2}u(\\rho)-\\lambda u(\\rho)=0,\n",
    "\\label{eq:hydrodimless1} \\tag{8}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182186f",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755eb769",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "H=-\\frac{1}{2}\\frac{\\partial^2 }{\\partial \\rho^2}-\n",
    "\\frac{1}{\\rho}+\\frac{l(l+1)}{2\\rho^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6d101f",
   "metadata": {
    "editable": true
   },
   "source": [
    "Use variational parameter $\\alpha$ in the trial\n",
    "wave function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9937d2",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:trialhydrogen\"></div>\n",
    "\n",
    "$$\n",
    "u_T^{\\alpha}(\\rho)=\\alpha\\rho e^{-\\alpha\\rho}. \n",
    "\\label{eq:trialhydrogen} \\tag{9}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbe9b6",
   "metadata": {
    "editable": true
   },
   "source": [
    "Inserting this wave function into the expression for the\n",
    "local energy $E_L$ gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80124b2e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_L(\\rho)=-\\frac{1}{\\rho}-\n",
    "              \\frac{\\alpha}{2}\\left(\\alpha-\\frac{2}{\\rho}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae23721",
   "metadata": {
    "editable": true
   },
   "source": [
    "A simple variational Monte Carlo calculation results in\n",
    "<table class=\"dotable\" border=\"1\">\n",
    "<thead>\n",
    "<tr><th align=\"center\">  $\\alpha$ </th> <th align=\"center\">$\\langle H \\rangle $</th> <th align=\"center\"> $\\sigma^2$</th> <th align=\"center\">$\\sigma/\\sqrt{N}$</th> </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td align=\"center\">   7.00000E-01    </td> <td align=\"center\">   -4.57759E-01            </td> <td align=\"center\">   4.51201E-02    </td> <td align=\"center\">   6.71715E-04          </td> </tr>\n",
    "<tr><td align=\"center\">   8.00000E-01    </td> <td align=\"center\">   -4.81461E-01            </td> <td align=\"center\">   3.05736E-02    </td> <td align=\"center\">   5.52934E-04          </td> </tr>\n",
    "<tr><td align=\"center\">   9.00000E-01    </td> <td align=\"center\">   -4.95899E-01            </td> <td align=\"center\">   8.20497E-03    </td> <td align=\"center\">   2.86443E-04          </td> </tr>\n",
    "<tr><td align=\"center\">   1.00000E-00    </td> <td align=\"center\">   -5.00000E-01            </td> <td align=\"center\">   0.00000E+00    </td> <td align=\"center\">   0.00000E+00          </td> </tr>\n",
    "<tr><td align=\"center\">   1.10000E+00    </td> <td align=\"center\">   -4.93738E-01            </td> <td align=\"center\">   1.16989E-02    </td> <td align=\"center\">   3.42036E-04          </td> </tr>\n",
    "<tr><td align=\"center\">   1.20000E+00    </td> <td align=\"center\">   -4.75563E-01            </td> <td align=\"center\">   8.85899E-02    </td> <td align=\"center\">   9.41222E-04          </td> </tr>\n",
    "<tr><td align=\"center\">   1.30000E+00    </td> <td align=\"center\">   -4.54341E-01            </td> <td align=\"center\">   1.45171E-01    </td> <td align=\"center\">   1.20487E-03          </td> </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "We note that at $\\alpha=1$ we obtain the exact\n",
    "result, and the variance is zero, as it should. The reason is that \n",
    "we then have the exact wave function, and the action of the hamiltionan\n",
    "on the wave function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849a4f2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "H\\psi = \\mathrm{constant}\\times \\psi,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395eb9b",
   "metadata": {
    "editable": true
   },
   "source": [
    "yields just a constant. The integral which defines various \n",
    "expectation values involving moments of the hamiltonian becomes then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebbc0e8",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle H^n \\rangle =\n",
    "   \\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})H^n(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}=\n",
    "\\mathrm{constant}\\times\\frac{\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}\n",
    "        {\\int d\\boldsymbol{R}\\Psi^{\\ast}_T(\\boldsymbol{R})\\Psi_T(\\boldsymbol{R})}=\\mathrm{constant}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d617f8",
   "metadata": {
    "editable": true
   },
   "source": [
    "**This gives an important information: the exact wave function leads to zero variance!**\n",
    "Variation is then performed by minimizing both the energy and the variance.\n",
    "\n",
    "For bosons in a harmonic oscillator-like  trap we will use is a spherical (S)\n",
    " or an elliptical (E) harmonic trap in one, two and finally three\n",
    " dimensions, with the latter given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d1584",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"trap_eqn\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " V_{ext}(\\mathbf{r}) = \\Bigg\\{\n",
    " \\begin{array}{ll}\n",
    "\t \\frac{1}{2}m\\omega_{ho}^2r^2 & (S)\\\\\n",
    " \\strut\n",
    "\t \\frac{1}{2}m[\\omega_{ho}^2(x^2+y^2) + \\omega_z^2z^2] & (E)\n",
    "\\label{trap_eqn} \\tag{10}\n",
    " \\end{array}\n",
    " \\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db364cae",
   "metadata": {
    "editable": true
   },
   "source": [
    "where (S) stands for symmetric and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928dc9ce",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "     \\hat{H} = \\sum_i^N \\left(\n",
    "\t \\frac{-\\hbar^2}{2m}\n",
    "\t { \\bigtriangledown }_{i}^2 +\n",
    "\t V_{ext}({\\bf{r}}_i)\\right)  +\n",
    "\t \\sum_{i<j}^{N} V_{int}({\\bf{r}}_i,{\\bf{r}}_j),\n",
    "\\label{_auto1} \\tag{11}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9156d8c2",
   "metadata": {
    "editable": true
   },
   "source": [
    "as the two-body Hamiltonian of the system.  \n",
    "\n",
    " We will represent the inter-boson interaction by a pairwise, repulsive potential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec13df",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " V_{int}(|\\mathbf{r}_i-\\mathbf{r}_j|) =  \\Bigg\\{\n",
    " \\begin{array}{ll}\n",
    "\t \\infty & {|\\mathbf{r}_i-\\mathbf{r}_j|} \\leq {a}\\\\\n",
    "\t 0 & {|\\mathbf{r}_i-\\mathbf{r}_j|} > {a}\n",
    " \\end{array}\n",
    "\\label{_auto2} \\tag{12}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dceed7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $a$ is the so-called hard-core diameter of the bosons.\n",
    " Clearly, $V_{int}(|\\mathbf{r}_i-\\mathbf{r}_j|)$ is zero if the bosons are\n",
    " separated by a distance $|\\mathbf{r}_i-\\mathbf{r}_j|$ greater than $a$ but\n",
    " infinite if they attempt to come within a distance $|\\mathbf{r}_i-\\mathbf{r}_j| \\leq a$.\n",
    "\n",
    " Our trial wave function for the ground state with $N$ atoms is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a8a430",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:trialwf\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    " \\Psi_T(\\mathbf{R})=\\Psi_T(\\mathbf{r}_1, \\mathbf{r}_2, \\dots \\mathbf{r}_N,\\alpha,\\beta)=\\prod_i g(\\alpha,\\beta,\\mathbf{r}_i)\\prod_{i<j}f(a,|\\mathbf{r}_i-\\mathbf{r}_j|),\n",
    "\\label{eq:trialwf} \\tag{13}\n",
    " \\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f631b",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\alpha$ and $\\beta$ are variational parameters. The\n",
    " single-particle wave function is proportional to the harmonic\n",
    " oscillator function for the ground state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472e44c1",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    g(\\alpha,\\beta,\\mathbf{r}_i)= \\exp{[-\\alpha(x_i^2+y_i^2+\\beta z_i^2)]}.\n",
    "\\label{_auto3} \\tag{14}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e6f0e",
   "metadata": {
    "editable": true
   },
   "source": [
    "For spherical traps we have $\\beta = 1$ and for non-interacting\n",
    "bosons ($a=0$) we have $\\alpha = 1/2a_{ho}^2$.  The correlation wave\n",
    " function is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e2320",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    f(a,|\\mathbf{r}_i-\\mathbf{r}_j|)=\\Bigg\\{\n",
    " \\begin{array}{ll}\n",
    "\t 0 & {|\\mathbf{r}_i-\\mathbf{r}_j|} \\leq {a}\\\\\n",
    "\t (1-\\frac{a}{|\\mathbf{r}_i-\\mathbf{r}_j|}) & {|\\mathbf{r}_i-\\mathbf{r}_j|} > {a}.\n",
    " \\end{array}\n",
    "\\label{_auto4} \\tag{15}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8660956",
   "metadata": {
    "editable": true
   },
   "source": [
    "### A simple Python code that solves the two-boson or two-fermion case in two-dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "572e87a8",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Importing various packages\n",
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "\n",
    "#Trial wave function for quantum dots in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "#Local energy  for quantum dots in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# The Monte Carlo sampling with the Metropolis algo\n",
    "def MonteCarloSampling():\n",
    "\n",
    "    NumberMCcycles= 100000\n",
    "    StepSize = 1.0\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # seed for rng generator\n",
    "    seed()\n",
    "    # start variational parameter\n",
    "    alpha = 0.9\n",
    "    for ia in range(MaxVariations):\n",
    "        alpha += .025\n",
    "        AlphaValues[ia] = alpha\n",
    "        beta = 0.2 \n",
    "        for jb in range(MaxVariations):\n",
    "            beta += .01\n",
    "            BetaValues[jb] = beta\n",
    "            energy = energy2 = 0.0\n",
    "            DeltaE = 0.0\n",
    "            #Initial position\n",
    "            for i in range(NumberParticles):\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = StepSize * (random() - .5)\n",
    "            wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "\n",
    "            #Loop over MC MCcycles\n",
    "            for MCcycle in range(NumberMCcycles):\n",
    "                #Trial position\n",
    "                for i in range(NumberParticles):\n",
    "                    for j in range(Dimension):\n",
    "                        PositionNew[i,j] = PositionOld[i,j] + StepSize * (random() - .5)\n",
    "                wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "\n",
    "                #Metropolis test to see whether we accept the move\n",
    "                if random() < wfnew**2 / wfold**2:\n",
    "                   PositionOld = PositionNew.copy()\n",
    "                   wfold = wfnew\n",
    "                   DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "                energy += DeltaE\n",
    "                energy2 += DeltaE**2\n",
    "\n",
    "            #We calculate mean, variance and error ...\n",
    "            energy /= NumberMCcycles\n",
    "            energy2 /= NumberMCcycles\n",
    "            variance = energy2 - energy**2\n",
    "            error = sqrt(variance/NumberMCcycles)\n",
    "            Energies[ia,jb] = energy    \n",
    "    return Energies, AlphaValues, BetaValues\n",
    "\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "MaxVariations = 10\n",
    "Energies = np.zeros((MaxVariations,MaxVariations))\n",
    "AlphaValues = np.zeros(MaxVariations)\n",
    "BetaValues = np.zeros(MaxVariations)\n",
    "(Energies, AlphaValues, BetaValues) = MonteCarloSampling()\n",
    "\n",
    "# Prepare for plots\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "X, Y = np.meshgrid(AlphaValues, BetaValues)\n",
    "surf = ax.plot_surface(X, Y, Energies,cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "# Customize the z axis.\n",
    "zmin = np.matrix(Energies).min()\n",
    "zmax = np.matrix(Energies).max()\n",
    "ax.set_zlim(zmin, zmax)\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.set_zlabel(r'$\\langle E \\rangle$')\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58d9791",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Quantum Monte Carlo: the helium atom\n",
    "\n",
    "The helium atom consists of two electrons and a nucleus with\n",
    "charge $Z=2$. \n",
    "The contribution  \n",
    "to the potential energy due to the attraction from the nucleus is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee72b81",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\frac{2ke^2}{r_1}-\\frac{2ke^2}{r_2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fe2ab",
   "metadata": {
    "editable": true
   },
   "source": [
    "and if we add the repulsion arising from the two \n",
    "interacting electrons, we obtain the potential energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77958111",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "V(r_1, r_2)=-\\frac{2ke^2}{r_1}-\\frac{2ke^2}{r_2}+\n",
    "               \\frac{ke^2}{r_{12}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aded0ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the electrons separated at a distance \n",
    "$r_{12}=|\\boldsymbol{r}_1-\\boldsymbol{r}_2|$.\n",
    "\n",
    "The hamiltonian becomes then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3588037",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{H}=-\\frac{\\hbar^2\\nabla_1^2}{2m}-\\frac{\\hbar^2\\nabla_2^2}{2m}\n",
    "          -\\frac{2ke^2}{r_1}-\\frac{2ke^2}{r_2}+\n",
    "               \\frac{ke^2}{r_{12}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ed661",
   "metadata": {
    "editable": true
   },
   "source": [
    "and  Schroedingers equation reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbcc4ff",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{H}\\psi=E\\psi.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec139d6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "All observables are evaluated with respect to the probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ebf0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P(\\boldsymbol{R})= \\frac{\\left|\\psi_T(\\boldsymbol{R})\\right|^2}{\\int \\left|\\psi_T(\\boldsymbol{R})\\right|^2d\\boldsymbol{R}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45260ee2",
   "metadata": {
    "editable": true
   },
   "source": [
    "generated by the trial wave function.   \n",
    "The trial wave function must approximate an exact \n",
    "eigenstate in order that accurate results are to be obtained. \n",
    "\n",
    "Choice of trial wave function for Helium:\n",
    "Assume $r_1 \\rightarrow 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc9cef",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_L(\\boldsymbol{R})=\\frac{1}{\\psi_T(\\boldsymbol{R})}H\\psi_T(\\boldsymbol{R})=\n",
    "     \\frac{1}{\\psi_T(\\boldsymbol{R})}\\left(-\\frac{1}{2}\\nabla^2_1\n",
    "     -\\frac{Z}{r_1}\\right)\\psi_T(\\boldsymbol{R}) + \\mathrm{finite \\hspace{0.1cm}terms}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd860d8c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_L(R)=\n",
    "    \\frac{1}{\\mathbf{R}_T(r_1)}\\left(-\\frac{1}{2}\\frac{d^2}{dr_1^2}-\n",
    "     \\frac{1}{r_1}\\frac{d}{dr_1}\n",
    "     -\\frac{Z}{r_1}\\right)\\mathbf{R}_T(r_1) + \\mathrm{finite\\hspace{0.1cm} terms}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c70bb",
   "metadata": {
    "editable": true
   },
   "source": [
    "For small values of $r_1$, the terms which dominate are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722cb906",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\lim_{r_1 \\rightarrow 0}E_L(R)=\n",
    "    \\frac{1}{\\mathbf{R}_T(r_1)}\\left(-\n",
    "     \\frac{1}{r_1}\\frac{d}{dr_1}\n",
    "     -\\frac{Z}{r_1}\\right)\\mathbf{R}_T(r_1),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d3ae0",
   "metadata": {
    "editable": true
   },
   "source": [
    "since the second derivative does not diverge due to the finiteness of  $\\Psi$ at the origin.\n",
    "\n",
    "This results in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e3564",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\mathbf{R}_T(r_1)}\\frac{d \\mathbf{R}_T(r_1)}{dr_1}=-Z,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00c543",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e794020f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{R}_T(r_1)\\propto e^{-Zr_1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d24bb7",
   "metadata": {
    "editable": true
   },
   "source": [
    "A similar condition applies to electron 2 as well. \n",
    "For orbital momenta $l > 0$ we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1e046",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\mathbf{R}_T(r)}\\frac{d \\mathbf{R}_T(r)}{dr}=-\\frac{Z}{l+1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df3171",
   "metadata": {
    "editable": true
   },
   "source": [
    "Similarly, studying the case $r_{12}\\rightarrow 0$ we can write \n",
    "a possible trial wave function as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7738745",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:wavehelium2\"></div>\n",
    "\n",
    "$$\n",
    "\\psi_T(\\boldsymbol{R})=e^{-\\alpha(r_1+r_2)}e^{\\beta r_{12}}.\n",
    "\\label{eq:wavehelium2} \\tag{16}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d5b42",
   "metadata": {
    "editable": true
   },
   "source": [
    "The last equation can be generalized to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efbb55",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\psi_T(\\boldsymbol{R})=\\phi(\\boldsymbol{r}_1)\\phi(\\boldsymbol{r}_2)\\dots\\phi(\\boldsymbol{r}_N)\n",
    "                   \\prod_{i < j}f(r_{ij}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9bc6b7",
   "metadata": {
    "editable": true
   },
   "source": [
    "for a system with $N$ electrons or particles. \n",
    "\n",
    "During the development of our code we need to make several checks. It is also very instructive to compute a closed form expression for the local energy. Since our wave function is rather simple  it is straightforward\n",
    "to find an analytic expressions.  Consider first the case of the simple helium function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaee1684",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_T(\\boldsymbol{r}_1,\\boldsymbol{r}_2) = e^{-\\alpha(r_1+r_2)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0dd0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "The local energy is for this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd3780",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_{L1} = \\left(\\alpha-Z\\right)\\left(\\frac{1}{r_1}+\\frac{1}{r_2}\\right)+\\frac{1}{r_{12}}-\\alpha^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca27517",
   "metadata": {
    "editable": true
   },
   "source": [
    "which gives an expectation value for the local energy given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e08ffcf",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle E_{L1} \\rangle = \\alpha^2-2\\alpha\\left(Z-\\frac{5}{16}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c350ec6",
   "metadata": {
    "editable": true
   },
   "source": [
    "With closed form formulae we  can speed up the computation of the correlation. In our case\n",
    "we write it as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b65a08",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_C= \\exp{\\left\\{\\sum_{i < j}\\frac{ar_{ij}}{1+\\beta r_{ij}}\\right\\}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c62e4",
   "metadata": {
    "editable": true
   },
   "source": [
    "which means that the gradient needed for the so-called quantum force and local energy \n",
    "can be calculated analytically.\n",
    "This will speed up your code since the computation of the correlation part and the Slater determinant are the most \n",
    "time consuming parts in your code.  \n",
    "\n",
    "We will refer to this correlation function as $\\Psi_C$ or the *linear Pade-Jastrow*.\n",
    "\n",
    "We can test this by computing the local energy for our helium wave function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153b28a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\psi_{T}(\\boldsymbol{r}_1,\\boldsymbol{r}_2) = \n",
    "   \\exp{\\left(-\\alpha(r_1+r_2)\\right)}\n",
    "   \\exp{\\left(\\frac{r_{12}}{2(1+\\beta r_{12})}\\right)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35425e67",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\alpha$ and $\\beta$ as variational parameters.\n",
    "\n",
    "The local energy is for this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3972c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_{L2} = E_{L1}+\\frac{1}{2(1+\\beta r_{12})^2}\\left\\{\\frac{\\alpha(r_1+r_2)}{r_{12}}(1-\\frac{\\boldsymbol{r}_1\\boldsymbol{r}_2}{r_1r_2})-\\frac{1}{2(1+\\beta r_{12})^2}-\\frac{2}{r_{12}}+\\frac{2\\beta}{1+\\beta r_{12}}\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede2503",
   "metadata": {
    "editable": true
   },
   "source": [
    "It is very useful to test your code against these expressions. It means also that you don't need to\n",
    "compute a derivative numerically as discussed in the code example below. \n",
    "\n",
    "For the computation of various derivatives with different types of wave functions, you will find it useful to use python with symbolic python, that is sympy, see [online manual](http://docs.sympy.org/latest/index.html).  Using sympy allows you autogenerate both Latex code as well c++, python or Fortran codes. Here you will find some simple examples. We choose \n",
    "the $2s$ hydrogen-orbital  (not normalized) as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952abcc3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\phi_{2s}(\\boldsymbol{r}) = (Zr - 2)\\exp{-(\\frac{1}{2}Zr)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c8fdc",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $ r^2 = x^2 + y^2 + z^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5dda523",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sympy import symbols, diff, exp, sqrt\n",
    "x, y, z, Z = symbols('x y z Z')\n",
    "r = sqrt(x*x + y*y + z*z)\n",
    "r\n",
    "phi = (Z*r - 2)*exp(-Z*r/2)\n",
    "phi\n",
    "diff(phi, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c8f44",
   "metadata": {
    "editable": true
   },
   "source": [
    "This doesn't look very nice, but sympy provides several functions that allow for improving and simplifying the output.\n",
    "\n",
    "We can improve our output by factorizing and substituting expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de11a4bc",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sympy import symbols, diff, exp, sqrt, factor, Symbol, printing\n",
    "x, y, z, Z = symbols('x y z Z')\n",
    "r = sqrt(x*x + y*y + z*z)\n",
    "phi = (Z*r - 2)*exp(-Z*r/2)\n",
    "R = Symbol('r') #Creates a symbolic equivalent of r\n",
    "#print latex and c++ code\n",
    "print printing.latex(diff(phi, x).factor().subs(r, R))\n",
    "print printing.ccode(diff(phi, x).factor().subs(r, R))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c35de0c",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can in turn look at second derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b79deb1",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sympy import symbols, diff, exp, sqrt, factor, Symbol, printing\n",
    "x, y, z, Z = symbols('x y z Z')\n",
    "r = sqrt(x*x + y*y + z*z)\n",
    "phi = (Z*r - 2)*exp(-Z*r/2)\n",
    "R = Symbol('r') #Creates a symbolic equivalent of r\n",
    "(diff(diff(phi, x), x) + diff(diff(phi, y), y) + diff(diff(phi, z), z)).factor().subs(r, R)\n",
    "# Collect the Z values\n",
    "(diff(diff(phi, x), x) + diff(diff(phi, y), y) +diff(diff(phi, z), z)).factor().collect(Z).subs(r, R)\n",
    "# Factorize also the r**2 terms\n",
    "(diff(diff(phi, x), x) + diff(diff(phi, y), y) + diff(diff(phi, z), z)).factor().collect(Z).subs(r, R).subs(r**2, R**2).factor()\n",
    "print printing.ccode((diff(diff(phi, x), x) + diff(diff(phi, y), y) + diff(diff(phi, z), z)).factor().collect(Z).subs(r, R).subs(r**2, R**2).factor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2324f2",
   "metadata": {
    "editable": true
   },
   "source": [
    "With some practice this allows one to be able to check one's own calculation and translate automatically into code lines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f7f86b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The Metropolis algorithm\n",
    "\n",
    "The Metropolis algorithm , see [the original article](http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.1699114) was invented by Metropolis et. al\n",
    "and is often simply called the Metropolis algorithm.\n",
    "It is a method to sample a normalized probability\n",
    "distribution by a stochastic process. We define $\\mathbf{P}_i^{(n)}$ to\n",
    "be the probability for finding the system in the state $i$ at step $n$.\n",
    "The algorithm is then\n",
    "\n",
    "* Sample a possible new state $j$ with some probability $T_{i\\rightarrow j}$.\n",
    "\n",
    "* Accept the new state $j$ with probability $A_{i \\rightarrow j}$ and use it as the next sample. With probability $1-A_{i\\rightarrow j}$ the move is rejected and the original state $i$ is used again as a sample.\n",
    "\n",
    "We wish to derive the required properties of $T$ and $A$ such that\n",
    "$\\mathbf{P}_i^{(n\\rightarrow \\infty)} \\rightarrow p_i$ so that starting\n",
    "from any distribution, the method converges to the correct distribution.\n",
    "Note that the description here is for a discrete probability distribution.\n",
    "Replacing probabilities $p_i$ with expressions like $p(x_i)dx_i$ will\n",
    "take all of these over to the corresponding continuum expressions.\n",
    "\n",
    "The dynamical equation for $\\mathbf{P}_i^{(n)}$ can be written directly from\n",
    "the description above. The probability of being in the state $i$ at step $n$\n",
    "is given by the probability of being in any state $j$ at the previous step,\n",
    "and making an accepted transition to $i$ added to the probability of\n",
    "being in the state $i$, making a transition to any state $j$ and\n",
    "rejecting the move:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32ccd0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{P}^{(n)}_i = \\sum_j \\left [\n",
    "\\mathbf{P}^{(n-1)}_jT_{j\\rightarrow i} A_{j\\rightarrow i} \n",
    "+\\mathbf{P}^{(n-1)}_iT_{i\\rightarrow j}\\left ( 1- A_{i\\rightarrow j} \\right)\n",
    "\\right ] \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec05bd9a",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since the probability of making some transition must be 1,\n",
    "$\\sum_j T_{i\\rightarrow j} = 1$, and the above equation becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcefa2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{P}^{(n)}_i = \\mathbf{P}^{(n-1)}_i +\n",
    " \\sum_j \\left [\n",
    "\\mathbf{P}^{(n-1)}_jT_{j\\rightarrow i} A_{j\\rightarrow i} \n",
    "-\\mathbf{P}^{(n-1)}_iT_{i\\rightarrow j}A_{i\\rightarrow j}\n",
    "\\right ] \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabdd47",
   "metadata": {
    "editable": true
   },
   "source": [
    "For large $n$ we require that $\\mathbf{P}^{(n\\rightarrow \\infty)}_i = p_i$,\n",
    "the desired probability distribution. Taking this limit, gives the\n",
    "balance requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d895c2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sum_j \\left [\n",
    "p_jT_{j\\rightarrow i} A_{j\\rightarrow i}\n",
    "-p_iT_{i\\rightarrow j}A_{i\\rightarrow j}\n",
    "\\right ] = 0 \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18444767",
   "metadata": {
    "editable": true
   },
   "source": [
    "The balance requirement is very weak. Typically the much stronger detailed\n",
    "balance requirement is enforced, that is rather than the sum being\n",
    "set to zero, we set each term separately to zero and use this\n",
    "to determine the acceptance probabilities. Rearranging, the result is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00647d3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{ A_{j\\rightarrow i}}{A_{i\\rightarrow j}}\n",
    "= \\frac{p_iT_{i\\rightarrow j}}{ p_jT_{j\\rightarrow i}} \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76836c5",
   "metadata": {
    "editable": true
   },
   "source": [
    "The Metropolis choice is to maximize the $A$ values, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52fec61",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "A_{j \\rightarrow i} = \\min \\left ( 1,\n",
    "\\frac{p_iT_{i\\rightarrow j}}{ p_jT_{j\\rightarrow i}}\\right ).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b8f43",
   "metadata": {
    "editable": true
   },
   "source": [
    "Other choices are possible, but they all correspond to multilplying\n",
    "$A_{i\\rightarrow j}$ and $A_{j\\rightarrow i}$ by the same constant\n",
    "smaller than unity.\\footnote{The penalty function method uses just such\n",
    "a factor to compensate for $p_i$ that are evaluated stochastically\n",
    "and are therefore noisy.}\n",
    "\n",
    "Having chosen the acceptance probabilities, we have guaranteed that\n",
    "if the  $\\mathbf{P}_i^{(n)}$ has equilibrated, that is if it is equal to $p_i$,\n",
    "it will remain equilibrated. Next we need to find the circumstances for\n",
    "convergence to equilibrium.\n",
    "\n",
    "The dynamical equation can be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5185f2c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{P}^{(n)}_i = \\sum_j M_{ij}\\mathbf{P}^{(n-1)}_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c4a530",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the matrix $M$ given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ebf74",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "M_{ij} = \\delta_{ij}\\left [ 1 -\\sum_k T_{i\\rightarrow k} A_{i \\rightarrow k}\n",
    "\\right ] + T_{j\\rightarrow i} A_{j\\rightarrow i} \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc37e7",
   "metadata": {
    "editable": true
   },
   "source": [
    "Summing over $i$ shows that $\\sum_i M_{ij} = 1$, and since\n",
    "$\\sum_k T_{i\\rightarrow k} = 1$, and $A_{i \\rightarrow k} \\leq 1$, the\n",
    "elements of the matrix satisfy $M_{ij} \\geq 0$. The matrix $M$ is therefore\n",
    "a stochastic matrix.\n",
    "\n",
    "The Metropolis method is simply the power method for computing the\n",
    "right eigenvector of $M$ with the largest magnitude eigenvalue.\n",
    "By construction, the correct probability distribution is a right eigenvector\n",
    "with eigenvalue 1. Therefore, for the Metropolis method to converge\n",
    "to this result, we must show that $M$ has only one eigenvalue with this\n",
    "magnitude, and all other eigenvalues are smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f34a70",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Importance sampling\n",
    "\n",
    "We need to replace the brute force\n",
    "Metropolis algorithm with a walk in coordinate space biased by the trial wave function.\n",
    "This approach is based on the Fokker-Planck equation and the Langevin equation for generating a trajectory in coordinate space.  The link between the Fokker-Planck equation and the Langevin equations are explained, only partly, in the slides below.\n",
    "An excellent reference on topics like Brownian motion, Markov chains, the Fokker-Planck equation and the Langevin equation is the text by  [Van Kampen](http://www.elsevier.com/books/stochastic-processes-in-physics-and-chemistry/van-kampen/978-0-444-52965-7)\n",
    "Here we will focus first on the implementation part first.\n",
    "\n",
    "For a diffusion process characterized by a time-dependent probability density $P(x,t)$ in one dimension the Fokker-Planck\n",
    "equation reads (for one particle /walker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af2f4d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial P}{\\partial t} = D\\frac{\\partial }{\\partial x}\\left(\\frac{\\partial }{\\partial x} -F\\right)P(x,t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8a82e",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $F$ is a drift term and $D$ is the diffusion coefficient. \n",
    "\n",
    "The new positions in coordinate space are given as the solutions of the Langevin equation using Euler's method, namely,\n",
    "we go from the Langevin equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62984978",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial x(t)}{\\partial t} = DF(x(t)) +\\eta,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180dee2f",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\eta$ a random variable,\n",
    "yielding a new position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8b89f8",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "y = x+DF(x)\\Delta t +\\xi\\sqrt{\\Delta t},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9491936",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\xi$ is gaussian random variable and $\\Delta t$ is a chosen time step. \n",
    "The quantity $D$ is, in atomic units, equal to $1/2$ and comes from the factor $1/2$ in the kinetic energy operator. Note that $\\Delta t$ is to be viewed as a parameter. Values of $\\Delta t \\in [0.001,0.01]$ yield in general rather stable values of the ground state energy.  \n",
    "\n",
    "The process of isotropic diffusion characterized by a time-dependent probability density $P(\\mathbf{x},t)$ obeys (as an approximation) the so-called Fokker-Planck equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d0e43b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial P}{\\partial t} = \\sum_i D\\frac{\\partial }{\\partial \\mathbf{x_i}}\\left(\\frac{\\partial }{\\partial \\mathbf{x_i}} -\\mathbf{F_i}\\right)P(\\mathbf{x},t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b309bd5",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\mathbf{F_i}$ is the $i^{th}$ component of the drift term (drift velocity) caused by an external potential, and $D$ is the diffusion coefficient. The convergence to a stationary probability density can be obtained by setting the left hand side to zero. The resulting equation will be satisfied if and only if all the terms of the sum are equal zero,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff60e23c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial^2 P}{\\partial {\\mathbf{x_i}^2}} = P\\frac{\\partial}{\\partial {\\mathbf{x_i}}}\\mathbf{F_i} + \\mathbf{F_i}\\frac{\\partial}{\\partial {\\mathbf{x_i}}}P.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197828f",
   "metadata": {
    "editable": true
   },
   "source": [
    "The drift vector should be of the form $\\mathbf{F} = g(\\mathbf{x}) \\frac{\\partial P}{\\partial \\mathbf{x}}$. Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e017f16",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial^2 P}{\\partial {\\mathbf{x_i}^2}} = P\\frac{\\partial g}{\\partial P}\\left( \\frac{\\partial P}{\\partial {\\mathbf{x}_i}}  \\right)^2 + P g \\frac{\\partial ^2 P}{\\partial {\\mathbf{x}_i^2}}  + g \\left( \\frac{\\partial P}{\\partial {\\mathbf{x}_i}}  \\right)^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09338aa8",
   "metadata": {
    "editable": true
   },
   "source": [
    "The condition of stationary density means that the left hand side equals zero. In other words, the terms containing first and second derivatives have to cancel each other. It is possible only if $g = \\frac{1}{P}$, which yields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ef9a3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{F} = 2\\frac{1}{\\Psi_T}\\nabla\\Psi_T,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0ff704",
   "metadata": {
    "editable": true
   },
   "source": [
    "which is known as the so-called *quantum force*. This term is responsible for pushing the walker towards regions of configuration space where the trial wave function is large, increasing the efficiency of the simulation in contrast to the Metropolis algorithm where the walker has the same probability of moving in every direction.\n",
    "\n",
    "The Fokker-Planck equation yields a (the solution to the equation) transition probability given by the Green's function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641af4b1",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "G(y,x,\\Delta t) = \\frac{1}{(4\\pi D\\Delta t)^{3N/2}} \\exp{\\left(-(y-x-D\\Delta t F(x))^2/4D\\Delta t\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678dbb3",
   "metadata": {
    "editable": true
   },
   "source": [
    "which in turn means that our brute force Metropolis algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340de63",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "A(y,x) = \\mathrm{min}(1,q(y,x))),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe17356",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $q(y,x) = |\\Psi_T(y)|^2/|\\Psi_T(x)|^2$ is now replaced by the [Metropolis-Hastings algorithm](http://scitation.aip.org/content/aip/journal/jcp/21/6/10.1063/1.1699114) as well as [Hasting's article](http://biomet.oxfordjournals.org/content/57/1/97.abstract),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d4703",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "q(y,x) = \\frac{G(x,y,\\Delta t)|\\Psi_T(y)|^2}{G(y,x,\\Delta t)|\\Psi_T(x)|^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d8279",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Importance sampling, program elements\n",
    "\n",
    "The general derivative formula of the Jastrow factor is (the subscript $C$ stands for Correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3fb60e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\Psi_C}\\frac{\\partial \\Psi_C}{\\partial x_k} =\n",
    "\\sum_{i=1}^{k-1}\\frac{\\partial g_{ik}}{\\partial x_k}\n",
    "+\n",
    "\\sum_{i=k+1}^{N}\\frac{\\partial g_{ki}}{\\partial x_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3957c",
   "metadata": {
    "editable": true
   },
   "source": [
    "However, \n",
    "with our written in way which can be reused later as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aac9aa4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_C=\\prod_{i< j}g(r_{ij})= \\exp{\\left\\{\\sum_{i<j}f(r_{ij})\\right\\}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76bcb1",
   "metadata": {
    "editable": true
   },
   "source": [
    "the gradient needed for the quantum force and local energy is easy to compute.  \n",
    "The function $f(r_{ij})$ will depends on the system under study. In the equations below we will keep this general form.\n",
    "\n",
    "In the Metropolis/Hasting algorithm, the *acceptance ratio* determines the probability for a particle  to be accepted at a new position. The ratio of the trial wave functions evaluated at the new and current positions is given by ($OB$ for the onebody  part)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec2206",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "R \\equiv \\frac{\\Psi_{T}^{new}}{\\Psi_{T}^{old}} = \n",
    "\\frac{\\Psi_{OB}^{new}}{\\Psi_{OB}^{old}}\\frac{\\Psi_{C}^{new}}{\\Psi_{C}^{old}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683d9d59",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here $\\Psi_{OB}$ is our onebody part (Slater determinant or product of boson single-particle states)  while $\\Psi_{C}$ is our correlation function, or Jastrow factor. \n",
    "We need to optimize the $\\nabla \\Psi_T / \\Psi_T$ ratio and the second derivative as well, that is\n",
    "the $\\mathbf{\\nabla}^2 \\Psi_T/\\Psi_T$ ratio. The first is needed when we compute the so-called quantum force in importance sampling.\n",
    "The second is needed when we compute the kinetic energy term of the local energy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd0729b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\mathbf{\\mathbf{\\nabla}}  \\Psi}{\\Psi}  = \\frac{\\mathbf{\\nabla}  (\\Psi_{OB} \\, \\Psi_{C})}{\\Psi_{OB} \\, \\Psi_{C}}  =  \\frac{ \\Psi_C \\mathbf{\\nabla}  \\Psi_{OB} + \\Psi_{OB} \\mathbf{\\nabla}  \\Psi_{C}}{\\Psi_{OB} \\Psi_{C}} = \\frac{\\mathbf{\\nabla}  \\Psi_{OB}}{\\Psi_{OB}} + \\frac{\\mathbf{\\nabla}   \\Psi_C}{ \\Psi_C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08aabe",
   "metadata": {
    "editable": true
   },
   "source": [
    "The expectation value of the kinetic energy expressed in atomic units for electron $i$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68d10cd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\hat{K}_i \\rangle = -\\frac{1}{2}\\frac{\\langle\\Psi|\\mathbf{\\nabla}_{i}^2|\\Psi \\rangle}{\\langle\\Psi|\\Psi \\rangle},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df047b97",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{K}_i = -\\frac{1}{2}\\frac{\\mathbf{\\nabla}_{i}^{2} \\Psi}{\\Psi}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de291c6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "The second derivative which enters the definition of the local energy is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c27c07f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\mathbf{\\nabla}^2 \\Psi}{\\Psi}=\\frac{\\mathbf{\\nabla}^2 \\Psi_{OB}}{\\Psi_{OB}} + \\frac{\\mathbf{\\nabla}^2  \\Psi_C}{ \\Psi_C} + 2 \\frac{\\mathbf{\\nabla}  \\Psi_{OB}}{\\Psi_{OB}}\\cdot\\frac{\\mathbf{\\nabla}   \\Psi_C}{ \\Psi_C}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc70a278",
   "metadata": {
    "editable": true
   },
   "source": [
    "We discuss here how to calculate these quantities in an optimal way,\n",
    "\n",
    "We have defined the correlated function as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f29cc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_C=\\prod_{i< j}g(r_{ij})=\\prod_{i< j}^Ng(r_{ij})= \\prod_{i=1}^N\\prod_{j=i+1}^Ng(r_{ij}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a740f66",
   "metadata": {
    "editable": true
   },
   "source": [
    "with \n",
    "$r_{ij}=|\\mathbf{r}_i-\\mathbf{r}_j|=\\sqrt{(x_i-x_j)^2+(y_i-y_j)^2+(z_i-z_j)^2}$ in three dimensions or\n",
    "$r_{ij}=|\\mathbf{r}_i-\\mathbf{r}_j|=\\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}$ if we work with two-dimensional systems.\n",
    "\n",
    "In our particular case we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bcd5d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_C=\\prod_{i< j}g(r_{ij})=\\exp{\\left\\{\\sum_{i<j}f(r_{ij})\\right\\}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32a86b",
   "metadata": {
    "editable": true
   },
   "source": [
    "The total number of different relative distances $r_{ij}$ is $N(N-1)/2$. In a matrix storage format, the relative distances  form a strictly upper triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f3e66",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{r} \\equiv \\begin{pmatrix}\n",
    "  0 & r_{1,2} & r_{1,3} & \\cdots & r_{1,N} \\\\\n",
    "  \\vdots & 0       & r_{2,3} & \\cdots & r_{2,N} \\\\\n",
    "  \\vdots & \\vdots  & 0  & \\ddots & \\vdots  \\\\\n",
    "  \\vdots & \\vdots  & \\vdots  & \\ddots  & r_{N-1,N} \\\\\n",
    "  0 & 0  & 0  & \\cdots  & 0\n",
    " \\end{pmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53413a",
   "metadata": {
    "editable": true
   },
   "source": [
    "This applies to  $\\mathbf{g} = \\mathbf{g}(r_{ij})$ as well. \n",
    "\n",
    "In our algorithm we will move one particle  at the time, say the $kth$-particle.  This sampling will be seen to be particularly efficient when we are going to compute a Slater determinant. \n",
    "\n",
    "We have that the ratio between Jastrow factors $R_C$ is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd0f04",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "R_{C} = \\frac{\\Psi_{C}^\\mathrm{new}}{\\Psi_{C}^\\mathrm{cur}} =\n",
    "\\prod_{i=1}^{k-1}\\frac{g_{ik}^\\mathrm{new}}{g_{ik}^\\mathrm{cur}}\n",
    "\\prod_{i=k+1}^{N}\\frac{ g_{ki}^\\mathrm{new}} {g_{ki}^\\mathrm{cur}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc1ead",
   "metadata": {
    "editable": true
   },
   "source": [
    "For the Pade-Jastrow form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea325d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "R_{C} = \\frac{\\Psi_{C}^\\mathrm{new}}{\\Psi_{C}^\\mathrm{cur}} = \n",
    "\\frac{\\exp{U_{new}}}{\\exp{U_{cur}}} = \\exp{\\Delta U},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd28b0a",
   "metadata": {
    "editable": true
   },
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a4a8a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Delta U =\n",
    "\\sum_{i=1}^{k-1}\\big(f_{ik}^\\mathrm{new}-f_{ik}^\\mathrm{cur}\\big)\n",
    "+\n",
    "\\sum_{i=k+1}^{N}\\big(f_{ki}^\\mathrm{new}-f_{ki}^\\mathrm{cur}\\big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61015d1e",
   "metadata": {
    "editable": true
   },
   "source": [
    "One needs to develop a special algorithm \n",
    "that runs only through the elements of the upper triangular\n",
    "matrix $\\mathbf{g}$ and have $k$ as an index. \n",
    "\n",
    "The expression to be derived in the following is of interest when computing the quantum force and the kinetic energy. It has the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9141031",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\mathbf{\\nabla}_i\\Psi_C}{\\Psi_C} = \\frac{1}{\\Psi_C}\\frac{\\partial \\Psi_C}{\\partial x_i},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df31a8d",
   "metadata": {
    "editable": true
   },
   "source": [
    "for all dimensions and with $i$ running over all particles.\n",
    "\n",
    "For the first derivative only $N-1$ terms survive the ratio because the $g$-terms that are not differentiated cancel with their corresponding ones in the denominator. Then,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b1e73",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\Psi_C}\\frac{\\partial \\Psi_C}{\\partial x_k} =\n",
    "\\sum_{i=1}^{k-1}\\frac{1}{g_{ik}}\\frac{\\partial g_{ik}}{\\partial x_k}\n",
    "+\n",
    "\\sum_{i=k+1}^{N}\\frac{1}{g_{ki}}\\frac{\\partial g_{ki}}{\\partial x_k}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f869bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "An equivalent equation is obtained for the exponential form after replacing $g_{ij}$ by $\\exp(f_{ij})$, yielding:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30492329",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\Psi_C}\\frac{\\partial \\Psi_C}{\\partial x_k} =\n",
    "\\sum_{i=1}^{k-1}\\frac{\\partial g_{ik}}{\\partial x_k}\n",
    "+\n",
    "\\sum_{i=k+1}^{N}\\frac{\\partial g_{ki}}{\\partial x_k},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048a032",
   "metadata": {
    "editable": true
   },
   "source": [
    "with both expressions scaling as $\\mathcal{O}(N)$.\n",
    "\n",
    "Using the identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d550820",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial x_i}g_{ij} = -\\frac{\\partial}{\\partial x_j}g_{ij},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0b2e1",
   "metadata": {
    "editable": true
   },
   "source": [
    "we get expressions where all the derivatives acting on the particle  are represented by the *second* index of $g$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e8aa1",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\Psi_C}\\frac{\\partial \\Psi_C}{\\partial x_k} =\n",
    "\\sum_{i=1}^{k-1}\\frac{1}{g_{ik}}\\frac{\\partial g_{ik}}{\\partial x_k}\n",
    "-\\sum_{i=k+1}^{N}\\frac{1}{g_{ki}}\\frac{\\partial g_{ki}}{\\partial x_i},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f38f05",
   "metadata": {
    "editable": true
   },
   "source": [
    "and for the exponential case:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683339d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\Psi_C}\\frac{\\partial \\Psi_C}{\\partial x_k} =\n",
    "\\sum_{i=1}^{k-1}\\frac{\\partial g_{ik}}{\\partial x_k}\n",
    "-\\sum_{i=k+1}^{N}\\frac{\\partial g_{ki}}{\\partial x_i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee31e0",
   "metadata": {
    "editable": true
   },
   "source": [
    "For correlation forms depending only on the scalar distances $r_{ij}$ we can use the chain rule. Noting that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e3d3ab",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial g_{ij}}{\\partial x_j} = \\frac{\\partial g_{ij}}{\\partial r_{ij}} \\frac{\\partial r_{ij}}{\\partial x_j} = \\frac{x_j - x_i}{r_{ij}} \\frac{\\partial g_{ij}}{\\partial r_{ij}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b62ce",
   "metadata": {
    "editable": true
   },
   "source": [
    "we arrive at"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c1e11",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\Psi_C}\\frac{\\partial \\Psi_C}{\\partial x_k} = \n",
    "\\sum_{i=1}^{k-1}\\frac{1}{g_{ik}} \\frac{\\mathbf{r_{ik}}}{r_{ik}} \\frac{\\partial g_{ik}}{\\partial r_{ik}}\n",
    "-\\sum_{i=k+1}^{N}\\frac{1}{g_{ki}}\\frac{\\mathbf{r_{ki}}}{r_{ki}}\\frac{\\partial g_{ki}}{\\partial r_{ki}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae20af7",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that for the Pade-Jastrow form we can set $g_{ij} \\equiv g(r_{ij}) = e^{f(r_{ij})} = e^{f_{ij}}$ and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2a63b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial g_{ij}}{\\partial r_{ij}} = g_{ij} \\frac{\\partial f_{ij}}{\\partial r_{ij}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51112839",
   "metadata": {
    "editable": true
   },
   "source": [
    "Therefore,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434db96b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{\\Psi_{C}}\\frac{\\partial \\Psi_{C}}{\\partial x_k} =\n",
    "\\sum_{i=1}^{k-1}\\frac{\\mathbf{r_{ik}}}{r_{ik}}\\frac{\\partial f_{ik}}{\\partial r_{ik}}\n",
    "-\\sum_{i=k+1}^{N}\\frac{\\mathbf{r_{ki}}}{r_{ki}}\\frac{\\partial f_{ki}}{\\partial r_{ki}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c511131",
   "metadata": {
    "editable": true
   },
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a589654",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{r}_{ij} = |\\mathbf{r}_j - \\mathbf{r}_i| = (x_j - x_i)\\mathbf{e}_1 + (y_j - y_i)\\mathbf{e}_2 + (z_j - z_i)\\mathbf{e}_3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb7571",
   "metadata": {
    "editable": true
   },
   "source": [
    "is the relative distance. \n",
    "\n",
    "The second derivative of the Jastrow factor divided by the Jastrow factor (the way it enters the kinetic energy) is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5757df0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left[\\frac{\\mathbf{\\nabla}^2 \\Psi_C}{\\Psi_C}\\right]_x =\\  \n",
    "2\\sum_{k=1}^{N}\n",
    "\\sum_{i=1}^{k-1}\\frac{\\partial^2 g_{ik}}{\\partial x_k^2}\\ +\\ \n",
    "\\sum_{k=1}^N\n",
    "\\left(\n",
    "\\sum_{i=1}^{k-1}\\frac{\\partial g_{ik}}{\\partial x_k} -\n",
    "\\sum_{i=k+1}^{N}\\frac{\\partial g_{ki}}{\\partial x_i}\n",
    "\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46486706",
   "metadata": {
    "editable": true
   },
   "source": [
    "But we have a simple form for the function, namely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a812a3cd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_{C}=\\prod_{i< j}\\exp{f(r_{ij})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da336f8",
   "metadata": {
    "editable": true
   },
   "source": [
    "and it is easy to see that for particle  $k$\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271cd80",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\mathbf{\\nabla}^2_k \\Psi_C}{\\Psi_C }=\n",
    "\\sum_{ij\\ne k}\\frac{(\\mathbf{r}_k-\\mathbf{r}_i)(\\mathbf{r}_k-\\mathbf{r}_j)}{r_{ki}r_{kj}}f'(r_{ki})f'(r_{kj})+\n",
    "\\sum_{j\\ne k}\\left( f''(r_{kj})+\\frac{2}{r_{kj}}f'(r_{kj})\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d147378",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Importance sampling, Fokker-Planck and Langevin equations\n",
    "\n",
    "A stochastic process is simply a function of two variables, one is the time,\n",
    "the other is a stochastic variable $X$, defined by specifying\n",
    "* the set $\\left\\{x\\right\\}$ of possible values for $X$;\n",
    "\n",
    "* the probability distribution, $w_X(x)$,  over this set, or briefly $w(x)$\n",
    "\n",
    "The set of values $\\left\\{x\\right\\}$ for $X$ \n",
    "may be discrete, or continuous. If the set of\n",
    "values is continuous, then $w_X (x)$ is a probability density so that \n",
    "$w_X (x)dx$\n",
    "is the probability that one finds the stochastic variable $X$ to have values\n",
    "in the range $[x, x + dx]$ .\n",
    "\n",
    "     An arbitrary number of other stochastic variables may be derived from\n",
    "$X$. For example, any $Y$ given by a mapping of $X$, is also a stochastic\n",
    "variable. The mapping may also be time-dependent, that is, the mapping\n",
    "depends on an additional variable $t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a995d6a1",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "Y_X (t) = f (X, t) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855e922",
   "metadata": {
    "editable": true
   },
   "source": [
    "The quantity $Y_X (t)$ is called a random function, or, since $t$ often is time,\n",
    "a stochastic process. A stochastic process is a function of two variables,\n",
    "one is the time, the other is a stochastic variable $X$. Let $x$ be one of the\n",
    "possible values of $X$ then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3781d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "y(t) = f (x, t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c99880b",
   "metadata": {
    "editable": true
   },
   "source": [
    "is a function of $t$, called a sample function or realization of the process.\n",
    "In physics one considers the stochastic process to be an ensemble of such\n",
    "sample functions.\n",
    "\n",
    "     For many physical systems initial distributions of a stochastic \n",
    "variable $y$ tend to equilibrium distributions: $w(y, t)\\rightarrow w_0(y)$ \n",
    "as $t\\rightarrow\\infty$. In\n",
    "equilibrium detailed balance constrains the transition rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104dae34",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(y\\rightarrow y')w(y ) = W(y'\\rightarrow y)w_0 (y),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d751080",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $W(y'\\rightarrow y)$ \n",
    "is the probability, per unit time, that the system changes\n",
    "from a state $|y\\rangle$ , characterized by the value $y$ \n",
    "for the stochastic variable $Y$ , to a state $|y'\\rangle$.\n",
    "\n",
    "Note that for a system in equilibrium the transition rate \n",
    "$W(y'\\rightarrow y)$ and\n",
    "the reverse $W(y\\rightarrow y')$ may be very different. \n",
    "\n",
    "Consider, for instance, a simple\n",
    "system that has only two energy levels $\\epsilon_0 = 0$ and \n",
    "$\\epsilon_1 = \\Delta E$. \n",
    "\n",
    "For a system governed by the Boltzmann distribution we find (the partition function has been taken out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5586be",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(0\\rightarrow 1)\\exp{-(\\epsilon_0/kT)} = W(1\\rightarrow 0)\\exp{-(\\epsilon_1/kT)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6b8f0",
   "metadata": {
    "editable": true
   },
   "source": [
    "We get then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b098f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{W(1\\rightarrow 0)}{W(0 \\rightarrow 1)}=\\exp{-(\\Delta E/kT)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c490e33",
   "metadata": {
    "editable": true
   },
   "source": [
    "which goes to zero when $T$ tends to zero.\n",
    "\n",
    "If we assume a discrete set of events,\n",
    "our initial probability\n",
    "distribution function can be  given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6536a0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w_i(0) = \\delta_{i,0},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8eae54",
   "metadata": {
    "editable": true
   },
   "source": [
    "and its time-development after a given time step $\\Delta t=\\epsilon$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c7ace",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w_i(t) = \\sum_{j}W(j\\rightarrow i)w_j(t=0).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da602202",
   "metadata": {
    "editable": true
   },
   "source": [
    "The continuous analog to $w_i(0)$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc698c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{x})\\rightarrow \\delta(\\mathbf{x}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0781c",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we now have generalized the one-dimensional position $x$ to a generic-dimensional  \n",
    "vector $\\mathbf{x}$. The Kroenecker $\\delta$ function is replaced by the $\\delta$ distribution\n",
    "function $\\delta(\\mathbf{x})$ at  $t=0$.  \n",
    "\n",
    "The transition from a state $j$ to a state $i$ is now replaced by a transition\n",
    "to a state with position $\\mathbf{y}$ from a state with position $\\mathbf{x}$. \n",
    "The discrete sum of transition probabilities can then be replaced by an integral\n",
    "and we obtain the new distribution at a time $t+\\Delta t$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33ff24",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{y},t+\\Delta t)= \\int W(\\mathbf{y},t+\\Delta t| \\mathbf{x},t)w(\\mathbf{x},t)d\\mathbf{x},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2f193f",
   "metadata": {
    "editable": true
   },
   "source": [
    "and after $m$ time steps we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a67a08",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{y},t+m\\Delta t)= \\int W(\\mathbf{y},t+m\\Delta t| \\mathbf{x},t)w(\\mathbf{x},t)d\\mathbf{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1281716",
   "metadata": {
    "editable": true
   },
   "source": [
    "When equilibrium is reached we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81893545",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{y})= \\int W(\\mathbf{y}|\\mathbf{x}, t)w(\\mathbf{x})d\\mathbf{x},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b937e37",
   "metadata": {
    "editable": true
   },
   "source": [
    "that is no time-dependence. Note our change of notation for $W$\n",
    "\n",
    "We can solve the equation for $w(\\mathbf{y},t)$ by making a Fourier transform to\n",
    "momentum space. \n",
    "The PDF $w(\\mathbf{x},t)$ is related to its Fourier transform\n",
    "$\\tilde{w}(\\mathbf{k},t)$ through"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168394d9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{x},t) = \\int_{-\\infty}^{\\infty}d\\mathbf{k} \\exp{(i\\mathbf{kx})}\\tilde{w}(\\mathbf{k},t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd326511",
   "metadata": {
    "editable": true
   },
   "source": [
    "and using the definition of the \n",
    "$\\delta$-function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b391dec6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\delta(\\mathbf{x}) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty}d\\mathbf{k} \\exp{(i\\mathbf{kx})},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724f7785",
   "metadata": {
    "editable": true
   },
   "source": [
    "we see that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6221c132",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{w}(\\mathbf{k},0)=1/2\\pi.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d100f8",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can then use the Fourier-transformed diffusion equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c8d4e5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial \\tilde{w}(\\mathbf{k},t)}{\\partial t} = -D\\mathbf{k}^2\\tilde{w}(\\mathbf{k},t),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290b8c5",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the obvious solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec374f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tilde{w}(\\mathbf{k},t)=\\tilde{w}(\\mathbf{k},0)\\exp{\\left[-(D\\mathbf{k}^2t)\\right)}=\n",
    "    \\frac{1}{2\\pi}\\exp{\\left[-(D\\mathbf{k}^2t)\\right]}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc798be4",
   "metadata": {
    "editable": true
   },
   "source": [
    "With the Fourier transform we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41683fda",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{x},t)=\\int_{-\\infty}^{\\infty}d\\mathbf{k} \\exp{\\left[i\\mathbf{kx}\\right]}\\frac{1}{2\\pi}\\exp{\\left[-(D\\mathbf{k}^2t)\\right]}=\n",
    "    \\frac{1}{\\sqrt{4\\pi Dt}}\\exp{\\left[-(\\mathbf{x}^2/4Dt)\\right]},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7eb2cc",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the normalization condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623d437",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\int_{-\\infty}^{\\infty}w(\\mathbf{x},t)d\\mathbf{x}=1.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8e2f93",
   "metadata": {
    "editable": true
   },
   "source": [
    "The solution represents the probability of finding\n",
    "our random walker at position $\\mathbf{x}$ at time $t$ if the initial distribution \n",
    "was placed at $\\mathbf{x}=0$ at $t=0$. \n",
    "\n",
    "There is another interesting feature worth observing. The discrete transition probability $W$\n",
    "itself is given by a binomial distribution.\n",
    "The results from the central limit theorem state that \n",
    "transition probability in the limit $n\\rightarrow \\infty$ converges to the normal \n",
    "distribution. It is then possible to show that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154efc3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(il-jl,n\\epsilon)\\rightarrow W(\\mathbf{y},t+\\Delta t|\\mathbf{x},t)=\n",
    "    \\frac{1}{\\sqrt{4\\pi D\\Delta t}}\\exp{\\left[-((\\mathbf{y}-\\mathbf{x})^2/4D\\Delta t)\\right]},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139033a",
   "metadata": {
    "editable": true
   },
   "source": [
    "and that it satisfies the normalization condition and is itself a solution\n",
    "to the diffusion equation.\n",
    "\n",
    "Let us now assume that we have three PDFs for times $t_0 < t' < t$, that is\n",
    "$w(\\mathbf{x}_0,t_0)$, $w(\\mathbf{x}',t')$ and $w(\\mathbf{x},t)$.\n",
    "We have then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c559ef65",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{x},t)= \\int_{-\\infty}^{\\infty} W(\\mathbf{x}.t|\\mathbf{x}'.t')w(\\mathbf{x}',t')d\\mathbf{x}',\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59874625",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f944f4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{x},t)= \\int_{-\\infty}^{\\infty} W(\\mathbf{x}.t|\\mathbf{x}_0.t_0)w(\\mathbf{x}_0,t_0)d\\mathbf{x}_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6830b",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb95924",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "w(\\mathbf{x}',t')= \\int_{-\\infty}^{\\infty} W(\\mathbf{x}'.t'|\\mathbf{x}_0,t_0)w(\\mathbf{x}_0,t_0)d\\mathbf{x}_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914d483",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can combine these equations and arrive at the famous Einstein-Smoluchenski-Kolmogorov-Chapman (ESKC) relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46ab86",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(\\mathbf{x}t|\\mathbf{x}_0t_0)  = \\int_{-\\infty}^{\\infty} W(\\mathbf{x},t|\\mathbf{x}',t')W(\\mathbf{x}',t'|\\mathbf{x}_0,t_0)d\\mathbf{x}'.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cf06c2",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can replace the spatial dependence with a dependence upon say the velocity\n",
    "(or momentum), that is we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fade3cf",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(\\mathbf{v},t|\\mathbf{v}_0,t_0)  = \\int_{-\\infty}^{\\infty} W(\\mathbf{v},t|\\mathbf{v}',t')W(\\mathbf{v}',t'|\\mathbf{v}_0,t_0)d\\mathbf{x}'.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc67710",
   "metadata": {
    "editable": true
   },
   "source": [
    "We will now derive the Fokker-Planck equation. \n",
    "We start from the ESKC equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb89eae",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(\\mathbf{x},t|\\mathbf{x}_0,t_0)  = \\int_{-\\infty}^{\\infty} W(\\mathbf{x},t|\\mathbf{x}',t')W(\\mathbf{x}',t'|\\mathbf{x}_0,t_0)d\\mathbf{x}'.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d16166",
   "metadata": {
    "editable": true
   },
   "source": [
    "Define $s=t'-t_0$, $\\tau=t-t'$ and $t-t_0=s+\\tau$. We have then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad78be",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(\\mathbf{x},s+\\tau|\\mathbf{x}_0)  = \\int_{-\\infty}^{\\infty} W(\\mathbf{x},\\tau|\\mathbf{x}')W(\\mathbf{x}',s|\\mathbf{x}_0)d\\mathbf{x}'.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2c500",
   "metadata": {
    "editable": true
   },
   "source": [
    "Assume now that $\\tau$ is very small so that we can make an expansion in terms of a small step $xi$, with $\\mathbf{x}'=\\mathbf{x}-\\xi$, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73065ea",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(\\mathbf{x},s|\\mathbf{x}_0)+\\frac{\\partial W}{\\partial s}\\tau +O(\\tau^2) = \\int_{-\\infty}^{\\infty} W(\\mathbf{x},\\tau|\\mathbf{x}-\\xi)W(\\mathbf{x}-\\xi,s|\\mathbf{x}_0)d\\mathbf{x}'.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd9bc9",
   "metadata": {
    "editable": true
   },
   "source": [
    "We assume that $W(\\mathbf{x},\\tau|\\mathbf{x}-\\xi)$ takes non-negligible values only when $\\xi$ is small. This is just another way of stating the Master equation!!\n",
    "\n",
    "We say thus that $\\mathbf{x}$ changes only by a small amount in the time interval $\\tau$. \n",
    "This means that we can make a Taylor expansion in terms of $\\xi$, that is we\n",
    "expand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edc8247",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(\\mathbf{x},\\tau|\\mathbf{x}-\\xi)W(\\mathbf{x}-\\xi,s|\\mathbf{x}_0) =\n",
    "\\sum_{n=0}^{\\infty}\\frac{(-\\xi)^n}{n!}\\frac{\\partial^n}{\\partial x^n}\\left[W(\\mathbf{x}+\\xi,\\tau|\\mathbf{x})W(\\mathbf{x},s|\\mathbf{x}_0)\n",
    "\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc02a8",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can then rewrite the ESKC equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9106b9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial W}{\\partial s}\\tau=-W(\\mathbf{x},s|\\mathbf{x}_0)+\n",
    "\\sum_{n=0}^{\\infty}\\frac{(-\\xi)^n}{n!}\\frac{\\partial^n}{\\partial x^n}\n",
    "\\left[W(\\mathbf{x},s|\\mathbf{x}_0)\\int_{-\\infty}^{\\infty} \\xi^nW(\\mathbf{x}+\\xi,\\tau|\\mathbf{x})d\\xi\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19fe6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have neglected higher powers of $\\tau$ and have used that for $n=0$ \n",
    "we get simply $W(\\mathbf{x},s|\\mathbf{x}_0)$ due to normalization.\n",
    "\n",
    "We say thus that $\\mathbf{x}$ changes only by a small amount in the time interval $\\tau$. \n",
    "This means that we can make a Taylor expansion in terms of $\\xi$, that is we\n",
    "expand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df42266",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "W(\\mathbf{x},\\tau|\\mathbf{x}-\\xi)W(\\mathbf{x}-\\xi,s|\\mathbf{x}_0) =\n",
    "\\sum_{n=0}^{\\infty}\\frac{(-\\xi)^n}{n!}\\frac{\\partial^n}{\\partial x^n}\\left[W(\\mathbf{x}+\\xi,\\tau|\\mathbf{x})W(\\mathbf{x},s|\\mathbf{x}_0)\n",
    "\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7cd1b9",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can then rewrite the ESKC equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ab7c7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial W(\\mathbf{x},s|\\mathbf{x}_0)}{\\partial s}\\tau=-W(\\mathbf{x},s|\\mathbf{x}_0)+\n",
    "\\sum_{n=0}^{\\infty}\\frac{(-\\xi)^n}{n!}\\frac{\\partial^n}{\\partial x^n}\n",
    "\\left[W(\\mathbf{x},s|\\mathbf{x}_0)\\int_{-\\infty}^{\\infty} \\xi^nW(\\mathbf{x}+\\xi,\\tau|\\mathbf{x})d\\xi\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f0025",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have neglected higher powers of $\\tau$ and have used that for $n=0$ \n",
    "we get simply $W(\\mathbf{x},s|\\mathbf{x}_0)$ due to normalization.\n",
    "\n",
    "We simplify the above by introducing the moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b5674",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "M_n=\\frac{1}{\\tau}\\int_{-\\infty}^{\\infty} \\xi^nW(\\mathbf{x}+\\xi,\\tau|\\mathbf{x})d\\xi=\n",
    "\\frac{\\langle [\\Delta x(\\tau)]^n\\rangle}{\\tau},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da13a7",
   "metadata": {
    "editable": true
   },
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebfddd9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial W(\\mathbf{x},s|\\mathbf{x}_0)}{\\partial s}=\n",
    "\\sum_{n=1}^{\\infty}\\frac{(-\\xi)^n}{n!}\\frac{\\partial^n}{\\partial x^n}\n",
    "\\left[W(\\mathbf{x},s|\\mathbf{x}_0)M_n\\right].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa68c763",
   "metadata": {
    "editable": true
   },
   "source": [
    "When $\\tau \\rightarrow 0$ we assume that $\\langle [\\Delta x(\\tau)]^n\\rangle \\rightarrow 0$ more rapidly than $\\tau$ itself if $n > 2$. \n",
    "When $\\tau$ is much larger than the standard correlation time of \n",
    "system then $M_n$ for $n > 2$ can normally be neglected.\n",
    "This means that fluctuations become negligible at large time scales.\n",
    "\n",
    "If we neglect such terms we can rewrite the ESKC equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255fff4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial W(\\mathbf{x},s|\\mathbf{x}_0)}{\\partial s}=\n",
    "-\\frac{\\partial M_1W(\\mathbf{x},s|\\mathbf{x}_0)}{\\partial x}+\n",
    "\\frac{1}{2}\\frac{\\partial^2 M_2W(\\mathbf{x},s|\\mathbf{x}_0)}{\\partial x^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff6ebe",
   "metadata": {
    "editable": true
   },
   "source": [
    "In a more compact form we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1039493",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\partial W}{\\partial s}=\n",
    "-\\frac{\\partial M_1W}{\\partial x}+\n",
    "\\frac{1}{2}\\frac{\\partial^2 M_2W}{\\partial x^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3545c651",
   "metadata": {
    "editable": true
   },
   "source": [
    "which is the Fokker-Planck equation!  It is trivial to replace \n",
    "position with velocity (momentum).\n",
    "\n",
    "Consider a particle  suspended in a liquid. On its path through the liquid it will continuously collide with the liquid molecules. Because on average the particle  will collide more often on the front side than on the back side, it will experience a systematic force proportional with its velocity, and directed opposite to its velocity. Besides this systematic force the particle  will experience a stochastic force  $\\mathbf{F}(t)$. \n",
    "The equations of motion are \n",
    "* $\\frac{d\\mathbf{r}}{dt}=\\mathbf{v}$ and \n",
    "\n",
    "* $\\frac{d\\mathbf{v}}{dt}=-\\xi \\mathbf{v}+\\mathbf{F}$.\n",
    "\n",
    "From hydrodynamics  we know that the friction constant  $\\xi$ is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac19c81",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\xi =6\\pi \\eta a/m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda004bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\eta$ is the viscosity  of the solvent and a is the radius of the particle .\n",
    "\n",
    "Solving the second equation in the previous slide we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66130f5b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{v}(t)=\\mathbf{v}_{0}e^{-\\xi t}+\\int_{0}^{t}d\\tau e^{-\\xi (t-\\tau )}\\mathbf{F }(\\tau ).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0566e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "If we want to get some useful information out of this, we have to average over all possible realizations of \n",
    "$\\mathbf{F}(t)$, with the initial velocity as a condition. A useful quantity for example is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef555060",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{v}(t)\\cdot \\mathbf{v}(t)\\rangle_{\\mathbf{v}_{0}}=v_{0}^{-\\xi 2t}\n",
    "+2\\int_{0}^{t}d\\tau e^{-\\xi (2t-\\tau)}\\mathbf{v}_{0}\\cdot \\langle \\mathbf{F}(\\tau )\\rangle_{\\mathbf{v}_{0}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19cf132",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "+\\int_{0}^{t}d\\tau ^{\\prime }\\int_{0}^{t}d\\tau e^{-\\xi (2t-\\tau -\\tau ^{\\prime })}\n",
    "\\langle \\mathbf{F}(\\tau )\\cdot \\mathbf{F}(\\tau ^{\\prime })\\rangle_{ \\mathbf{v}_{0}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42023abc",
   "metadata": {
    "editable": true
   },
   "source": [
    "In order to continue we have to make some assumptions about the conditional averages of the stochastic forces. \n",
    "In view of the chaotic character of the stochastic forces the following \n",
    "assumptions seem to be appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772acf9a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{F}(t)\\rangle=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b122065e",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e424e9da",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{F}(t)\\cdot \\mathbf{F}(t^{\\prime })\\rangle_{\\mathbf{v}_{0}}=  C_{\\mathbf{v}_{0}}\\delta (t-t^{\\prime }).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520a6c80",
   "metadata": {
    "editable": true
   },
   "source": [
    "We omit the subscript $\\mathbf{v}_{0}$, when the quantity of interest turns out to be independent of $\\mathbf{v}_{0}$. Using the last three equations we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfc5188",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{v}(t)\\cdot \\mathbf{v}(t)\\rangle_{\\mathbf{v}_{0}}=v_{0}^{2}e^{-2\\xi t}+\\frac{C_{\\mathbf{v}_{0}}}{2\\xi }(1-e^{-2\\xi t}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6ce92e",
   "metadata": {
    "editable": true
   },
   "source": [
    "For large t this should be equal to 3kT/m, from which it follows that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f7627",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{F}(t)\\cdot \\mathbf{F}(t^{\\prime })\\rangle =6\\frac{kT}{m}\\xi \\delta (t-t^{\\prime }).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8cf79",
   "metadata": {
    "editable": true
   },
   "source": [
    "This result is called the fluctuation-dissipation theorem .\n",
    "\n",
    "Integrating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc025d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{v}(t)=\\mathbf{v}_{0}e^{-\\xi t}+\\int_{0}^{t}d\\tau e^{-\\xi (t-\\tau )}\\mathbf{F }(\\tau ),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e354939",
   "metadata": {
    "editable": true
   },
   "source": [
    "we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e973af6f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{r}(t)=\\mathbf{r}_{0}+\\mathbf{v}_{0}\\frac{1}{\\xi }(1-e^{-\\xi t})+\n",
    "\\int_0^td\\tau \\int_0^{\\tau}\\tau ^{\\prime } e^{-\\xi (\\tau -\\tau ^{\\prime })}\\mathbf{F}(\\tau ^{\\prime }),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dff578",
   "metadata": {
    "editable": true
   },
   "source": [
    "from which we calculate the mean square displacement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef1485",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle ( \\mathbf{r}(t)-\\mathbf{r}_{0})^{2}\\rangle _{\\mathbf{v}_{0}}=\\frac{v_0^2}{\\xi}(1-e^{-\\xi t})^{2}+\\frac{3kT}{m\\xi ^{2}}(2\\xi t-3+4e^{-\\xi t}-e^{-2\\xi t}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa333e6",
   "metadata": {
    "editable": true
   },
   "source": [
    "For very large $t$ this becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da668dc4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle (\\mathbf{r}(t)-\\mathbf{r}_{0})^{2}\\rangle =\\frac{6kT}{m\\xi }t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff213d4",
   "metadata": {
    "editable": true
   },
   "source": [
    "from which we get the Einstein relation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e843f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "D= \\frac{kT}{m\\xi }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb16d290",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we have used $\\langle (\\mathbf{r}(t)-\\mathbf{r}_{0})^{2}\\rangle =6Dt$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76bc98",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Code example for two electrons in a quantum dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac491ee8",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# No energy minimization\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "from numba import jit,njit\n",
    "\n",
    "\n",
    "#Read name of output file from command line\n",
    "if len(sys.argv) == 2:\n",
    "    outfilename = sys.argv[1]\n",
    "else:\n",
    "    print('\\nError: Name of output file must be given as command line argument.\\n')\n",
    "outfile = open(outfilename,'w')\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha,beta):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha*(r[0,:]-r[1,:])*deno*deno/r12\n",
    "    qforce[1,:] = -2*r[1,:]*alpha*(r[1,:]-r[0,:])*deno*deno/r12\n",
    "    return qforce\n",
    "    \n",
    "# The Monte Carlo sampling with the Metropolis algo\n",
    "# jit decorator tells Numba to compile this function.\n",
    "# The argument types will be inferred by Numba when function is called.\n",
    "@jit()\n",
    "def MonteCarloSampling():\n",
    "\n",
    "    NumberMCcycles= 100000\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator \n",
    "    seed()\n",
    "    # start variational parameter  loops, two parameters here\n",
    "    alpha = 0.9\n",
    "    for ia in range(MaxVariations):\n",
    "        alpha += .025\n",
    "        AlphaValues[ia] = alpha\n",
    "        beta = 0.2 \n",
    "        for jb in range(MaxVariations):\n",
    "            beta += .01\n",
    "            BetaValues[jb] = beta\n",
    "            energy = energy2 = 0.0\n",
    "            DeltaE = 0.0\n",
    "            #Initial position\n",
    "            for i in range(NumberParticles):\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "            wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "            QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "            #Loop over MC MCcycles\n",
    "            for MCcycle in range(NumberMCcycles):\n",
    "                #Trial position moving one particle at the time\n",
    "                for i in range(NumberParticles):\n",
    "                    for j in range(Dimension):\n",
    "                        PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                           QuantumForceOld[i,j]*TimeStep*D\n",
    "                    wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "                    QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "                    GreensFunction = 0.0\n",
    "                    for j in range(Dimension):\n",
    "                        GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "                    GreensFunction = exp(GreensFunction)\n",
    "                    ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "                    #Metropolis-Hastings test to see whether we accept the move\n",
    "                    if random() <= ProbabilityRatio:\n",
    "                       for j in range(Dimension):\n",
    "                           PositionOld[i,j] = PositionNew[i,j]\n",
    "                           QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                       wfold = wfnew\n",
    "                DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "                energy += DeltaE\n",
    "                energy2 += DeltaE**2\n",
    "            # We calculate mean, variance and error (no blocking applied)\n",
    "            energy /= NumberMCcycles\n",
    "            energy2 /= NumberMCcycles\n",
    "            variance = energy2 - energy**2\n",
    "            error = sqrt(variance/NumberMCcycles)\n",
    "            Energies[ia,jb] = energy    \n",
    "            outfile.write('%f %f %f %f %f\\n' %(alpha,beta,energy,variance,error))\n",
    "    return Energies, AlphaValues, BetaValues\n",
    "\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "MaxVariations = 10\n",
    "Energies = np.zeros((MaxVariations,MaxVariations))\n",
    "AlphaValues = np.zeros(MaxVariations)\n",
    "BetaValues = np.zeros(MaxVariations)\n",
    "(Energies, AlphaValues, BetaValues) = MonteCarloSampling()\n",
    "outfile.close()\n",
    "# Prepare for plots\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "X, Y = np.meshgrid(AlphaValues, BetaValues)\n",
    "surf = ax.plot_surface(X, Y, Energies,cmap=cm.coolwarm,linewidth=0, antialiased=False)\n",
    "# Customize the z axis.\n",
    "zmin = np.matrix(Energies).min()\n",
    "zmax = np.matrix(Energies).max()\n",
    "ax.set_zlim(zmin, zmax)\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.set_zlabel(r'$\\langle E \\rangle$')\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa426bf0",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Bringing the gradient optmization\n",
    "\n",
    "The simple one-particle case in a harmonic oscillator trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c1ed0f",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Gradient descent stepping with analytical derivative\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "def DerivativeE(x):\n",
    "    return x-1.0/(4*x*x*x);\n",
    "\n",
    "def Energy(x):\n",
    "   return x*x*0.5+1.0/(8*x*x);\n",
    "x0 = 1.0\n",
    "eta = 0.1\n",
    "Niterations = 100\n",
    "\n",
    "for iter in range(Niterations):\n",
    "    gradients = DerivativeE(x0)\n",
    "    x0 -= eta*gradients\n",
    "\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af1b84b8",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "from numba import jit\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    return exp(-0.5*alpha*(r1+r2))\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,alpha):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    WfDer = -(r1+r2)\n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha\n",
    "    qforce[1,:] = -2*r[1,:]*alpha\n",
    "    return qforce\n",
    "    \n",
    "# Computing the derivative of the energy and the energy \n",
    "# jit decorator tells Numba to compile this function.\n",
    "# The argument types will be inferred by Numba when function is called.\n",
    "@jit\n",
    "def EnergyMinimization(alpha):\n",
    "\n",
    "    NumberMCcycles= 1000\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator \n",
    "    seed()\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    EnergyDer = 0.0\n",
    "    DeltaPsi = 0.0\n",
    "    DerivativePsiE = 0.0\n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha)\n",
    "        DeltaPsi = DerivativeWFansatz(PositionOld,alpha)\n",
    "        energy += DeltaE\n",
    "        DerivativePsiE += DeltaPsi*DeltaE\n",
    "            \n",
    "    # We calculate mean, variance and error (no blocking applied)\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE /= NumberMCcycles\n",
    "    DeltaPsi /= NumberMCcycles\n",
    "    EnergyDer  = 2*(DerivativePsiE-DeltaPsi*energy)\n",
    "    return energy, EnergyDer\n",
    "\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "# guess for variational parameters\n",
    "x0 = 1.5\n",
    "# Set up iteration using stochastic gradient method\n",
    "Energy =0 ; EnergyDer = 0\n",
    "Energy, EnergyDer = EnergyMinimization(x0)\n",
    "print(Energy, EnergyDer)\n",
    "\n",
    "eta = 0.01\n",
    "Niterations = 100\n",
    "\n",
    "for iter in range(Niterations):\n",
    "    gradients = EnergyDer\n",
    "    x0 -= eta*gradients\n",
    "    Energy, EnergyDer = EnergyMinimization(x0)\n",
    "\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dbd0f9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## VMC for fermions: Efficient calculation of Slater determinants\n",
    "The potentially most time-consuming part is the\n",
    "evaluation of the gradient and the Laplacian of an $N$-particle  Slater\n",
    "determinant. \n",
    "\n",
    "We have to differentiate the determinant with respect to\n",
    "all spatial coordinates of all particles. A brute force\n",
    "differentiation would involve $N\\cdot d$ evaluations of the entire\n",
    "determinant which would even worsen the already undesirable time\n",
    "scaling, making it $Nd\\cdot O(N^3)\\sim O(d\\cdot N^4)$.\n",
    "\n",
    "This poses serious hindrances to the overall efficiency of our code.\n",
    "\n",
    "The efficiency can be improved however if we move only one electron at the time.\n",
    "The Slater determinant matrix $\\hat{D}$ is defined by the matrix elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2404f0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "d_{ij}=\\phi_j(x_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4fc6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\phi_j(\\mathbf{r}_i)$ is a single particle  wave function.\n",
    "The columns correspond to the position of a given particle \n",
    "while the rows stand for the various quantum numbers.\n",
    "\n",
    "What we need to realize is that when differentiating a Slater\n",
    "determinant with respect to some given coordinate, only one row of the\n",
    "corresponding Slater matrix is changed. \n",
    "\n",
    "Therefore, by recalculating\n",
    "the whole determinant we risk producing redundant information. The\n",
    "solution turns out to be an algorithm that requires to keep track of\n",
    "the *inverse* of the Slater matrix.\n",
    "\n",
    "Let the current position in phase space be represented by the $(N\\cdot d)$-element \n",
    "vector $\\mathbf{r}^{\\mathrm{old}}$ and the new suggested\n",
    "position by the vector $\\mathbf{r}^{\\mathrm{new}}$.\n",
    "\n",
    "The inverse of $\\hat{D}$ can be expressed in terms of its\n",
    "cofactors $C_{ij}$ and its determinant (this our notation for a determinant) $\\vert\\hat{D}\\vert$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311218ec",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:inverse_cofactor\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "d_{ij}^{-1} = \\frac{C_{ji}}{\\vert\\hat{D}\\vert}\n",
    "\\label{eq:inverse_cofactor} \\tag{17}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795952b",
   "metadata": {
    "editable": true
   },
   "source": [
    "Notice that the interchanged indices indicate that the matrix of cofactors is to be transposed.\n",
    "\n",
    "If $\\hat{D}$ is invertible, then we must obviously have $\\hat{D}^{-1}\\hat{D}= \\mathbf{1}$, or explicitly in terms of the individual\n",
    "elements of $\\hat{D}$ and $\\hat{D}^{-1}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9ba3f",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:unity_explicitely\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\sum_{k=1}^N d_{ik}^{\\phantom X}d_{kj}^{-1} = \\delta_{ij}^{\\phantom X}\n",
    "\\label{eq:unity_explicitely} \\tag{18}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e5313e",
   "metadata": {
    "editable": true
   },
   "source": [
    "Consider the ratio, which we shall call $R$, between $\\vert\\hat{D}(\\mathbf{r}^{\\mathrm{new}})\\vert$ and $\\vert\\hat{D}(\\mathbf{r}^{\\mathrm{old}})\\vert$. \n",
    "By definition, each of these determinants can\n",
    "individually be expressed in terms of the *i*-th row of its cofactor\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc6b7f",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:detratio_cofactors\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "R\\equiv\\frac{\\vert\\hat{D}(\\mathbf{r}^{\\mathrm{new}})\\vert}\n",
    "{\\vert\\hat{D}(\\mathbf{r}^{\\mathrm{old}})\\vert} =\n",
    "\\frac{\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{new}})\\,\n",
    "C_{ij}(\\mathbf{r}^{\\mathrm{new}})}\n",
    "{\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{old}})\\,\n",
    "C_{ij}(\\mathbf{r}^{\\mathrm{old}})}\n",
    "\\label{eq:detratio_cofactors} \\tag{19}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c633f9",
   "metadata": {
    "editable": true
   },
   "source": [
    "Suppose now that we move only one particle  at a time, meaning that\n",
    "$\\mathbf{r}^{\\mathrm{new}}$ differs from $\\mathbf{r}^{\\mathrm{old}}$ by the\n",
    "position of only one, say the *i*-th, particle . This means that $\\hat{D}(\\mathbf{r}^{\\mathrm{new}})$ and $\\hat{D}(\\mathbf{r}^{\\mathrm{old}})$ differ\n",
    "only by the entries of the *i*-th row.  Recall also that the *i*-th row\n",
    "of a cofactor matrix $\\hat{C}$ is independent of the entries of the\n",
    "*i*-th row of its corresponding matrix $\\hat{D}$. In this particular\n",
    "case we therefore get that the *i*-th row of $\\hat{C}(\\mathbf{r}^{\\mathrm{new}})$ \n",
    "and $\\hat{C}(\\mathbf{r}^{\\mathrm{old}})$ must be\n",
    "equal. Explicitly, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937582f1",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto5\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "C_{ij}(\\mathbf{r}^{\\mathrm{new}}) = C_{ij}(\\mathbf{r}^{\\mathrm{old}})\\quad\n",
    "\\forall\\ j\\in\\{1,\\dots,N\\}\n",
    "\\label{_auto5} \\tag{20}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d01328d",
   "metadata": {
    "editable": true
   },
   "source": [
    "Inserting this into the numerator of eq. ([19](#eq:detratio_cofactors))\n",
    "and using eq. ([17](#eq:inverse_cofactor)) to substitute the cofactors\n",
    "with the elements of the inverse matrix, we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6d043b",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto6\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "R =\\frac{\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{new}})\\,\n",
    "C_{ij}(\\mathbf{r}^{\\mathrm{old}})}\n",
    "{\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{old}})\\,\n",
    "C_{ij}(\\mathbf{r}^{\\mathrm{old}})} =\n",
    "\\frac{\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{new}})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}^{\\mathrm{old}})}\n",
    "{\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{old}})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}^{\\mathrm{old}})}\n",
    "\\label{_auto6} \\tag{21}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a966d",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now by eq. ([18](#eq:unity_explicitely)) the denominator of the rightmost\n",
    "expression must be unity, so that we finally arrive at:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e233a8ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:detratio_inverse\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "R =\n",
    "\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{new}})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}^{\\mathrm{old}}) = \n",
    "\\sum_{j=1}^N \\phi_j(\\mathbf{r}_i^{\\mathrm{new}})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}^{\\mathrm{old}})\n",
    "\\label{eq:detratio_inverse} \\tag{22}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7414bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "What this means is that in order to get the ratio when only the *i*-th\n",
    "particle  has been moved, we only need to calculate the dot\n",
    "product of the vector $\\left(\\phi_1(\\mathbf{r}_i^\\mathrm{new}),\\,\\dots,\\,\\phi_N(\\mathbf{r}_i^\\mathrm{new})\\right)$ of single particle  wave functions\n",
    "evaluated at this new position with the *i*-th column of the inverse\n",
    "matrix $\\hat{D}^{-1}$ evaluated at the original position. Such\n",
    "an operation has a time scaling of $O(N)$. The only extra thing we\n",
    "need to do is to maintain the inverse matrix $\\hat{D}^{-1}(\\mathbf{x}^{\\mathrm{old}})$.\n",
    "\n",
    "If the new position $\\mathbf{r}^{\\mathrm{new}}$ is accepted, then the\n",
    "inverse matrix can by suitably updated by an algorithm having a time\n",
    "scaling of $O(N^2)$.  This algorithm goes as\n",
    "follows. First we update all but the *i*-th column of $\\hat{D}^{-1}$. For each column $j\\neq i$, we first calculate the quantity:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e62159",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:inverse_update_1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "S_j =\n",
    "(\\hat{D}(\\mathbf{r}^{\\mathrm{new}})\\times\n",
    "\\hat{D}^{-1}(\\mathbf{r}^{\\mathrm{old}}))_{ij} =\n",
    "\\sum_{l=1}^N d_{il}(\\mathbf{r}^{\\mathrm{new}})\\,\n",
    "d^{-1}_{lj}(\\mathbf{r}^{\\mathrm{old}})\n",
    "\\label{eq:inverse_update_1} \\tag{23}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44938a8e",
   "metadata": {
    "editable": true
   },
   "source": [
    "The new elements of the *j*-th column of $\\hat{D}^{-1}$ are then given\n",
    "by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1908c8f",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:inverse_update_2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "d_{kj}^{-1}(\\mathbf{r}^{\\mathrm{new}}) =\n",
    "d_{kj}^{-1}(\\mathbf{r}^{\\mathrm{old}}) -\n",
    "\\frac{S_j}{R}\\,d_{ki}^{-1}(\\mathbf{r}^{\\mathrm{old}})\\quad\n",
    "\\begin{array}{ll}\n",
    "\\forall\\ \\ k\\in\\{1,\\dots,N\\}\\\\j\\neq i\n",
    "\\end{array}\n",
    "\\label{eq:inverse_update_2} \\tag{24}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760a8d45",
   "metadata": {
    "editable": true
   },
   "source": [
    "Finally the elements of the *i*-th column of $\\hat{D}^{-1}$ are updated\n",
    "simply as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fdefca",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:inverse_update_3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "d_{ki}^{-1}(\\mathbf{r}^{\\mathrm{new}}) =\n",
    "\\frac{1}{R}\\,d_{ki}^{-1}(\\mathbf{r}^{\\mathrm{old}})\\quad\n",
    "\\forall\\ \\ k\\in\\{1,\\dots,N\\}\n",
    "\\label{eq:inverse_update_3} \\tag{25}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a2ffd",
   "metadata": {
    "editable": true
   },
   "source": [
    "We see from these formulas that the time scaling of an update of\n",
    "$\\hat{D}^{-1}$ after changing one row of $\\hat{D}$ is $O(N^2)$.\n",
    "\n",
    "The scheme is also applicable for the calculation of the ratios\n",
    "involving derivatives. It turns\n",
    "out that differentiating the Slater determinant with respect\n",
    "to the coordinates of a single particle  $\\mathbf{r}_i$ changes only the\n",
    "*i*-th row of the corresponding Slater matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef250d7",
   "metadata": {
    "editable": true
   },
   "source": [
    "### The gradient and the Laplacian\n",
    "\n",
    "The gradient and the Laplacian can therefore be calculated as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1271e99",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\vec\\nabla_i\\vert\\hat{D}(\\mathbf{r})\\vert}{\\vert\\hat{D}(\\mathbf{r})\\vert} =\n",
    "\\sum_{j=1}^N \\vec\\nabla_i d_{ij}(\\mathbf{r})d_{ji}^{-1}(\\mathbf{r}) =\n",
    "\\sum_{j=1}^N \\vec\\nabla_i \\phi_j(\\mathbf{r}_i)d_{ji}^{-1}(\\mathbf{r})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae61c6",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7096cb1f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\nabla^2_i\\vert\\hat{D}(\\mathbf{r})\\vert}{\\vert\\hat{D}(\\mathbf{r})\\vert} =\n",
    "\\sum_{j=1}^N \\nabla^2_i d_{ij}(\\mathbf{r})d_{ji}^{-1}(\\mathbf{r}) =\n",
    "\\sum_{j=1}^N \\nabla^2_i \\phi_j(\\mathbf{r}_i)\\,d_{ji}^{-1}(\\mathbf{r})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090936cb",
   "metadata": {
    "editable": true
   },
   "source": [
    "Thus, to calculate all the derivatives of the Slater determinant, we\n",
    "only need the derivatives of the single particle  wave functions\n",
    "($\\vec\\nabla_i \\phi_j(\\mathbf{r}_i)$ and $\\nabla^2_i \\phi_j(\\mathbf{r}_i)$)\n",
    "and the elements of the corresponding inverse Slater matrix ($\\hat{D}^{-1}(\\mathbf{r}_i)$). A calculation of a single derivative is by the\n",
    "above result an $O(N)$ operation. Since there are $d\\cdot N$\n",
    "derivatives, the time scaling of the total evaluation becomes\n",
    "$O(d\\cdot N^2)$. With an $O(N^2)$ updating algorithm for the\n",
    "inverse matrix, the total scaling is no worse, which is far better\n",
    "than the brute force approach yielding $O(d\\cdot N^4)$.\n",
    "\n",
    "**Important note**: In most cases you end with closed form expressions for the single-particle  wave functions. It is then useful to calculate the various derivatives and make separate functions\n",
    "for them.\n",
    "\n",
    "The Slater determinant takes the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d3a74",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Phi(\\mathbf{r}_1,\\mathbf{r}_2,,\\mathbf{r}_3,\\mathbf{r}_4, \\alpha,\\beta,\\gamma,\\delta)=\\frac{1}{\\sqrt{4!}}\n",
    "\\left| \\begin{array}{cccc} \\psi_{100\\uparrow}(\\mathbf{r}_1)& \\psi_{100\\uparrow}(\\mathbf{r}_2)& \\psi_{100\\uparrow}(\\mathbf{r}_3)&\\psi_{100\\uparrow}(\\mathbf{r}_4) \\\\\n",
    "\\psi_{100\\downarrow}(\\mathbf{r}_1)& \\psi_{100\\downarrow}(\\mathbf{r}_2)& \\psi_{100\\downarrow}(\\mathbf{r}_3)&\\psi_{100\\downarrow}(\\mathbf{r}_4) \\\\\n",
    "\\psi_{200\\uparrow}(\\mathbf{r}_1)& \\psi_{200\\uparrow}(\\mathbf{r}_2)& \\psi_{200\\uparrow}(\\mathbf{r}_3)&\\psi_{200\\uparrow}(\\mathbf{r}_4) \\\\\n",
    "\\psi_{200\\downarrow}(\\mathbf{r}_1)& \\psi_{200\\downarrow}(\\mathbf{r}_2)& \\psi_{200\\downarrow}(\\mathbf{r}_3)&\\psi_{200\\downarrow}(\\mathbf{r}_4) \\end{array} \\right|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3ac81",
   "metadata": {
    "editable": true
   },
   "source": [
    "The Slater determinant as written is zero since the spatial wave functions for the spin up and spin down \n",
    "states are equal.  \n",
    "But we can rewrite it as the product of two Slater determinants, one for spin up and one for spin down.\n",
    "\n",
    "We can rewrite it as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07cb99",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Phi(\\mathbf{r}_1,\\mathbf{r}_2,,\\mathbf{r}_3,\\mathbf{r}_4, \\alpha,\\beta,\\gamma,\\delta)=\\det\\uparrow(1,2)\\det\\downarrow(3,4)-\\det\\uparrow(1,3)\\det\\downarrow(2,4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94d1a4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "-\\det\\uparrow(1,4)\\det\\downarrow(3,2)+\\det\\uparrow(2,3)\\det\\downarrow(1,4)-\\det\\uparrow(2,4)\\det\\downarrow(1,3)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa7644",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "+\\det\\uparrow(3,4)\\det\\downarrow(1,2),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9807adcd",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we have defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5e1ed5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\det\\uparrow(1,2)=\\frac{1}{\\sqrt{2}}\\left| \\begin{array}{cc} \\psi_{100\\uparrow}(\\mathbf{r}_1)& \\psi_{100\\uparrow}(\\mathbf{r}_2)\\\\\n",
    "\\psi_{200\\uparrow}(\\mathbf{r}_1)& \\psi_{200\\uparrow}(\\mathbf{r}_2) \\end{array} \\right|,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40cb1a5",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9179ede",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\det\\downarrow(3,4)=\\frac{1}{\\sqrt{2}}\\left| \\begin{array}{cc} \\psi_{100\\downarrow}(\\mathbf{r}_3)& \\psi_{100\\downarrow}(\\mathbf{r}_4)\\\\\n",
    "\\psi_{200\\downarrow}(\\mathbf{r}_3)& \\psi_{200\\downarrow}(\\mathbf{r}_4) \\end{array} \\right|.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f5c9a",
   "metadata": {
    "editable": true
   },
   "source": [
    "We want to avoid to sum over spin variables, in particular when the interaction does not depend on spin.\n",
    "\n",
    "It can be shown, see for example Moskowitz and Kalos, [Int. J. Quantum Chem. **20** 1107 (1981)](http://onlinelibrary.wiley.com/doi/10.1002/qua.560200508/abstract), that for the variational energy\n",
    "we can approximate the Slater determinant as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014a4cd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Phi(\\mathbf{r}_1,\\mathbf{r}_2,,\\mathbf{r}_3,\\mathbf{r}_4, \\alpha,\\beta,\\gamma,\\delta) \\propto \\det\\uparrow(1,2)\\det\\downarrow(3,4),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5beb9d",
   "metadata": {
    "editable": true
   },
   "source": [
    "or more generally as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d455f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Phi(\\mathbf{r}_1,\\mathbf{r}_2,\\dots \\mathbf{r}_N) \\propto \\det\\uparrow \\det\\downarrow,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebb6cd",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we have the Slater determinant as the product of a spin up part involving the number of electrons with spin up only (2 for beryllium and 5 for neon) and a spin down part involving the electrons with spin down.\n",
    "\n",
    "This ansatz is not antisymmetric under the exchange of electrons with  opposite spins but it can be shown (show this) that it gives the same\n",
    "expectation value for the energy as the full Slater determinant.\n",
    "\n",
    "As long as the Hamiltonian is spin independent, the above is correct. It is rather straightforward to see this if you go back to the equations for the energy discussed earlier  this semester.\n",
    "\n",
    "We will thus\n",
    "factorize the full determinant $\\vert\\hat{D}\\vert$ into two smaller ones, where \n",
    "each can be identified with $\\uparrow$ and $\\downarrow$\n",
    "respectively:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7b3a6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\vert\\hat{D}\\vert = \\vert\\hat{D}\\vert_\\uparrow\\cdot \\vert\\hat{D}\\vert_\\downarrow\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2a529",
   "metadata": {
    "editable": true
   },
   "source": [
    "The combined dimensionality of the two smaller determinants equals the\n",
    "dimensionality of the full determinant. Such a factorization is\n",
    "advantageous in that it makes it possible to perform the calculation\n",
    "of the ratio $R$ and the updating of the inverse matrix separately for\n",
    "$\\vert\\hat{D}\\vert_\\uparrow$ and $\\vert\\hat{D}\\vert_\\downarrow$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774717a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\vert\\hat{D}\\vert^\\mathrm{new}}{\\vert\\hat{D}\\vert^\\mathrm{old}} =\n",
    "\\frac{\\vert\\hat{D}\\vert^\\mathrm{new}_\\uparrow}\n",
    "{\\vert\\hat{D}\\vert^\\mathrm{old}_\\uparrow}\\cdot\n",
    "\\frac{\\vert\\hat{D}\\vert^\\mathrm{new}_\\downarrow\n",
    "}{\\vert\\hat{D}\\vert^\\mathrm{old}_\\downarrow}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db3e22",
   "metadata": {
    "editable": true
   },
   "source": [
    "This reduces the calculation time by a constant factor. The maximal\n",
    "time reduction happens in a system of equal numbers of $\\uparrow$ and\n",
    "$\\downarrow$ particles, so that the two factorized determinants are\n",
    "half the size of the original one.\n",
    "\n",
    "Consider the case of moving only one particle  at a time which\n",
    "originally had the following time scaling for one transition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea921b2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "O_R(N)+O_\\mathrm{inverse}(N^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd786dd9",
   "metadata": {
    "editable": true
   },
   "source": [
    "For the factorized determinants one of the two determinants is\n",
    "obviously unaffected by the change so that it cancels from the ratio\n",
    "$R$. \n",
    "\n",
    "Therefore, only one determinant of size $N/2$ is involved in each\n",
    "calculation of $R$ and update of the inverse matrix. The scaling of\n",
    "each transition then becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3847647",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "O_R(N/2)+O_\\mathrm{inverse}(N^2/4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f32d80",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the time scaling when the transitions for all $N$ particles are\n",
    "put together:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df78ba9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "O_R(N^2/2)+O_\\mathrm{inverse}(N^3/4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4f886",
   "metadata": {
    "editable": true
   },
   "source": [
    "which gives the same reduction as in the case of moving all particles\n",
    "at once.\n",
    "\n",
    "Computing the ratios discussed above requires that we maintain \n",
    "the inverse of the Slater matrix evaluated at the current position. \n",
    "Each time a trial position is accepted, the row number $i$ of the Slater \n",
    "matrix changes and updating its inverse has to be carried out. \n",
    "Getting the inverse of an $N \\times N$ matrix by Gaussian elimination has a \n",
    "complexity of order of $\\mathcal{O}(N^3)$ operations, a luxury that we \n",
    "cannot afford for each time a particle  move is accepted.\n",
    "We will use the expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c28caf5",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"updatingInverse\"></div>\n",
    "\n",
    "$$\n",
    "\\label{updatingInverse} \\tag{26}\n",
    "d^{-1}_{kj}(\\mathbf{x^{new}}) = \\left\\{\\begin{array}{l l}\n",
    "  d^{-1}_{kj}(\\mathbf{x^{old}}) - \\frac{d^{-1}_{ki}(\\mathbf{x^{old}})}{R} \\sum_{l=1}^{N} d_{il}(\\mathbf{x^{new}})  d^{-1}_{lj}(\\mathbf{x^{old}}) & \\mbox{if $j \\neq i$}\\nonumber \\\\ \\\\\n",
    " \\frac{d^{-1}_{ki}(\\mathbf{x^{old}})}{R} \\sum_{l=1}^{N} d_{il}(\\mathbf{x^{old}}) d^{-1}_{lj}(\\mathbf{x^{old}}) & \\mbox{if $j=i$}\n",
    "\\end{array} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507286d",
   "metadata": {
    "editable": true
   },
   "source": [
    "This equation scales as $O(N^2)$.\n",
    "The evaluation of the determinant of an $N \\times N$ matrix by standard Gaussian elimination \n",
    "requires $\\mathbf{O}(N^3)$\n",
    "calculations. \n",
    "As there are $Nd$ independent coordinates we need to evaluate $Nd$ Slater determinants \n",
    "for the gradient (quantum force) and $Nd$ for the Laplacian (kinetic energy). \n",
    "With the updating algorithm we need only to invert the Slater \n",
    "determinant matrix once. This can be done by standard LU decomposition methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232af316",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Expectation value of the kinetic energy\n",
    "\n",
    "The expectation value of the kinetic energy expressed in atomic units for electron $i$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ea3f2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\hat{K}_i \\rangle = -\\frac{1}{2}\\frac{\\langle\\Psi|\\nabla_{i}^2|\\Psi \\rangle}{\\langle\\Psi|\\Psi \\rangle},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686fb71",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"kineticE\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\label{kineticE} \\tag{27}\n",
    "K_i = -\\frac{1}{2}\\frac{\\nabla_{i}^{2} \\Psi}{\\Psi}.\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9763e799",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\nabla^2 \\Psi}{\\Psi}  =  \\frac{\\nabla^2 ({\\Psi_{D} \\,  \\Psi_C})}{\\Psi_{D} \\,  \\Psi_C} = \\frac{\\nabla  \\cdot [\\nabla  {(\\Psi_{D} \\,  \\Psi_C)}]}{\\Psi_{D} \\,  \\Psi_C} = \\frac{\\nabla  \\cdot [ \\Psi_C \\nabla  \\Psi_{D} + \\Psi_{D} \\nabla   \\Psi_C]}{\\Psi_{D} \\,  \\Psi_C}\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c458970",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "=  \\frac{\\nabla   \\Psi_C \\cdot \\nabla  \\Psi_{D} +  \\Psi_C \\nabla^2 \\Psi_{D} + \\nabla  \\Psi_{D} \\cdot \\nabla   \\Psi_C + \\Psi_{D} \\nabla^2  \\Psi_C}{\\Psi_{D} \\,  \\Psi_C}\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda5cce",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto7\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\label{_auto7} \\tag{28}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0a39a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto8\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\nabla^2 \\Psi}{\\Psi}\n",
    " =  \\frac{\\nabla^2 \\Psi_{D}}{\\Psi_{D}} + \\frac{\\nabla^2  \\Psi_C}{ \\Psi_C} + 2 \\frac{\\nabla  \\Psi_{D}}{\\Psi_{D}}\\cdot\\frac{\\nabla   \\Psi_C}{ \\Psi_C}\n",
    "\\label{_auto8} \\tag{29}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aefebb",
   "metadata": {
    "editable": true
   },
   "source": [
    "The second derivative of the Jastrow factor divided by the Jastrow factor (the way it enters the kinetic energy) is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250a852d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left[\\frac{\\nabla^2 \\Psi_C}{\\Psi_C}\\right]_x =\\  \n",
    "2\\sum_{k=1}^{N}\n",
    "\\sum_{i=1}^{k-1}\\frac{\\partial^2 g_{ik}}{\\partial x_k^2}\\ +\\ \n",
    "\\sum_{k=1}^N\n",
    "\\left(\n",
    "\\sum_{i=1}^{k-1}\\frac{\\partial g_{ik}}{\\partial x_k} -\n",
    "\\sum_{i=k+1}^{N}\\frac{\\partial g_{ki}}{\\partial x_i}\n",
    "\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0557681",
   "metadata": {
    "editable": true
   },
   "source": [
    "But we have a simple form for the function, namely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb463dc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_{C}=\\prod_{i< j}\\exp{f(r_{ij})}= \\exp{\\left\\{\\sum_{i<j}\\frac{ar_{ij}}{1+\\beta r_{ij}}\\right\\}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370338a",
   "metadata": {
    "editable": true
   },
   "source": [
    "and it is easy to see that for particle  $k$\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f67b56",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\nabla^2_k \\Psi_C}{\\Psi_C }=\n",
    "\\sum_{ij\\ne k}\\frac{(\\mathbf{r}_k-\\mathbf{r}_i)(\\mathbf{r}_k-\\mathbf{r}_j)}{r_{ki}r_{kj}}f'(r_{ki})f'(r_{kj})+\n",
    "\\sum_{j\\ne k}\\left( f''(r_{kj})+\\frac{2}{r_{kj}}f'(r_{kj})\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7f5ca",
   "metadata": {
    "editable": true
   },
   "source": [
    "Using"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39ad0f9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f(r_{ij})= \\frac{ar_{ij}}{1+\\beta r_{ij}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd0da0d",
   "metadata": {
    "editable": true
   },
   "source": [
    "and $g'(r_{kj})=dg(r_{kj})/dr_{kj}$ and \n",
    "$g''(r_{kj})=d^2g(r_{kj})/dr_{kj}^2$  we find that for particle  $k$\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb99061c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\nabla^2_k \\Psi_C}{\\Psi_C }=\n",
    "\\sum_{ij\\ne k}\\frac{(\\mathbf{r}_k-\\mathbf{r}_i)(\\mathbf{r}_k-\\mathbf{r}_j)}{r_{ki}r_{kj}}\\frac{a}{(1+\\beta r_{ki})^2}\n",
    "\\frac{a}{(1+\\beta r_{kj})^2}+\n",
    "\\sum_{j\\ne k}\\left(\\frac{2a}{r_{kj}(1+\\beta r_{kj})^2}-\\frac{2a\\beta}{(1+\\beta r_{kj})^3}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df7227",
   "metadata": {
    "editable": true
   },
   "source": [
    "The gradient and\n",
    "Laplacian can be calculated as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb765b6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\mathbf{\\nabla}_i\\vert\\hat{D}(\\mathbf{r})\\vert}\n",
    "{\\vert\\hat{D}(\\mathbf{r})\\vert} =\n",
    "\\sum_{j=1}^N \\vec\\nabla_i d_{ij}(\\mathbf{r})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}) =\n",
    "\\sum_{j=1}^N \\vec\\nabla_i \\phi_j(\\mathbf{r}_i)\\,\n",
    "d_{ji}^{-1}(\\mathbf{r})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8b3dc",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc20389",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\nabla^2_i\\vert\\hat{D}(\\mathbf{r})\\vert}\n",
    "{\\vert\\hat{D}(\\mathbf{r})\\vert} =\n",
    "\\sum_{j=1}^N \\nabla^2_i d_{ij}(\\mathbf{r})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}) =\n",
    "\\sum_{j=1}^N \\nabla^2_i \\phi_j(\\mathbf{r}_i)\\,\n",
    "d_{ji}^{-1}(\\mathbf{r})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deefd96",
   "metadata": {
    "editable": true
   },
   "source": [
    "The gradient for the determinant is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727eb0cb",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{\\mathbf{\\nabla}_i\\vert\\hat{D}(\\mathbf{r})\\vert}\n",
    "{\\vert\\hat{D}(\\mathbf{r})\\vert} =\n",
    "\\sum_{j=1}^N \\mathbf{\\nabla}_i d_{ij}(\\mathbf{r})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}) =\n",
    "\\sum_{j=1}^N \\mathbf{\\nabla}_i \\phi_j(\\mathbf{r}_i)\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69fb946",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9f2ee",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\Psi_C=\\prod_{i< j}g(r_{ij})= \\exp{\\left\\{\\sum_{i<j}\\frac{ar_{ij}}{1+\\beta r_{ij}}\\right\\}},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1f154",
   "metadata": {
    "editable": true
   },
   "source": [
    "the gradient needed for the quantum force and local energy is easy to compute.  \n",
    "We get for particle  $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86c2f6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{ \\nabla_k \\Psi_C}{ \\Psi_C }= \\sum_{j\\ne k}\\frac{\\mathbf{r}_{kj}}{r_{kj}}\\frac{a}{(1+\\beta r_{kj})^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506e24f",
   "metadata": {
    "editable": true
   },
   "source": [
    "which is rather easy to code.  Remember to sum over all particles  when you compute the local energy.\n",
    "\n",
    "We need to compute the ratio between wave functions, in particular  for the Slater determinants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a013d2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "R =\\sum_{j=1}^N d_{ij}(\\mathbf{r}^{\\mathrm{new}})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}^{\\mathrm{old}}) = \n",
    "\\sum_{j=1}^N \\phi_j(\\mathbf{r}_i^{\\mathrm{new}})\\,\n",
    "d_{ji}^{-1}(\\mathbf{r}^{\\mathrm{old}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63d7b1",
   "metadata": {
    "editable": true
   },
   "source": [
    "What this means is that in order to get the ratio when only the *i*-th\n",
    "particle  has been moved, we only need to calculate the dot\n",
    "product of the vector $\\left(\\phi_1(\\mathbf{r}_i^\\mathrm{new}),\\,\\dots,\\,\n",
    "\\phi_N(\\mathbf{r}_i^\\mathrm{new})\\right)$ of single particle  wave functions\n",
    "evaluated at this new position with the *i*-th column of the inverse\n",
    "matrix $\\hat{D}^{-1}$ evaluated at the original position. Such\n",
    "an operation has a time scaling of $O(N)$. The only extra thing we\n",
    "need to do is to maintain the inverse matrix \n",
    "$\\hat{D}^{-1}(\\mathbf{x}^{\\mathrm{old}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0a5f8",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Gradient Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5ba0c3",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Top-down start\n",
    "\n",
    "* We will start with a top-down view, with a simple harmonic oscillator problem in one dimension as case.\n",
    "\n",
    "* Thereafter we continue with implementing the simplest possible steepest descent approach to our two-electron problem with an electrostatic (Coulomb) interaction. Our code includes also importance sampling. The simple Python code here illustrates the basic elements which need to be included in our own code.\n",
    "\n",
    "* Then we move on to the mathematical description of various gradient methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739cc512",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Motivation\n",
    "\n",
    "Our aim with this part of the project is to be able to\n",
    "* find an optimal value for the variational parameters using only some few Monte Carlo cycles\n",
    "\n",
    "* use these optimal values for the variational parameters to perform a large-scale Monte Carlo calculation\n",
    "\n",
    "To achieve this will look at methods like *Steepest descent* and the *conjugate gradient method*. Both these methods allow us to find\n",
    "the minima of a multivariable  function like our energy (function of several variational parameters). \n",
    "Alternatively, you can always use Newton's method. In particular, since we will normally have one variational parameter,\n",
    "Newton's method can be easily used in finding the minimum of the local energy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7cd03f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Simple example and demonstration\n",
    "\n",
    "Let us illustrate what is needed in our calculations using a simple example, the harmonic oscillator in one dimension.\n",
    "For the harmonic oscillator in one-dimension we have a  trial wave function and probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeffb74",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\psi_T(x;\\alpha) = \\exp{-(\\frac{1}{2}\\alpha^2x^2)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c811c",
   "metadata": {
    "editable": true
   },
   "source": [
    "which results in a local energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb8e19",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{1}{2}\\left(\\alpha^2+x^2(1-\\alpha^4)\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2e50b",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can compare our numerically calculated energies with the exact energy as function of $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c216345b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\overline{E}[\\alpha] = \\frac{1}{4}\\left(\\alpha^2+\\frac{1}{\\alpha^2}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105b74bf",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Simple example and demonstration\n",
    "\n",
    "The derivative of the energy with respect to $\\alpha$ gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2daf7e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{d\\langle  E_L[\\alpha]\\rangle}{d\\alpha} = \\frac{1}{2}\\alpha-\\frac{1}{2\\alpha^3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441f2d2b",
   "metadata": {
    "editable": true
   },
   "source": [
    "and a second derivative which is always positive (meaning that we find a minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25904adb",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{d^2\\langle  E_L[\\alpha]\\rangle}{d\\alpha^2} = \\frac{1}{2}+\\frac{3}{2\\alpha^4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29418241",
   "metadata": {
    "editable": true
   },
   "source": [
    "The condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601fa3c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{d\\langle  E_L[\\alpha]\\rangle}{d\\alpha} = 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73ea93",
   "metadata": {
    "editable": true
   },
   "source": [
    "gives the optimal $\\alpha=1$, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2bfa7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 1: Find the local energy for the harmonic oscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533761d",
   "metadata": {
    "editable": true
   },
   "source": [
    "**a)**\n",
    "Derive the local energy for the harmonic oscillator in one dimension and find its expectation value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c326d130",
   "metadata": {
    "editable": true
   },
   "source": [
    "**b)**\n",
    "Show also that the optimal value of optimal $\\alpha=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a555d",
   "metadata": {
    "editable": true
   },
   "source": [
    "**c)**\n",
    "Repeat the above steps in two dimensions for $N$ bosons or electrons. What is the optimal value of $\\alpha$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06c31e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Variance in the simple model\n",
    "\n",
    "We can also minimize the variance. In our simple model the variance is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca22f177",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\sigma^2[\\alpha]=\\frac{1}{4}\\left(1+(1-\\alpha^4)^2\\frac{3}{4\\alpha^4}\\right)-\\overline{E}^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810278ec",
   "metadata": {
    "editable": true
   },
   "source": [
    "which yields a second derivative which is always positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765f749",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Computing the derivatives\n",
    "\n",
    "In general we end up computing the expectation value of the energy in terms \n",
    "of some parameters $\\alpha_0,\\alpha_1,\\dots,\\alpha_n$\n",
    "and we search for a minimum in this multi-variable parameter space.  \n",
    "This leads to an energy minimization problem *where we need the derivative of the energy as a function of the variational parameters*.\n",
    "\n",
    "In the above example this was easy and we were able to find the expression for the derivative by simple derivations. \n",
    "However, in our actual calculations the energy is represented by a multi-dimensional integral with several variational parameters.\n",
    "How can we can then obtain the derivatives of the energy with respect to the variational parameters without having \n",
    "to resort to expensive numerical derivations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc80cec",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Expressions for finding the derivatives of the local energy\n",
    "\n",
    "To find the derivatives of the local energy expectation value as function of the variational parameters, we can use the chain rule and the hermiticity of the Hamiltonian.  \n",
    "\n",
    "Let us define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924364a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\bar{E}_{\\alpha}=\\frac{d\\langle  E_L[\\alpha]\\rangle}{d\\alpha}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e334d57",
   "metadata": {
    "editable": true
   },
   "source": [
    "as the derivative of the energy with respect to the variational parameter $\\alpha$ (we limit ourselves to one parameter only).\n",
    "In the above example this was easy and we obtain a simple expression for the derivative.\n",
    "We define also the derivative of the trial function (skipping the subindex $T$) as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d77ed",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\bar{\\psi}_{\\alpha}=\\frac{d\\psi[\\alpha]\\rangle}{d\\alpha}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6924c06",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Derivatives of the local energy\n",
    "\n",
    "The elements of the gradient of the local energy are then (using the chain rule and the hermiticity of the Hamiltonian)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0222e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\bar{E}_{\\alpha} = 2\\left( \\langle \\frac{\\bar{\\psi}_{\\alpha}}{\\psi[\\alpha]}E_L[\\alpha]\\rangle -\\langle \\frac{\\bar{\\psi}_{\\alpha}}{\\psi[\\alpha]}\\rangle\\langle E_L[\\alpha] \\rangle\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e31bdef",
   "metadata": {
    "editable": true
   },
   "source": [
    "From a computational point of view it means that you need to compute the expectation values of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c04686",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\frac{\\bar{\\psi}_{\\alpha}}{\\psi[\\alpha]}E_L[\\alpha]\\rangle,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9000156",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb385d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\frac{\\bar{\\psi}_{\\alpha}}{\\psi[\\alpha]}\\rangle\\langle E_L[\\alpha]\\rangle\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faac57e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 2: General expression for the derivative of the energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf32bc1",
   "metadata": {
    "editable": true
   },
   "source": [
    "**a)**\n",
    "Show that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d411a32",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\bar{E}_{\\alpha} = 2\\left( \\langle \\frac{\\bar{\\psi}_{\\alpha}}{\\psi[\\alpha]}E_L[\\alpha]\\rangle -\\langle \\frac{\\bar{\\psi}_{\\alpha}}{\\psi[\\alpha]}\\rangle\\langle E_L[\\alpha] \\rangle\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446d0d4",
   "metadata": {
    "editable": true
   },
   "source": [
    "**b)**\n",
    "Find the corresponding expression for the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddea2496",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Python program for 2-electrons in 2 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38c34cf",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# Added energy minimization with gradient descent using fixed step size\n",
    "# To do: replace with optimization codes from scipy and/or use stochastic gradient descent\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,alpha,beta):\n",
    "    \n",
    "    WfDer  = np.zeros((2), np.double)\n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    WfDer[0] = -0.5*(r1+r2)\n",
    "    WfDer[1] = -r12*r12*deno2\n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha,beta):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha*(r[0,:]-r[1,:])*deno*deno/r12\n",
    "    qforce[1,:] = -2*r[1,:]*alpha*(r[1,:]-r[0,:])*deno*deno/r12\n",
    "    return qforce\n",
    "    \n",
    "\n",
    "# Computing the derivative of the energy and the energy \n",
    "def EnergyMinimization(alpha, beta):\n",
    "\n",
    "    NumberMCcycles= 10000\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator \n",
    "    seed()\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    EnergyDer = np.zeros((2), np.double)\n",
    "    DeltaPsi = np.zeros((2), np.double)\n",
    "    DerivativePsiE = np.zeros((2), np.double)\n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        DerPsi = DerivativeWFansatz(PositionOld,alpha,beta)\n",
    "        DeltaPsi += DerPsi\n",
    "        energy += DeltaE\n",
    "        DerivativePsiE += DerPsi*DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE /= NumberMCcycles\n",
    "    DeltaPsi /= NumberMCcycles\n",
    "    EnergyDer  = 2*(DerivativePsiE-DeltaPsi*energy)\n",
    "    return energy, EnergyDer\n",
    "\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "# guess for variational parameters\n",
    "alpha = 0.9\n",
    "beta = 0.2\n",
    "# Set up iteration using gradient descent method\n",
    "Energy = 0\n",
    "EDerivative = np.zeros((2), np.double)\n",
    "eta = 0.01\n",
    "Niterations = 50\n",
    "# \n",
    "for iter in range(Niterations):\n",
    "    Energy, EDerivative = EnergyMinimization(alpha,beta)\n",
    "    alphagradient = EDerivative[0]\n",
    "    betagradient = EDerivative[1]\n",
    "    alpha -= eta*alphagradient\n",
    "    beta -= eta*betagradient \n",
    "\n",
    "print(alpha, beta)\n",
    "print(Energy, EDerivative[0], EDerivative[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f8074",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Using Broyden's algorithm in scipy\n",
    "The following function uses the above described BFGS algorithm. Here we have defined a function which calculates the energy and a function which computes the first derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156b8e35",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# Added energy minimization using the BFGS algorithm, see p. 136 of https://www.springer.com/it/book/9780387303031\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,alpha,beta):\n",
    "    r1 = r[0,0]**2 + r[0,1]**2\n",
    "    r2 = r[1,0]**2 + r[1,1]**2\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = r12/(1+beta*r12)\n",
    "    return exp(-0.5*alpha*(r1+r2)+deno)\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,alpha,beta):\n",
    "    \n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    return 0.5*(1-alpha*alpha)*(r1 + r2) +2.0*alpha + 1.0/r12+deno2*(alpha*r12-deno2+2*beta*deno-1.0/r12)\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,alpha,beta):\n",
    "    \n",
    "    WfDer  = np.zeros((2), np.double)\n",
    "    r1 = (r[0,0]**2 + r[0,1]**2)\n",
    "    r2 = (r[1,0]**2 + r[1,1]**2)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    deno2 = deno*deno\n",
    "    WfDer[0] = -0.5*(r1+r2)\n",
    "    WfDer[1] = -r12*r12*deno2\n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,alpha,beta):\n",
    "\n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    r12 = sqrt((r[0,0]-r[1,0])**2 + (r[0,1]-r[1,1])**2)\n",
    "    deno = 1.0/(1+beta*r12)\n",
    "    qforce[0,:] = -2*r[0,:]*alpha*(r[0,:]-r[1,:])*deno*deno/r12\n",
    "    qforce[1,:] = -2*r[1,:]*alpha*(r[1,:]-r[0,:])*deno*deno/r12\n",
    "    return qforce\n",
    "    \n",
    "\n",
    "# Computing the derivative of the energy and the energy \n",
    "def EnergyDerivative(x0):\n",
    "\n",
    "    \n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    NumberMCcycles= 10000\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    alpha = x0[0]\n",
    "    beta = x0[1]\n",
    "    EnergyDer = 0.0\n",
    "    DeltaPsi = 0.0\n",
    "    DerivativePsiE = 0.0 \n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        DerPsi = DerivativeWFansatz(PositionOld,alpha,beta)\n",
    "        DeltaPsi += DerPsi\n",
    "        energy += DeltaE\n",
    "        DerivativePsiE += DerPsi*DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE /= NumberMCcycles\n",
    "    DeltaPsi /= NumberMCcycles\n",
    "    EnergyDer  = 2*(DerivativePsiE-DeltaPsi*energy)\n",
    "    return EnergyDer\n",
    "\n",
    "\n",
    "# Computing the expectation value of the local energy \n",
    "def Energy(x0):\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "    alpha = x0[0]\n",
    "    beta = x0[1]\n",
    "    NumberMCcycles= 10000\n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,alpha,beta)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,alpha, beta)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,alpha,beta)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,alpha, beta)\n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "\t                              (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        DeltaE = LocalEnergy(PositionOld,alpha,beta)\n",
    "        energy += DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    return energy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "# seed for rng generator \n",
    "seed()\n",
    "# guess for variational parameters\n",
    "x0 = np.array([0.9,0.2])\n",
    "# Using Broydens method\n",
    "res = minimize(Energy, x0, method='BFGS', jac=EnergyDerivative, options={'gtol': 1e-4,'disp': True})\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5628ba8c",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that the **minimize** function returns the finale values for the variable $\\alpha=x0[0]$ and $\\beta=x0[1]$ in the array $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e2214",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Brief reminder on Newton-Raphson's method\n",
    "\n",
    "Let us quickly remind ourselves how we derive the above method.\n",
    "\n",
    "Perhaps the most celebrated of all one-dimensional root-finding\n",
    "routines is Newton's method, also called the Newton-Raphson\n",
    "method. This method  requires the evaluation of both the\n",
    "function $f$ and its derivative $f'$ at arbitrary points. \n",
    "If you can only calculate the derivative\n",
    "numerically and/or your function is not of the smooth type, we\n",
    "normally discourage the use of this method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a60682",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The equations\n",
    "\n",
    "The Newton-Raphson formula consists geometrically of extending the\n",
    "tangent line at a current point until it crosses zero, then setting\n",
    "the next guess to the abscissa of that zero-crossing.  The mathematics\n",
    "behind this method is rather simple. Employing a Taylor expansion for\n",
    "$x$ sufficiently close to the solution $s$, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a5035",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:taylornr\"></div>\n",
    "\n",
    "$$\n",
    "f(s)=0=f(x)+(s-x)f'(x)+\\frac{(s-x)^2}{2}f''(x) +\\dots.\n",
    "    \\label{eq:taylornr} \\tag{30}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a7139",
   "metadata": {
    "editable": true
   },
   "source": [
    "For small enough values of the function and for well-behaved\n",
    "functions, the terms beyond linear are unimportant, hence we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63faab8",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f(x)+(s-x)f'(x)\\approx 0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d69e3",
   "metadata": {
    "editable": true
   },
   "source": [
    "yielding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9f7e7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "s\\approx x-\\frac{f(x)}{f'(x)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22129f28",
   "metadata": {
    "editable": true
   },
   "source": [
    "Having in mind an iterative procedure, it is natural to start iterating with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85295716",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "x_{n+1}=x_n-\\frac{f(x_n)}{f'(x_n)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775dc6e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Simple geometric interpretation\n",
    "\n",
    "The above is Newton-Raphson's method. It has a simple geometric\n",
    "interpretation, namely $x_{n+1}$ is the point where the tangent from\n",
    "$(x_n,f(x_n))$ crosses the $x$-axis.  Close to the solution,\n",
    "Newton-Raphson converges fast to the desired result. However, if we\n",
    "are far from a root, where the higher-order terms in the series are\n",
    "important, the Newton-Raphson formula can give grossly inaccurate\n",
    "results. For instance, the initial guess for the root might be so far\n",
    "from the true root as to let the search interval include a local\n",
    "maximum or minimum of the function.  If an iteration places a trial\n",
    "guess near such a local extremum, so that the first derivative nearly\n",
    "vanishes, then Newton-Raphson may fail totally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efff9b",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Extending to more than one variable\n",
    "\n",
    "Newton's method can be generalized to systems of several non-linear equations\n",
    "and variables. Consider the case with two equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42999b5c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{array}{cc} f_1(x_1,x_2) &=0\\\\\n",
    "                     f_2(x_1,x_2) &=0,\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8884a8",
   "metadata": {
    "editable": true
   },
   "source": [
    "which we Taylor expand to obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54cefd4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{array}{cc} 0=f_1(x_1+h_1,x_2+h_2)=&f_1(x_1,x_2)+h_1\n",
    "                     \\partial f_1/\\partial x_1+h_2\n",
    "                     \\partial f_1/\\partial x_2+\\dots\\\\\n",
    "                     0=f_2(x_1+h_1,x_2+h_2)=&f_2(x_1,x_2)+h_1\n",
    "                     \\partial f_2/\\partial x_1+h_2\n",
    "                     \\partial f_2/\\partial x_2+\\dots\n",
    "                       \\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1034c0",
   "metadata": {
    "editable": true
   },
   "source": [
    "Defining the Jacobian matrix $\\hat{J}$ we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb96199",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{J}=\\left( \\begin{array}{cc}\n",
    "                         \\partial f_1/\\partial x_1  & \\partial f_1/\\partial x_2 \\\\\n",
    "                          \\partial f_2/\\partial x_1     &\\partial f_2/\\partial x_2\n",
    "             \\end{array} \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e368ba2a",
   "metadata": {
    "editable": true
   },
   "source": [
    "we can rephrase Newton's method as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a99e0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left(\\begin{array}{c} x_1^{n+1} \\\\ x_2^{n+1} \\end{array} \\right)=\n",
    "\\left(\\begin{array}{c} x_1^{n} \\\\ x_2^{n} \\end{array} \\right)+\n",
    "\\left(\\begin{array}{c} h_1^{n} \\\\ h_2^{n} \\end{array} \\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbaec1",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we have defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253d633",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\left(\\begin{array}{c} h_1^{n} \\\\ h_2^{n} \\end{array} \\right)=\n",
    "   -{\\bf \\hat{J}}^{-1}\n",
    "   \\left(\\begin{array}{c} f_1(x_1^{n},x_2^{n}) \\\\ f_2(x_1^{n},x_2^{n}) \\end{array} \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1413a9d",
   "metadata": {
    "editable": true
   },
   "source": [
    "We need thus to compute the inverse of the Jacobian matrix and it\n",
    "is to understand that difficulties  may\n",
    "arise in case $\\hat{J}$ is nearly singular.\n",
    "\n",
    "It is rather straightforward to extend the above scheme to systems of\n",
    "more than two non-linear equations. In our case, the Jacobian matrix is given by the Hessian that represents the second derivative of cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfed9d9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Steepest descent\n",
    "\n",
    "The basic idea of gradient descent is\n",
    "that a function $F(\\mathbf{x})$, \n",
    "$\\mathbf{x} \\equiv (x_1,\\cdots,x_n)$, decreases fastest if one goes from $\\bf {x}$ in the\n",
    "direction of the negative gradient $-\\nabla F(\\mathbf{x})$.\n",
    "\n",
    "It can be shown that if"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938cee7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\gamma_k \\nabla F(\\mathbf{x}_k),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a7f05b",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\gamma_k > 0$.\n",
    "\n",
    "For $\\gamma_k$ small enough, then $F(\\mathbf{x}_{k+1}) \\leq\n",
    "F(\\mathbf{x}_k)$. This means that for a sufficiently small $\\gamma_k$\n",
    "we are always moving towards smaller function values, i.e a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcbb5c1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on Steepest descent\n",
    "\n",
    "The previous observation is the basis of the method of steepest\n",
    "descent, which is also referred to as just gradient descent (GD). One\n",
    "starts with an initial guess $\\mathbf{x}_0$ for a minimum of $F$ and\n",
    "computes new approximations according to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5e3435",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\gamma_k \\nabla F(\\mathbf{x}_k), \\ \\ k \\geq 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41971857",
   "metadata": {
    "editable": true
   },
   "source": [
    "The parameter $\\gamma_k$ is often referred to as the step length or\n",
    "the learning rate within the context of Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6f6bae",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The ideal\n",
    "\n",
    "Ideally the sequence $\\{\\mathbf{x}_k \\}_{k=0}$ converges to a global\n",
    "minimum of the function $F$. In general we do not know if we are in a\n",
    "global or local minimum. In the special case when $F$ is a convex\n",
    "function, all local minima are also global minima, so in this case\n",
    "gradient descent can converge to the global solution. The advantage of\n",
    "this scheme is that it is conceptually simple and straightforward to\n",
    "implement. However the method in this form has some severe\n",
    "limitations:\n",
    "\n",
    "In machine learing we are often faced with non-convex high dimensional\n",
    "cost functions with many local minima. Since GD is deterministic we\n",
    "will get stuck in a local minimum, if the method converges, unless we\n",
    "have a very good intial guess. This also implies that the scheme is\n",
    "sensitive to the chosen initial condition.\n",
    "\n",
    "Note that the gradient is a function of $\\mathbf{x} =\n",
    "(x_1,\\cdots,x_n)$ which makes it expensive to compute numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6d4715",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The sensitiveness of the gradient descent\n",
    "\n",
    "The gradient descent method \n",
    "is sensitive to the choice of learning rate $\\gamma_k$. This is due\n",
    "to the fact that we are only guaranteed that $F(\\mathbf{x}_{k+1}) \\leq\n",
    "F(\\mathbf{x}_k)$ for sufficiently small $\\gamma_k$. The problem is to\n",
    "determine an optimal learning rate. If the learning rate is chosen too\n",
    "small the method will take a long time to converge and if it is too\n",
    "large we can experience erratic behavior.\n",
    "\n",
    "Many of these shortcomings can be alleviated by introducing\n",
    "randomness. One such method is that of Stochastic Gradient Descent\n",
    "(SGD), see below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95727703",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Convex functions\n",
    "\n",
    "Ideally we want our cost/loss function to be convex(concave).\n",
    "\n",
    "First we give the definition of a convex set: A set $C$ in\n",
    "$\\mathbb{R}^n$ is said to be convex if, for all $x$ and $y$ in $C$ and\n",
    "all $t \\in (0,1)$ , the point $(1  t)x + ty$ also belongs to\n",
    "C. Geometrically this means that every point on the line segment\n",
    "connecting $x$ and $y$ is in $C$ as discussed below.\n",
    "\n",
    "The convex subsets of $\\mathbb{R}$ are the intervals of\n",
    "$\\mathbb{R}$. Examples of convex sets of $\\mathbb{R}^2$ are the\n",
    "regular polygons (triangles, rectangles, pentagons, etc...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab292bf6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Convex function\n",
    "\n",
    "**Convex function**: Let $X \\subset \\mathbb{R}^n$ be a convex set. Assume that the function $f: X \\rightarrow \\mathbb{R}$ is continuous, then $f$ is said to be convex if $$f(tx_1 + (1-t)x_2) \\leq tf(x_1) + (1-t)f(x_2) $$ for all $x_1, x_2 \\in X$ and for all $t \\in [0,1]$. If $\\leq$ is replaced with a strict inequaltiy in the definition, we demand $x_1 \\neq x_2$ and $t\\in(0,1)$ then $f$ is said to be strictly convex. For a single variable function, convexity means that if you draw a straight line connecting $f(x_1)$ and $f(x_2)$, the value of the function on the interval $[x_1,x_2]$ is always below the line as illustrated below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c157e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conditions on convex functions\n",
    "\n",
    "In the following we state first and second-order conditions which\n",
    "ensures convexity of a function $f$. We write $D_f$ to denote the\n",
    "domain of $f$, i.e the subset of $R^n$ where $f$ is defined. For more\n",
    "details and proofs we refer to: [S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press](http://stanford.edu/boyd/cvxbook/, 2004).\n",
    "\n",
    " First order condition\n",
    "Suppose $f$ is differentiable (i.e $\\nabla f(x)$ is well defined for\n",
    "all $x$ in the domain of $f$). Then $f$ is convex if and only if $D_f$\n",
    "is a convex set and $$f(y) \\geq f(x) + \\nabla f(x)^T (y-x) $$ holds\n",
    "for all $x,y \\in D_f$. This condition means that for a convex function\n",
    "the first order Taylor expansion (right hand side above) at any point\n",
    "a global under estimator of the function. To convince yourself you can\n",
    "make a drawing of $f(x) = x^2+1$ and draw the tangent line to $f(x)$ and\n",
    "note that it is always below the graph.  \n",
    "\n",
    " Second order condition \n",
    "Assume that $f$ is twice\n",
    "differentiable, i.e the Hessian matrix exists at each point in\n",
    "$D_f$. Then $f$ is convex if and only if $D_f$ is a convex set and its\n",
    "Hessian is positive semi-definite for all $x\\in D_f$. For a\n",
    "single-variable function this reduces to $f''(x) \\geq 0$. Geometrically this means that $f$ has nonnegative curvature\n",
    "everywhere.\n",
    "\n",
    "This condition is particularly useful since it gives us an procedure for determining if the function under consideration is convex, apart from using the definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39f855",
   "metadata": {
    "editable": true
   },
   "source": [
    "## More on convex functions\n",
    "\n",
    "The next result is of great importance to us and the reason why we are\n",
    "going on about convex functions. In machine learning we frequently\n",
    "have to minimize a loss/cost function in order to find the best\n",
    "parameters for the model we are considering. \n",
    "\n",
    "Ideally we want the\n",
    "global minimum (for high-dimensional models it is hard to know\n",
    "if we have local or global minimum). However, if the cost/loss function\n",
    "is convex the following result provides invaluable information:\n",
    "\n",
    " Any minimum is global for convex functions\n",
    "Consider the problem of finding $x \\in \\mathbb{R}^n$ such that $f(x)$\n",
    "is minimal, where $f$ is convex and differentiable. Then, any point\n",
    "$x^*$ that satisfies $\\nabla f(x^*) = 0$ is a global minimum.\n",
    "\n",
    "This result means that if we know that the cost/loss function is convex and we are able to find a minimum, we are guaranteed that it is a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8142a9",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Some simple problems\n",
    "\n",
    "1. Show that $f(x)=x^2$ is convex for $x \\in \\mathbb{R}$ using the definition of convexity. Hint: If you re-write the definition, $f$ is convex if the following holds for all $x,y \\in D_f$ and any $\\lambda \\in [0,1]$ $\\lambda f(x)+(1-\\lambda)f(y)-f(\\lambda x + (1-\\lambda) y ) \\geq 0$.\n",
    "\n",
    "2. Using the second order condition show that the following functions are convex on the specified domain.\n",
    "\n",
    " * $f(x) = e^x$ is convex for $x \\in \\mathbb{R}$.\n",
    "\n",
    " * $g(x) = -\\ln(x)$ is convex for $x \\in (0,\\infty)$.\n",
    "\n",
    "3. Let $f(x) = x^2$ and $g(x) = e^x$. Show that $f(g(x))$ and $g(f(x))$ is convex for $x \\in \\mathbb{R}$. Also show that if $f(x)$ is any convex function than $h(x) = e^{f(x)}$ is convex.\n",
    "\n",
    "4. A norm is any function that satisfy the following properties\n",
    "\n",
    " * $f(\\alpha x) = |\\alpha| f(x)$ for all $\\alpha \\in \\mathbb{R}$.\n",
    "\n",
    " * $f(x+y) \\leq f(x) + f(y)$\n",
    "\n",
    " * $f(x) \\leq 0$ for all $x \\in \\mathbb{R}^n$ with equality if and only if $x = 0$\n",
    "\n",
    "Using the definition of convexity, try to show that a function satisfying the properties above is convex (the third condition is not needed to show this)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fcee76",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Standard steepest descent\n",
    "\n",
    "Before we proceed, we would like to discuss the approach called the\n",
    "**standard Steepest descent**, which again leads to us having to be able\n",
    "to compute a matrix. It belongs to the class of Conjugate Gradient methods (CG).\n",
    "\n",
    "[The success of the CG method](https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf)\n",
    "for finding solutions of non-linear problems is based on the theory\n",
    "of conjugate gradients for linear systems of equations. It belongs to\n",
    "the class of iterative methods for solving problems from linear\n",
    "algebra of the type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d10c855",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{x} = \\hat{b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d1b98",
   "metadata": {
    "editable": true
   },
   "source": [
    "In the iterative process we end up with a problem like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563c3e3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{r}= \\hat{b}-\\hat{A}\\hat{x},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bb35c",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\hat{r}$ is the so-called residual or error in the iterative process.\n",
    "\n",
    "When we have found the exact solution, $\\hat{r}=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc827e1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Gradient method\n",
    "\n",
    "The residual is zero when we reach the minimum of the quadratic equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db44e56",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P(\\hat{x})=\\frac{1}{2}\\hat{x}^T\\hat{A}\\hat{x} - \\hat{x}^T\\hat{b},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53692e",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the constraint that the matrix $\\hat{A}$ is positive definite and\n",
    "symmetric.  This defines also the Hessian and we want it to be  positive definite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f4325",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Steepest descent  method\n",
    "\n",
    "We denote the initial guess for $\\hat{x}$ as $\\hat{x}_0$. \n",
    "We can assume without loss of generality that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182f4644",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{x}_0=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ad4b5",
   "metadata": {
    "editable": true
   },
   "source": [
    "or consider the system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e912c8b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{z} = \\hat{b}-\\hat{A}\\hat{x}_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb295cc",
   "metadata": {
    "editable": true
   },
   "source": [
    "instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2319e4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Steepest descent  method\n",
    "\n",
    "One can show that the solution $\\hat{x}$ is also the unique minimizer of the quadratic form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff52a02",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f(\\hat{x}) = \\frac{1}{2}\\hat{x}^T\\hat{A}\\hat{x} - \\hat{x}^T \\hat{x} , \\quad \\hat{x}\\in\\mathbf{R}^n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44d412",
   "metadata": {
    "editable": true
   },
   "source": [
    "This suggests taking the first basis vector $\\hat{r}_1$ (see below for definition) \n",
    "to be the gradient of $f$ at $\\hat{x}=\\hat{x}_0$, \n",
    "which equals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04761c21",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{x}_0-\\hat{b},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edab1aa",
   "metadata": {
    "editable": true
   },
   "source": [
    "and \n",
    "$\\hat{x}_0=0$ it is equal $-\\hat{b}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c8669",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Final expressions\n",
    "\n",
    "We can compute the residual iteratively as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610bd2e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{r}_{k+1}=\\hat{b}-\\hat{A}\\hat{x}_{k+1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c506f",
   "metadata": {
    "editable": true
   },
   "source": [
    "which equals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e4300",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{b}-\\hat{A}(\\hat{x}_k+\\alpha_k\\hat{r}_k),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda1c43",
   "metadata": {
    "editable": true
   },
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f19e53c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "(\\hat{b}-\\hat{A}\\hat{x}_k)-\\alpha_k\\hat{A}\\hat{r}_k,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9608723",
   "metadata": {
    "editable": true
   },
   "source": [
    "which gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a354f71",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\alpha_k = \\frac{\\hat{r}_k^T\\hat{r}_k}{\\hat{r}_k^T\\hat{A}\\hat{r}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dd345c",
   "metadata": {
    "editable": true
   },
   "source": [
    "leading to the iterative scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796206b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{x}_{k+1}=\\hat{x}_k-\\alpha_k\\hat{r}_{k},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c665c901",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method\n",
    "\n",
    "In the CG method we define so-called conjugate directions and two vectors \n",
    "$\\hat{s}$ and $\\hat{t}$\n",
    "are said to be\n",
    "conjugate if"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14832cf3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{s}^T\\hat{A}\\hat{t}= 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d584c",
   "metadata": {
    "editable": true
   },
   "source": [
    "The philosophy of the CG method is to perform searches in various conjugate directions\n",
    "of our vectors $\\hat{x}_i$ obeying the above criterion, namely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f78569",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{x}_i^T\\hat{A}\\hat{x}_j= 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d77753b",
   "metadata": {
    "editable": true
   },
   "source": [
    "Two vectors are conjugate if they are orthogonal with respect to \n",
    "this inner product. Being conjugate is a symmetric relation: if $\\hat{s}$ is conjugate to $\\hat{t}$, then $\\hat{t}$ is conjugate to $\\hat{s}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aababe1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method\n",
    "\n",
    "An example is given by the eigenvectors of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f7d5b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{v}_i^T\\hat{A}\\hat{v}_j= \\lambda\\hat{v}_i^T\\hat{v}_j,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca8a7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "which is zero unless $i=j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e567462",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method\n",
    "\n",
    "Assume now that we have a symmetric positive-definite matrix $\\hat{A}$ of size\n",
    "$n\\times n$. At each iteration $i+1$ we obtain the conjugate direction of a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c514156d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{x}_{i+1}=\\hat{x}_{i}+\\alpha_i\\hat{p}_{i}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dc446",
   "metadata": {
    "editable": true
   },
   "source": [
    "We assume that $\\hat{p}_{i}$ is a sequence of $n$ mutually conjugate directions. \n",
    "Then the $\\hat{p}_{i}$  form a basis of $R^n$ and we can expand the solution \n",
    "$  \\hat{A}\\hat{x} = \\hat{b}$ in this basis, namely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5523fbb",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{x}  = \\sum^{n}_{i=1} \\alpha_i \\hat{p}_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766067e7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method\n",
    "\n",
    "The coefficients are given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52538d41",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{A}\\mathbf{x} = \\sum^{n}_{i=1} \\alpha_i \\mathbf{A} \\mathbf{p}_i = \\mathbf{b}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321fe3e",
   "metadata": {
    "editable": true
   },
   "source": [
    "Multiplying with $\\hat{p}_k^T$  from the left gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fb70e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{p}_k^T \\hat{A}\\hat{x} = \\sum^{n}_{i=1} \\alpha_i\\hat{p}_k^T \\hat{A}\\hat{p}_i= \\hat{p}_k^T \\hat{b},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde29f6",
   "metadata": {
    "editable": true
   },
   "source": [
    "and we can define the coefficients $\\alpha_k$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1650ae4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\alpha_k = \\frac{\\hat{p}_k^T \\hat{b}}{\\hat{p}_k^T \\hat{A} \\hat{p}_k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77851887",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method and iterations\n",
    "\n",
    "If we choose the conjugate vectors $\\hat{p}_k$ carefully, \n",
    "then we may not need all of them to obtain a good approximation to the solution \n",
    "$\\hat{x}$. \n",
    "We want to regard the conjugate gradient method as an iterative method. \n",
    "This will us to solve systems where $n$ is so large that the direct \n",
    "method would take too much time.\n",
    "\n",
    "We denote the initial guess for $\\hat{x}$ as $\\hat{x}_0$. \n",
    "We can assume without loss of generality that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ac669f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{x}_0=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2ef1f",
   "metadata": {
    "editable": true
   },
   "source": [
    "or consider the system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ea5c9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{z} = \\hat{b}-\\hat{A}\\hat{x}_0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a4b493",
   "metadata": {
    "editable": true
   },
   "source": [
    "instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c70d74",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method\n",
    "\n",
    "One can show that the solution $\\hat{x}$ is also the unique minimizer of the quadratic form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06cf7f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f(\\hat{x}) = \\frac{1}{2}\\hat{x}^T\\hat{A}\\hat{x} - \\hat{x}^T \\hat{x} , \\quad \\hat{x}\\in\\mathbf{R}^n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f4776",
   "metadata": {
    "editable": true
   },
   "source": [
    "This suggests taking the first basis vector $\\hat{p}_1$ \n",
    "to be the gradient of $f$ at $\\hat{x}=\\hat{x}_0$, \n",
    "which equals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f779cc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{A}\\hat{x}_0-\\hat{b},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b69cb",
   "metadata": {
    "editable": true
   },
   "source": [
    "and \n",
    "$\\hat{x}_0=0$ it is equal $-\\hat{b}$.\n",
    "The other vectors in the basis will be conjugate to the gradient, \n",
    "hence the name conjugate gradient method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a7682",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method\n",
    "\n",
    "Let  $\\hat{r}_k$ be the residual at the $k$-th step:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d8cca",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{r}_k=\\hat{b}-\\hat{A}\\hat{x}_k.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0bc606",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that $\\hat{r}_k$ is the negative gradient of $f$ at \n",
    "$\\hat{x}=\\hat{x}_k$, \n",
    "so the gradient descent method would be to move in the direction $\\hat{r}_k$. \n",
    "Here, we insist that the directions $\\hat{p}_k$ are conjugate to each other, \n",
    "so we take the direction closest to the gradient $\\hat{r}_k$  \n",
    "under the conjugacy constraint. \n",
    "This gives the following expression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118be533",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{p}_{k+1}=\\hat{r}_k-\\frac{\\hat{p}_k^T \\hat{A}\\hat{r}_k}{\\hat{p}_k^T\\hat{A}\\hat{p}_k} \\hat{p}_k.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af5a1c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Conjugate gradient method\n",
    "\n",
    "We can also  compute the residual iteratively as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31703357",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{r}_{k+1}=\\hat{b}-\\hat{A}\\hat{x}_{k+1},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee36d759",
   "metadata": {
    "editable": true
   },
   "source": [
    "which equals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b10196",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{b}-\\hat{A}(\\hat{x}_k+\\alpha_k\\hat{p}_k),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214cfe4a",
   "metadata": {
    "editable": true
   },
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fb629",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "(\\hat{b}-\\hat{A}\\hat{x}_k)-\\alpha_k\\hat{A}\\hat{p}_k,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eabb9a",
   "metadata": {
    "editable": true
   },
   "source": [
    "which gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0c98a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{r}_{k+1}=\\hat{r}_k-\\hat{A}\\hat{p}_{k},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e5c4a3",
   "metadata": {
    "editable": true
   },
   "source": [
    "## BroydenFletcherGoldfarbShanno algorithm\n",
    "\n",
    "The optimization problem is to minimize $f(\\mathbf {x} )$ where $\\mathbf {x}$  is a vector in $R^{n}$, and $f$ is a differentiable scalar function. There are no constraints on the values that  $\\mathbf {x}$  can take.\n",
    "\n",
    "The algorithm begins at an initial estimate for the optimal value $\\mathbf {x}_{0}$ and proceeds iteratively to get a better estimate at each stage.\n",
    "\n",
    "The search direction $p_k$ at stage $k$ is given by the solution of the analogue of the Newton equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a1a79",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "B_{k}\\mathbf {p} _{k}=-\\nabla f(\\mathbf {x}_{k}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871d4bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $B_{k}$ is an approximation to the Hessian matrix, which is\n",
    "updated iteratively at each stage, and $\\nabla f(\\mathbf {x} _{k})$\n",
    "is the gradient of the function\n",
    "evaluated at $x_k$. \n",
    "A line search in the direction $p_k$ is then used to\n",
    "find the next point $x_{k+1}$ by minimising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2d8b47",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f(\\mathbf {x}_{k}+\\alpha \\mathbf {p}_{k}),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc8b0ac",
   "metadata": {
    "editable": true
   },
   "source": [
    "over the scalar $\\alpha > 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b72f43",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "Stochastic gradient descent (SGD) and variants thereof address some of\n",
    "the shortcomings of the Gradient descent method discussed above.\n",
    "\n",
    "The underlying idea of SGD comes from the observation that a given \n",
    "function, which we want to minimize, can almost always be written as a\n",
    "sum over $n$ data points $\\{\\mathbf{x}_i\\}_{i=1}^n$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a7e5ac",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "C(\\mathbf{\\beta}) = \\sum_{i=1}^n c_i(\\mathbf{x}_i,\n",
    "\\mathbf{\\beta}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e33f5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Computation of gradients\n",
    "\n",
    "This in turn means that the gradient can be\n",
    "computed as a sum over $i$-gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9d4df2",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_\\beta C(\\mathbf{\\beta}) = \\sum_i^n \\nabla_\\beta c_i(\\mathbf{x}_i,\n",
    "\\mathbf{\\beta}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30ae53",
   "metadata": {
    "editable": true
   },
   "source": [
    "Stochasticity/randomness is introduced by only taking the\n",
    "gradient on a subset of the data called minibatches.  If there are $n$\n",
    "data points and the size of each minibatch is $M$, there will be $n/M$\n",
    "minibatches. We denote these minibatches by $B_k$ where\n",
    "$k=1,\\cdots,n/M$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d197f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## SGD example\n",
    "As an example, suppose we have $10$ data points $(\\mathbf{x}_1,\\cdots, \\mathbf{x}_{10})$ \n",
    "and we choose to have $M=5$ minibathces,\n",
    "then each minibatch contains two data points. In particular we have\n",
    "$B_1 = (\\mathbf{x}_1,\\mathbf{x}_2), \\cdots, B_5 =\n",
    "(\\mathbf{x}_9,\\mathbf{x}_{10})$. Note that if you choose $M=1$ you\n",
    "have only a single batch with all data points and on the other extreme,\n",
    "you may choose $M=n$ resulting in a minibatch for each datapoint, i.e\n",
    "$B_k = \\mathbf{x}_k$.\n",
    "\n",
    "The idea is now to approximate the gradient by replacing the sum over\n",
    "all data points with a sum over the data points in one the minibatches\n",
    "picked at random in each gradient descent step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da5139",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\nabla_{\\beta}\n",
    "C(\\mathbf{\\beta}) = \\sum_{i=1}^n \\nabla_\\beta c_i(\\mathbf{x}_i,\n",
    "\\mathbf{\\beta}) \\rightarrow \\sum_{i \\in B_k}^n \\nabla_\\beta\n",
    "c_i(\\mathbf{x}_i, \\mathbf{\\beta}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c42037",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The gradient step\n",
    "\n",
    "Thus a gradient descent step now looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf524d17",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\beta_{j+1} = \\beta_j - \\gamma_j \\sum_{i \\in B_k}^n \\nabla_\\beta c_i(\\mathbf{x}_i,\n",
    "\\mathbf{\\beta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d51c94",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $k$ is picked at random with equal\n",
    "probability from $[1,n/M]$. An iteration over the number of\n",
    "minibathces (n/M) is commonly referred to as an epoch. Thus it is\n",
    "typical to choose a number of epochs and for each epoch iterate over\n",
    "the number of minibatches, as exemplified in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b645d6d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Simple example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2843ba53",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "n = 100 #100 datapoints \n",
    "M = 5   #size of each minibatch\n",
    "m = int(n/M) #number of minibatches\n",
    "n_epochs = 10 #number of epochs\n",
    "\n",
    "j = 0\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for i in range(m):\n",
    "        k = np.random.randint(m) #Pick the k-th minibatch at random\n",
    "        #Compute the gradient using the data in minibatch Bk\n",
    "        #Compute new suggestion for \n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa41d9",
   "metadata": {
    "editable": true
   },
   "source": [
    "Taking the gradient only on a subset of the data has two important\n",
    "benefits. First, it introduces randomness which decreases the chance\n",
    "that our opmization scheme gets stuck in a local minima. Second, if\n",
    "the size of the minibatches are small relative to the number of\n",
    "datapoints ($M <  n$), the computation of the gradient is much\n",
    "cheaper since we sum over the datapoints in the $k-th$ minibatch and not\n",
    "all $n$ datapoints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c080da",
   "metadata": {
    "editable": true
   },
   "source": [
    "## When do we stop?\n",
    "\n",
    "A natural question is when do we stop the search for a new minimum?\n",
    "One possibility is to compute the full gradient after a given number\n",
    "of epochs and check if the norm of the gradient is smaller than some\n",
    "threshold and stop if true. However, the condition that the gradient\n",
    "is zero is valid also for local minima, so this would only tell us\n",
    "that we are close to a local/global minimum. However, we could also\n",
    "evaluate the cost function at this point, store the result and\n",
    "continue the search. If the test kicks in at a later stage we can\n",
    "compare the values of the cost function and keep the $\\beta$ that\n",
    "gave the lowest value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc360541",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Slightly different approach\n",
    "\n",
    "Another approach is to let the step length $\\gamma_j$ depend on the\n",
    "number of epochs in such a way that it becomes very small after a\n",
    "reasonable time such that we do not move at all.\n",
    "\n",
    "As an example, let $e = 0,1,2,3,\\cdots$ denote the current epoch and let $t_0, t_1 > 0$ be two fixed numbers. Furthermore, let $t = e \\cdot m + i$ where $m$ is the number of minibatches and $i=0,\\cdots,m-1$. Then the function $$\\gamma_j(t; t_0, t_1) = \\frac{t_0}{t+t_1} $$ goes to zero as the number of epochs gets large. I.e. we start with a step length $\\gamma_j (0; t_0, t_1) = t_0/t_1$ which decays in *time* $t$.\n",
    "\n",
    "In this way we can fix the number of epochs, compute $\\beta$ and\n",
    "evaluate the cost function at the end. Repeating the computation will\n",
    "give a different result since the scheme is random by design. Then we\n",
    "pick the final $\\beta$ that gives the lowest value of the cost\n",
    "function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50d17c8",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def step_length(t,t0,t1):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "n = 100 #100 datapoints \n",
    "M = 5   #size of each minibatch\n",
    "m = int(n/M) #number of minibatches\n",
    "n_epochs = 500 #number of epochs\n",
    "t0 = 1.0\n",
    "t1 = 10\n",
    "\n",
    "gamma_j = t0/t1\n",
    "j = 0\n",
    "for epoch in range(1,n_epochs+1):\n",
    "    for i in range(m):\n",
    "        k = np.random.randint(m) #Pick the k-th minibatch at random\n",
    "        #Compute the gradient using the data in minibatch Bk\n",
    "        #Compute new suggestion for beta\n",
    "        t = epoch*m+i\n",
    "        gamma_j = step_length(t,t0,t1)\n",
    "        j += 1\n",
    "\n",
    "print(\"gamma_j after %d epochs: %g\" % (n_epochs,gamma_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7a6ee5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Program for stochastic gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0743de6b",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Importing various packages\n",
    "from math import exp, sqrt\n",
    "from random import random, seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "x = 2*np.random.rand(100,1)\n",
    "y = 4+3*x+np.random.randn(100,1)\n",
    "\n",
    "xb = np.c_[np.ones((100,1)), x]\n",
    "theta_linreg = np.linalg.inv(xb.T.dot(xb)).dot(xb.T).dot(y)\n",
    "print(\"Own inversion\")\n",
    "print(theta_linreg)\n",
    "sgdreg = SGDRegressor(n_iter = 50, penalty=None, eta0=0.1)\n",
    "sgdreg.fit(x,y.ravel())\n",
    "print(\"sgdreg from scikit\")\n",
    "print(sgdreg.intercept_, sgdreg.coef_)\n",
    "\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "eta = 0.1\n",
    "Niterations = 1000\n",
    "m = 100\n",
    "\n",
    "for iter in range(Niterations):\n",
    "    gradients = 2.0/m*xb.T.dot(xb.dot(theta)-y)\n",
    "    theta -= eta*gradients\n",
    "print(\"theta frm own gd\")\n",
    "print(theta)\n",
    "\n",
    "xnew = np.array([[0],[2]])\n",
    "xbnew = np.c_[np.ones((2,1)), xnew]\n",
    "ypredict = xbnew.dot(theta)\n",
    "ypredict2 = xbnew.dot(theta_linreg)\n",
    "\n",
    "\n",
    "n_epochs = 50\n",
    "t0, t1 = 5, 50\n",
    "m = 100\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = xb[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta)-yi)\n",
    "        eta = learning_schedule(epoch*m+i)\n",
    "        theta = theta - eta*gradients\n",
    "print(\"theta from own sdg\")\n",
    "print(theta)\n",
    "\n",
    "\n",
    "plt.plot(xnew, ypredict, \"r-\")\n",
    "plt.plot(xnew, ypredict2, \"b-\")\n",
    "plt.plot(x, y ,'ro')\n",
    "plt.axis([0,2.0,0, 15.0])\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.title(r'Random numbers ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398a9f1",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Using gradient descent methods, limitations\n",
    "\n",
    "* **Gradient descent (GD) finds local minima of our function**. Since the GD algorithm is deterministic, if it converges, it will converge to a local minimum of our energy function. Because in ML we are often dealing with extremely rugged landscapes with many local minima, this can lead to poor performance.\n",
    "\n",
    "* **GD is sensitive to initial conditions**. One consequence of the local nature of GD is that initial conditions matter. Depending on where one starts, one will end up at a different local minima. Therefore, it is very important to think about how one initializes the training process. This is true for GD as well as more complicated variants of GD.\n",
    "\n",
    "* **Gradients are computationally expensive to calculate for large datasets**. In many cases in statistics and ML, the energy function is a sum of terms, with one term for each data point. For example, in linear regression, $E \\propto \\sum_{i=1}^n (y_i - \\mathbf{w}^T\\cdot\\mathbf{x}_i)^2$; for logistic regression, the square error is replaced by the cross entropy. To calculate the gradient we have to sum over *all* $n$ data points. Doing this at every GD step becomes extremely computationally expensive. An ingenious solution to this, is to calculate the gradients using small subsets of the data called \"mini batches\". This has the added benefit of introducing stochasticity into our algorithm.\n",
    "\n",
    "* **GD is very sensitive to choices of learning rates**. GD is extremely sensitive to the choice of learning rates. If the learning rate is very small, the training process take an extremely long time. For larger learning rates, GD can diverge and give poor results. Furthermore, depending on what the local landscape looks like, we have to modify the learning rates to ensure convergence. Ideally, we would *adaptively* choose the learning rates to match the landscape.\n",
    "\n",
    "* **GD treats all directions in parameter space uniformly.** Another major drawback of GD is that unlike Newton's method, the learning rate for GD is the same in all directions in parameter space. For this reason, the maximum learning rate is set by the behavior of the steepest direction and this can significantly slow down training. Ideally, we would like to take large steps in flat directions and small steps in steep directions. Since we are exploring rugged landscapes where curvatures change, this requires us to keep track of not only the gradient but second derivatives. The ideal scenario would be to calculate the Hessian but this proves to be too computationally expensive. \n",
    "\n",
    "* GD can take exponential time to escape saddle points, even with random initialization. As we mentioned, GD is extremely sensitive to initial condition since it determines the particular local minimum GD would eventually reach. However, even with a good initialization scheme, through the introduction of randomness, GD can still take exponential time to escape saddle points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e1b78",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Codes from numerical recipes\n",
    "\n",
    "You can however use codes we have adapted from the text [Numerical Recipes in C++](http://www.nr.com/), see chapter 10.7.  \n",
    "Here we present a program, which you also can find at the webpage of the course we use the functions **dfpmin** and **lnsrch**.  This is a variant of the Broyden et al algorithm discussed in the previous slide.\n",
    "\n",
    "* The program uses the harmonic oscillator in one dimensions as example.\n",
    "\n",
    "* The program does not use armadillo to handle vectors and matrices, but employs rather my own vector-matrix class. These auxiliary functions, and the main program *model.cpp* can all be found under the [program link here](https://github.com/CompPhysics/ComputationalPhysics2/tree/gh-pages/doc/pub/cg/programs/c%2B%2B).\n",
    "\n",
    "Below we show only excerpts from the main program. For the full program, see the above link."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685b8a1c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Finding the minimum of the harmonic oscillator model in one dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81bf8dc7",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "//   Main function begins here\n",
    "int main()\n",
    "{\n",
    "     int n, iter;\n",
    "     double gtol, fret;\n",
    "     double alpha;\n",
    "     n = 1;\n",
    "//   reserve space in memory for vectors containing the variational\n",
    "//   parameters\n",
    "     Vector g(n), p(n);\n",
    "     cout << \"Read in guess for alpha\" << endl;\n",
    "     cin >> alpha;\n",
    "     gtol = 1.0e-5;\n",
    "//   now call dfmin and compute the minimum\n",
    "     p(0) = alpha;\n",
    "     dfpmin(p, n, gtol, &iter, &fret, Efunction, dEfunction);\n",
    "     cout << \"Value of energy minimum = \" << fret << endl;\n",
    "     cout << \"Number of iterations = \" << iter << endl;\n",
    "     cout << \"Value of alpha at minimum = \" << p(0) << endl;\n",
    "      return 0;\n",
    "}  // end of main program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff4ebb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Functions to observe\n",
    "\n",
    "The functions **Efunction** and **dEfunction** compute the expectation value of the energy and its derivative.\n",
    "They use the the quasi-Newton method of [Broyden, Fletcher, Goldfarb, and Shanno (BFGS)](https://www.springer.com/it/book/9780387303031)\n",
    "It uses the first derivatives only. The BFGS algorithm has proven good performance even for non-smooth optimizations. \n",
    "These functions need to be changed when you want to your own derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcebc65a",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "//  this function defines the expectation value of the local energy\n",
    "double Efunction(Vector  &x)\n",
    "{\n",
    "  double value = x(0)*x(0)*0.5+1.0/(8*x(0)*x(0));\n",
    "  return value;\n",
    "} // end of function to evaluate\n",
    "\n",
    "//  this function defines the derivative of the energy \n",
    "void dEfunction(Vector &x, Vector &g)\n",
    "{\n",
    "  g(0) = x(0)-1.0/(4*x(0)*x(0)*x(0));\n",
    "} // end of function to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf7f72",
   "metadata": {
    "editable": true
   },
   "source": [
    "You need to change these functions in order to compute the local energy for your system. I used 1000\n",
    "cycles per call to get a new value of $\\langle E_L[\\alpha]\\rangle$.\n",
    "When I compute the local energy I also compute its derivative.\n",
    "After roughly 10-20 iterations I got a converged result in terms of $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c356cf3",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Resampling Techniques, Bootstrap and Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f8dab",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Why resampling methods ?\n",
    " Statistical analysis\n",
    "    * Our simulations can be treated as *computer experiments*. This is particularly the case for Monte Carlo methods\n",
    "\n",
    "    * The results can be analysed with the same statistical tools as we would use analysing experimental data.\n",
    "\n",
    "    * As in all experiments, we are looking for expectation values and an estimate of how accurate they are, i.e., possible sources for errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf90ce",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Statistical analysis\n",
    "\n",
    "    * As in other experiments, many numerical  experiments have two classes of errors:\n",
    "\n",
    "      * Statistical errors\n",
    "\n",
    "      * Systematical errors\n",
    "\n",
    "    * Statistical errors can be estimated using standard tools from statistics\n",
    "\n",
    "    * Systematical errors are method specific and must be treated differently from case to case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a731e",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Statistics, wrapping up from last week\n",
    "\n",
    "Let us analyze the problem by splitting up the correlation term into\n",
    "partial sums of the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb1a99",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "f_d = \\frac{1}{n-d}\\sum_{k=1}^{n-d}(x_k - \\bar x_n)(x_{k+d} - \\bar x_n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24c6c9",
   "metadata": {
    "editable": true
   },
   "source": [
    "The correlation term of the error can now be rewritten in terms of\n",
    "$f_d$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021234e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\frac{2}{n}\\sum_{k<l} (x_k - \\bar x_n)(x_l - \\bar x_n) =\n",
    "2\\sum_{d=1}^{n-1} f_d\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3a02c",
   "metadata": {
    "editable": true
   },
   "source": [
    "The value of $f_d$ reflects the correlation between measurements\n",
    "separated by the distance $d$ in the sample samples.  Notice that for\n",
    "$d=0$, $f$ is just the sample variance, $\\mathrm{var}(x)$. If we divide $f_d$\n",
    "by $\\mathrm{var}(x)$, we arrive at the so called *autocorrelation function*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8e79d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\kappa_d = \\frac{f_d}{\\mathrm{var}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8f2245",
   "metadata": {
    "editable": true
   },
   "source": [
    "which gives us a useful measure of pairwise correlations\n",
    "starting always at $1$ for $d=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c90532",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Statistics, final expression\n",
    "\n",
    "The sample error can now be\n",
    "written in terms of the autocorrelation function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150698f6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathrm{err}_X^2 =\n",
    "\\frac{1}{n}\\mathrm{var}(x)+\\frac{2}{n}\\cdot\\mathrm{var}(x)\\sum_{d=1}^{n-1}\n",
    "\\frac{f_d}{\\mathrm{var}(x)}\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb614c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "=\n",
    "\\left(1+2\\sum_{d=1}^{n-1}\\kappa_d\\right)\\frac{1}{n}\\mathrm{var}(x)\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fa4c3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto9\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=\\frac{\\tau}{n}\\cdot\\mathrm{var}(x)\n",
    "\\label{_auto9} \\tag{31}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdda639",
   "metadata": {
    "editable": true
   },
   "source": [
    "and we see that $\\mathrm{err}_X$ can be expressed in terms the\n",
    "uncorrelated sample variance times a correction factor $\\tau$ which\n",
    "accounts for the correlation between measurements. We call this\n",
    "correction factor the *autocorrelation time*:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af4bf56",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:autocorrelation_time\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\tau = 1+2\\sum_{d=1}^{n-1}\\kappa_d\n",
    "\\label{eq:autocorrelation_time} \\tag{32}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c76cd20",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Statistics, effective number of correlations\n",
    "\n",
    "For a correlation free experiment, $\\tau$\n",
    "equals 1.\n",
    "\n",
    "We can interpret a sequential\n",
    "correlation as an effective reduction of the number of measurements by\n",
    "a factor $\\tau$. The effective number of measurements becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2756e7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "n_\\mathrm{eff} = \\frac{n}{\\tau}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33956427",
   "metadata": {
    "editable": true
   },
   "source": [
    "To neglect the autocorrelation time $\\tau$ will always cause our\n",
    "simple uncorrelated estimate of $\\mathrm{err}_X^2\\approx \\mathrm{var}(x)/n$ to\n",
    "be less than the true sample error. The estimate of the error will be\n",
    "too *good*. On the other hand, the calculation of the full\n",
    "autocorrelation time poses an efficiency problem if the set of\n",
    "measurements is very large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d9d45c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Can we understand this? Time Auto-correlation Function\n",
    "\n",
    "The so-called time-displacement autocorrelation $\\phi(t)$ for a quantity $\\mathbf{M}$ is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066efc1d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\phi(t) = \\int dt' \\left[\\mathbf{M}(t')-\\langle \\mathbf{M} \\rangle\\right]\\left[\\mathbf{M}(t'+t)-\\langle \\mathbf{M} \\rangle\\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dbd0b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "which can be rewritten as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02867c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\phi(t) = \\int dt' \\left[\\mathbf{M}(t')\\mathbf{M}(t'+t)-\\langle \\mathbf{M} \\rangle^2\\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17440883",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\langle \\mathbf{M} \\rangle$ is the average value and\n",
    "$\\mathbf{M}(t)$ its instantaneous value. We can discretize this function as follows, where we used our\n",
    "set of computed values $\\mathbf{M}(t)$ for a set of discretized times (our Monte Carlo cycles corresponding to moving all electrons?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a9f29",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:phitf\"></div>\n",
    "\n",
    "$$\n",
    "\\phi(t)  = \\frac{1}{t_{\\mathrm{max}}-t}\\sum_{t'=0}^{t_{\\mathrm{max}}-t}\\mathbf{M}(t')\\mathbf{M}(t'+t)\n",
    "-\\frac{1}{t_{\\mathrm{max}}-t}\\sum_{t'=0}^{t_{\\mathrm{max}}-t}\\mathbf{M}(t')\\times\n",
    "\\frac{1}{t_{\\mathrm{max}}-t}\\sum_{t'=0}^{t_{\\mathrm{max}}-t}\\mathbf{M}(t'+t).\n",
    "\\label{eq:phitf} \\tag{33}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ec025",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "One should be careful with times close to $t_{\\mathrm{max}}$, the upper limit of the sums \n",
    "becomes small and we end up integrating over a rather small time interval. This means that the statistical\n",
    "error in $\\phi(t)$ due to the random nature of the fluctuations in $\\mathbf{M}(t)$ can become large.\n",
    "\n",
    "One should therefore choose $t \\ll t_{\\mathrm{max}}$.\n",
    "\n",
    "Note that the variable $\\mathbf{M}$ can be any expectation values of interest.\n",
    "\n",
    "The time-correlation function gives a measure of the correlation between the various values of the variable \n",
    "at a time $t'$ and a time $t'+t$. If we multiply the values of $\\mathbf{M}$ at these two different times,\n",
    "we will get a positive contribution if they are fluctuating in the same direction, or a negative value\n",
    "if they fluctuate in the opposite direction. If we then integrate over time, or use the discretized version of, the time correlation function $\\phi(t)$ should take a non-zero value if the fluctuations are \n",
    "correlated, else it should gradually go to zero. For times a long way apart \n",
    "the different values of $\\mathbf{M}$  are most likely \n",
    "uncorrelated and $\\phi(t)$ should be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fcea03",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "We can derive the correlation time by observing that our Metropolis algorithm is based on a random\n",
    "walk in the space of all  possible spin configurations. \n",
    "Our probability \n",
    "distribution function $\\mathbf{\\hat{w}}(t)$ after a given number of time steps $t$ could be written as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166891db",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{\\hat{w}}(t) = \\mathbf{\\hat{W}^t\\hat{w}}(0),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd8e76e",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\mathbf{\\hat{w}}(0)$ the distribution at $t=0$ and $\\mathbf{\\hat{W}}$ representing the \n",
    "transition probability matrix. \n",
    "We can always expand $\\mathbf{\\hat{w}}(0)$ in terms of the right eigenvectors of \n",
    "$\\mathbf{\\hat{v}}$ of $\\mathbf{\\hat{W}}$ as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35991f9",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{\\hat{w}}(0)  = \\sum_i\\alpha_i\\mathbf{\\hat{v}}_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674118ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ef156",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\mathbf{\\hat{w}}(t) = \\mathbf{\\hat{W}}^t\\mathbf{\\hat{w}}(0)=\\mathbf{\\hat{W}}^t\\sum_i\\alpha_i\\mathbf{\\hat{v}}_i=\n",
    "\\sum_i\\lambda_i^t\\alpha_i\\mathbf{\\hat{v}}_i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ec416b",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\lambda_i$ the $i^{\\mathrm{th}}$ eigenvalue corresponding to  \n",
    "the eigenvector $\\mathbf{\\hat{v}}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd881a2f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "If we assume that $\\lambda_0$ is the largest eigenvector we see that in the limit $t\\rightarrow \\infty$,\n",
    "$\\mathbf{\\hat{w}}(t)$ becomes proportional to the corresponding eigenvector \n",
    "$\\mathbf{\\hat{v}}_0$. This is our steady state or final distribution. \n",
    "\n",
    "We can relate this property to an observable like the mean energy.\n",
    "With the probabilty $\\mathbf{\\hat{w}}(t)$ (which in our case is the squared trial wave function) we\n",
    "can write the expectation values as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74b5be",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\sum_{\\mu} \\mathbf{\\hat{w}}(t)_{\\mu}\\mathbf{M}_{\\mu},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea2c67",
   "metadata": {
    "editable": true
   },
   "source": [
    "or as the scalar of a  vector product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e56d5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\mathbf{\\hat{w}}(t)\\mathbf{m},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392da64f",
   "metadata": {
    "editable": true
   },
   "source": [
    "with $\\mathbf{m}$ being the vector whose elements are the values of $\\mathbf{M}_{\\mu}$ in its \n",
    "various microstates $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7080f8bd",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "We rewrite this relation  as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfeea04",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\mathbf{\\hat{w}}(t)\\mathbf{m}=\\sum_i\\lambda_i^t\\alpha_i\\mathbf{\\hat{v}}_i\\mathbf{m}_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b67a7d",
   "metadata": {
    "editable": true
   },
   "source": [
    "If we define $m_i=\\mathbf{\\hat{v}}_i\\mathbf{m}_i$ as the expectation value of\n",
    "$\\mathbf{M}$ in the $i^{\\mathrm{th}}$ eigenstate we can rewrite the last equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7798ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\sum_i\\lambda_i^t\\alpha_im_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aca4a15",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since we have that in the limit $t\\rightarrow \\infty$ the mean value is dominated by the \n",
    "the largest eigenvalue $\\lambda_0$, we can rewrite the last equation as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a11c5c6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\langle \\mathbf{M}(\\infty) \\rangle+\\sum_{i\\ne 0}\\lambda_i^t\\alpha_im_i.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19321535",
   "metadata": {
    "editable": true
   },
   "source": [
    "We define the quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54983e9c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tau_i=-\\frac{1}{log\\lambda_i},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f434b5",
   "metadata": {
    "editable": true
   },
   "source": [
    "and rewrite the last expectation value as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429cbed8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:finalmeanm\"></div>\n",
    "\n",
    "$$\n",
    "\\langle \\mathbf{M}(t) \\rangle  = \\langle \\mathbf{M}(\\infty) \\rangle+\\sum_{i\\ne 0}\\alpha_im_ie^{-t/\\tau_i}.\n",
    "\\label{eq:finalmeanm} \\tag{34}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47edabd5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Time Auto-correlation Function\n",
    "\n",
    "The quantities $\\tau_i$ are the correlation times for the system. They control also the auto-correlation function \n",
    "discussed above.  The longest correlation time is obviously given by the second largest\n",
    "eigenvalue $\\tau_1$, which normally defines the correlation time discussed above. For large times, this is the \n",
    "only correlation time that survives. If higher eigenvalues of the transition matrix are well separated from \n",
    "$\\lambda_1$ and we simulate long enough,  $\\tau_1$ may well define the correlation time. \n",
    "In other cases we may not be able to extract a reliable result for $\\tau_1$. \n",
    "Coming back to the time correlation function $\\phi(t)$ we can present a more general definition in terms\n",
    "of the mean magnetizations $ \\langle \\mathbf{M}(t) \\rangle$. Recalling that the mean value is equal \n",
    "to $ \\langle \\mathbf{M}(\\infty) \\rangle$ we arrive at the expectation values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea2431",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\phi(t) =\\langle \\mathbf{M}(0)-\\mathbf{M}(\\infty)\\rangle \\langle \\mathbf{M}(t)-\\mathbf{M}(\\infty)\\rangle,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f24eb6a",
   "metadata": {
    "editable": true
   },
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf04bad",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\phi(t) =\\sum_{i,j\\ne 0}m_i\\alpha_im_j\\alpha_je^{-t/\\tau_i},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62256a",
   "metadata": {
    "editable": true
   },
   "source": [
    "which is appropriate for all times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60474d4",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Correlation Time\n",
    "\n",
    "If the correlation function decays exponentially"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d52d72",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\phi (t) \\sim \\exp{(-t/\\tau)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab60375",
   "metadata": {
    "editable": true
   },
   "source": [
    "then the exponential correlation time can be computed as the average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d371b1e5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tau_{\\mathrm{exp}}  =  -\\langle  \\frac{t}{log|\\frac{\\phi(t)}{\\phi(0)}|} \\rangle.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9bfbc7",
   "metadata": {
    "editable": true
   },
   "source": [
    "If the decay is exponential, then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce7d65",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\int_0^{\\infty} dt \\phi(t)  = \\int_0^{\\infty} dt \\phi(0)\\exp{(-t/\\tau)}  = \\tau \\phi(0),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46a6e9",
   "metadata": {
    "editable": true
   },
   "source": [
    "which  suggests another measure of correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec394c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\tau_{\\mathrm{int}} = \\sum_k \\frac{\\phi(k)}{\\phi(0)},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae26c3d",
   "metadata": {
    "editable": true
   },
   "source": [
    "called the integrated correlation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0da06",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Jackknife and Bootstrap\n",
    "\n",
    "Two famous\n",
    "resampling methods are the **independent bootstrap** and **the jackknife**. \n",
    "\n",
    "The jackknife is a special case of the independent bootstrap. Still, the jackknife was made\n",
    "popular prior to the independent bootstrap. And as the popularity of\n",
    "the independent bootstrap soared, new variants, such as **the dependent bootstrap**.\n",
    "\n",
    "The Jackknife and independent bootstrap work for\n",
    "independent, identically distributed random variables.\n",
    "If these conditions are not\n",
    "satisfied, the methods will fail.  Yet, it should be said that if the data are\n",
    "independent, identically distributed, and we only want to estimate the\n",
    "variance of $\\overline{X}$ (which often is the case), then there is no\n",
    "need for bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0cced5",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Jackknife\n",
    "\n",
    "The Jackknife works by making many replicas of the estimator $\\widehat{\\theta}$. \n",
    "The jackknife is a resampling method, we explained that this happens by scrambling the data in some way. When using the jackknife, this is done by systematically leaving out one observation from the vector of observed values $\\hat{x} = (x_1,x_2,\\cdots,X_n)$. \n",
    "Let $\\hat{x}_i$ denote the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21f7bb5",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\hat{x}_i = (x_1,x_2,\\cdots,x_{i-1},x_{i+1},\\cdots,x_n),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90debc30",
   "metadata": {
    "editable": true
   },
   "source": [
    "which equals the vector $\\hat{x}$ with the exception that observation\n",
    "number $i$ is left out. Using this notation, define\n",
    "$\\widehat{\\theta}_i$ to be the estimator\n",
    "$\\widehat{\\theta}$ computed using $\\vec{X}_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cbc71",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Jackknife estimator\n",
    "\n",
    "To get an estimate for the bias and\n",
    "standard error of $\\widehat{\\theta}$, use the following\n",
    "estimators for each component of $\\widehat{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f42927",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\widehat{\\mathrm{Bias}}(\\widehat \\theta,\\theta) = (n-1)\\left( - \\widehat{\\theta} + \\frac{1}{n}\\sum_{i=1}^{n} \\widehat \\theta_i \\right) \\qquad \\text{and} \\qquad \\widehat{\\sigma}^2_{\\widehat{\\theta} } = \\frac{n-1}{n}\\sum_{i=1}^{n}( \\widehat{\\theta}_i - \\frac{1}{n}\\sum_{j=1}^{n}\\widehat \\theta_j )^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1525d4c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Jackknife code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6347f6ed",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from numpy.random import randint, randn\n",
    "from time import time\n",
    "\n",
    "def jackknife(data, stat):\n",
    "    n = len(data);t = zeros(n); inds = arange(n); t0 = time()\n",
    "    ## 'jackknifing' by leaving out an observation for each i                                                                                                                      \n",
    "    for i in range(n):\n",
    "        t[i] = stat(delete(data,i) )\n",
    "\n",
    "    # analysis                                                                                                                                                                     \n",
    "    print(\"Runtime: %g sec\" % (time()-t0)); print(\"Jackknife Statistics :\")\n",
    "    print(\"original           bias      std. error\")\n",
    "    print(\"%8g %14g %15g\" % (stat(data),(n-1)*mean(t)/n, (n*var(t))**.5))\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "# Returns mean of data samples                                                                                                                                                     \n",
    "def stat(data):\n",
    "    return mean(data)\n",
    "\n",
    "\n",
    "mu, sigma = 100, 15\n",
    "datapoints = 10000\n",
    "x = mu + sigma*random.randn(datapoints)\n",
    "# jackknife returns the data sample                                                                                                                                                \n",
    "t = jackknife(x, stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7babfe03",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Bootstrap\n",
    "\n",
    "Bootstrapping is a nonparametric approach to statistical inference\n",
    "that substitutes computation for more traditional distributional\n",
    "assumptions and asymptotic results. Bootstrapping offers a number of\n",
    "advantages: \n",
    "1. The bootstrap is quite general, although there are some cases in which it fails.  \n",
    "\n",
    "2. Because it does not require distributional assumptions (such as normally distributed errors), the bootstrap can provide more accurate inferences when the data are not well behaved or when the sample size is small.  \n",
    "\n",
    "3. It is possible to apply the bootstrap to statistics with sampling distributions that are difficult to derive, even asymptotically. \n",
    "\n",
    "4. It is relatively simple to apply the bootstrap to complex data-collection plans (such as stratified and clustered samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d212718",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Bootstrap background\n",
    "\n",
    "Since $\\widehat{\\theta} = \\widehat{\\theta}(\\hat{X})$ is a function of random variables,\n",
    "$\\widehat{\\theta}$ itself must be a random variable. Thus it has\n",
    "a pdf, call this function $p(\\hat{t})$. The aim of the bootstrap is to\n",
    "estimate $p(\\hat{t})$ by the relative frequency of\n",
    "$\\widehat{\\theta}$. You can think of this as using a histogram\n",
    "in the place of $p(\\hat{t})$. If the relative frequency closely\n",
    "resembles $p(\\vec{t})$, then using numerics, it is straight forward to\n",
    "estimate all the interesting parameters of $p(\\hat{t})$ using point\n",
    "estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7dc1d",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: More Bootstrap background\n",
    "\n",
    "In the case that $\\widehat{\\theta}$ has\n",
    "more than one component, and the components are independent, we use the\n",
    "same estimator on each component separately.  If the probability\n",
    "density function of $X_i$, $p(x)$, had been known, then it would have\n",
    "been straight forward to do this by: \n",
    "1. Drawing lots of numbers from $p(x)$, suppose we call one such set of numbers $(X_1^*, X_2^*, \\cdots, X_n^*)$. \n",
    "\n",
    "2. Then using these numbers, we could compute a replica of $\\widehat{\\theta}$ called $\\widehat{\\theta}^*$. \n",
    "\n",
    "By repeated use of (1) and (2), many\n",
    "estimates of $\\widehat{\\theta}$ could have been obtained. The\n",
    "idea is to use the relative frequency of $\\widehat{\\theta}^*$\n",
    "(think of a histogram) as an estimate of $p(\\hat{t})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6545ed",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Bootstrap approach\n",
    "\n",
    "But\n",
    "unless there is enough information available about the process that\n",
    "generated $X_1,X_2,\\cdots,X_n$, $p(x)$ is in general\n",
    "unknown. Therefore, [Efron in 1979](https://projecteuclid.org/euclid.aos/1176344552)  asked the\n",
    "question: What if we replace $p(x)$ by the relative frequency\n",
    "of the observation $X_i$; if we draw observations in accordance with\n",
    "the relative frequency of the observations, will we obtain the same\n",
    "result in some asymptotic sense? The answer is yes.\n",
    "\n",
    "Instead of generating the histogram for the relative\n",
    "frequency of the observation $X_i$, just draw the values\n",
    "$(X_1^*,X_2^*,\\cdots,X_n^*)$ with replacement from the vector\n",
    "$\\hat{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ca868",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Bootstrap steps\n",
    "\n",
    "The independent bootstrap works like this: \n",
    "\n",
    "1. Draw with replacement $n$ numbers for the observed variables $\\hat{x} = (x_1,x_2,\\cdots,x_n)$. \n",
    "\n",
    "2. Define a vector $\\hat{x}^*$ containing the values which were drawn from $\\hat{x}$. \n",
    "\n",
    "3. Using the vector $\\hat{x}^*$ compute $\\widehat{\\theta}^*$ by evaluating $\\widehat \\theta$ under the observations $\\hat{x}^*$. \n",
    "\n",
    "4. Repeat this process $k$ times. \n",
    "\n",
    "When you are done, you can draw a histogram of the relative frequency of $\\widehat \\theta^*$. This is your estimate of the probability distribution $p(t)$. Using this probability distribution you can estimate any statistics thereof. In principle you never draw the histogram of the relative frequency of $\\widehat{\\theta}^*$. Instead you use the estimators corresponding to the statistic of interest. For example, if you are interested in estimating the variance of $\\widehat \\theta$, apply the etsimator $\\widehat \\sigma^2$ to the values $\\widehat \\theta ^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b41fff8",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Code example for the Bootstrap method\n",
    "\n",
    "The following code starts with a Gaussian distribution with mean value $\\mu =100$ and variance $\\sigma=15$. We use this to generate the data used in the bootstrap analysis. The bootstrap analysis returns a data set after a given number of bootstrap operations (as many as we have data points). This data set consists of estimated mean values for each bootstrap operation. The histogram generated by the bootstrap method shows that the distribution for these mean values is also a Gaussian, centered around the mean value $\\mu=100$ but with standard deviation $\\sigma/\\sqrt{n}$, where $n$ is the number of bootstrap samples (in this case the same as the number of original data points). The value of the standard deviation is what we expect from the central limit theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3088071",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from numpy import *\n",
    "from numpy.random import randint, randn\n",
    "from time import time\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Returns mean of bootstrap samples                                                                                                                                                \n",
    "def stat(data):\n",
    "    return mean(data)\n",
    "\n",
    "# Bootstrap algorithm                                                                                                                                                              \n",
    "def bootstrap(data, statistic, R):\n",
    "    t = zeros(R); n = len(data); inds = arange(n); t0 = time()\n",
    "\n",
    "    # non-parametric bootstrap                                                                                                                                                     \n",
    "    for i in range(R):\n",
    "        t[i] = statistic(data[randint(0,n,n)])\n",
    "\n",
    "    # analysis                                                                                                                                                                     \n",
    "    print(\"Runtime: %g sec\" % (time()-t0)); print(\"Bootstrap Statistics :\")\n",
    "    print(\"original           bias      std. error\")\n",
    "    print(\"%8g %8g %14g %15g\" % (statistic(data), std(data),\\\n",
    "                             mean(t), \\\n",
    "                             std(t)))\n",
    "    return t\n",
    "\n",
    "\n",
    "mu, sigma = 100, 15\n",
    "datapoints = 10000\n",
    "x = mu + sigma*random.randn(datapoints)\n",
    "# bootstrap returns the data sample                                                                                                          t = bootstrap(x, stat, datapoints)\n",
    "# the histogram of the bootstrapped  data  \n",
    "t = bootstrap(x, stat, datapoints)\n",
    "# the histogram of the bootstrapped  data                                            \n",
    "n, binsboot, patches = plt.hist(t, bins=50, density='true',histtype='bar', color='red', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line                                                                                                                                                          \n",
    "y = norm.pdf( binsboot, mean(t), std(t))\n",
    "lt = plt.plot(binsboot, y, 'r--', linewidth=1)\n",
    "plt.xlabel('Smarts')\n",
    "plt.ylabel('Probability')\n",
    "plt.axis([99.5, 100.6, 0, 3.0])\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae3eb60",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Resampling methods: Blocking\n",
    "\n",
    "The blocking method was made popular by [Flyvbjerg and Pedersen (1989)](https://aip.scitation.org/doi/10.1063/1.457480)\n",
    "and has become one of the standard ways to estimate\n",
    "$V(\\widehat{\\theta})$ for exactly one $\\widehat{\\theta}$, namely\n",
    "$\\widehat{\\theta} = \\overline{X}$. \n",
    "\n",
    "Assume $n = 2^d$ for some integer $d>1$ and $X_1,X_2,\\cdots, X_n$ is a stationary time series to begin with. \n",
    "Moreover, assume that the time series is asymptotically uncorrelated. We switch to vector notation by arranging $X_1,X_2,\\cdots,X_n$ in an $n$-tuple. Define:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb3c052",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{X} = (X_1,X_2,\\cdots,X_n).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff0d7a",
   "metadata": {
    "editable": true
   },
   "source": [
    "The strength of the blocking method is when the number of\n",
    "observations, $n$ is large. For large $n$, the complexity of dependent\n",
    "bootstrapping scales poorly, but the blocking method does not,\n",
    "moreover, it becomes more accurate the larger $n$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ae1ca",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations\n",
    " We now define\n",
    "blocking transformations. The idea is to take the mean of subsequent\n",
    "pair of elements from $\\vec{X}$ and form a new vector\n",
    "$\\vec{X}_1$. Continuing in the same way by taking the mean of\n",
    "subsequent pairs of elements of $\\vec{X}_1$ we obtain $\\vec{X}_2$, and\n",
    "so on. \n",
    "Define $\\vec{X}_i$ recursively by:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2b3b48",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "(\\vec{X}_0)_k \\equiv (\\vec{X})_k \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53490ba9",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto10\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "(\\vec{X}_{i+1})_k \\equiv \\frac{1}{2}\\Big( (\\vec{X}_i)_{2k-1} +\n",
    "(\\vec{X}_i)_{2k} \\Big) \\qquad \\text{for all} \\qquad 1 \\leq i \\leq d-1\n",
    "\\label{_auto10} \\tag{35}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9572f7f1",
   "metadata": {
    "editable": true
   },
   "source": [
    "The quantity $\\vec{X}_k$ is\n",
    "subject to $k$ **blocking transformations**.  We now have $d$ vectors\n",
    "$\\vec{X}_0, \\vec{X}_1,\\cdots,\\vec X_{d-1}$ containing the subsequent\n",
    "averages of observations. It turns out that if the components of\n",
    "$\\vec{X}$ is a stationary time series, then the components of\n",
    "$\\vec{X}_i$ is a stationary time series for all $0 \\leq i \\leq d-1$\n",
    "\n",
    "We can then compute the autocovariance, the variance, sample mean, and\n",
    "number of observations for each $i$. \n",
    "Let $\\gamma_i, \\sigma_i^2,\n",
    "\\overline{X}_i$ denote the autocovariance, variance and average of the\n",
    "elements of $\\vec{X}_i$ and let $n_i$ be the number of elements of\n",
    "$\\vec{X}_i$. It follows by induction that $n_i = n/2^i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238aadb",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations\n",
    "\n",
    "Using the\n",
    "definition of the blocking transformation and the distributive\n",
    "property of the covariance, it is clear that since $h =|i-j|$\n",
    "we can define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c9bcf4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\gamma_{k+1}(h) = cov\\left( ({X}_{k+1})_{i}, ({X}_{k+1})_{j} \\right) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4cb36",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "=  \\frac{1}{4}cov\\left( ({X}_{k})_{2i-1} + ({X}_{k})_{2i}, ({X}_{k})_{2j-1} + ({X}_{k})_{2j} \\right) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e42c4",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto11\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=  \\frac{1}{2}\\gamma_{k}(2h) + \\frac{1}{2}\\gamma_k(2h+1) \\hspace{0.1cm} \\mathrm{h = 0} \n",
    "\\label{_auto11} \\tag{36}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bc0e49",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto12\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "=\\frac{1}{4}\\gamma_k(2h-1) + \\frac{1}{2}\\gamma_k(2h) + \\frac{1}{4}\\gamma_k(2h+1) \\quad \\mathrm{else}\n",
    "\\label{_auto12} \\tag{37}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa270602",
   "metadata": {
    "editable": true
   },
   "source": [
    "The quantity $\\hat{X}$ is asymptotic uncorrelated by assumption, $\\hat{X}_k$ is also asymptotic uncorrelated. Let's turn our attention to the variance of the sample mean $V(\\overline{X})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ba00a",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations, getting there\n",
    "We have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149be1b0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto13\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V(\\overline{X}_k) = \\frac{\\sigma_k^2}{n_k} + \\underbrace{\\frac{2}{n_k} \\sum_{h=1}^{n_k-1}\\left( 1 - \\frac{h}{n_k} \\right)\\gamma_k(h)}_{\\equiv e_k} = \\frac{\\sigma^2_k}{n_k} + e_k \\quad \\text{if} \\quad \\gamma_k(0) = \\sigma_k^2. \n",
    "\\label{_auto13} \\tag{38}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeaf343",
   "metadata": {
    "editable": true
   },
   "source": [
    "The term $e_k$ is called the **truncation error**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622a238",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto14\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "e_k = \\frac{2}{n_k} \\sum_{h=1}^{n_k-1}\\left( 1 - \\frac{h}{n_k} \\right)\\gamma_k(h). \n",
    "\\label{_auto14} \\tag{39}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d0ef1",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can show that $V(\\overline{X}_i) = V(\\overline{X}_j)$ for all $0 \\leq i \\leq d-1$ and $0 \\leq j \\leq d-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ed245",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Blocking Transformations, final expressions\n",
    "\n",
    "We can then wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39280b7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "n_{j+1} \\overline{X}_{j+1}  = \\sum_{i=1}^{n_{j+1}} (\\hat{X}_{j+1})_i =  \\frac{1}{2}\\sum_{i=1}^{n_{j}/2} (\\hat{X}_{j})_{2i-1} + (\\hat{X}_{j})_{2i} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d650c98",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto15\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "= \\frac{1}{2}\\left[ (\\hat{X}_j)_1 + (\\hat{X}_j)_2 + \\cdots + (\\hat{X}_j)_{n_j} \\right] = \\underbrace{\\frac{n_j}{2}}_{=n_{j+1}} \\overline{X}_j = n_{j+1}\\overline{X}_j. \n",
    "\\label{_auto15} \\tag{40}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7372a54e",
   "metadata": {
    "editable": true
   },
   "source": [
    "By repeated use of this equation we get $V(\\overline{X}_i) = V(\\overline{X}_0) = V(\\overline{X})$ for all $0 \\leq i \\leq d-1$. This has the consequence that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d645697e",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"eq:convergence\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "V(\\overline{X}) = \\frac{\\sigma_k^2}{n_k} + e_k \\qquad \\text{for all} \\qquad 0 \\leq k \\leq d-1. \\label{eq:convergence} \\tag{41}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8b77d",
   "metadata": {
    "editable": true
   },
   "source": [
    "Flyvbjerg and Petersen demonstrated that the sequence\n",
    "$\\{e_k\\}_{k=0}^{d-1}$ is decreasing, and conjecture that the term\n",
    "$e_k$ can be made as small as we would like by making $k$ (and hence\n",
    "$d$) sufficiently large. The sequence is decreasing (Master of Science thesis by Marius Jonsson, UiO 2018).\n",
    "It means we can apply blocking transformations until\n",
    "$e_k$ is sufficiently small, and then estimate $V(\\overline{X})$ by\n",
    "$\\widehat{\\sigma}^2_k/n_k$. \n",
    "\n",
    "For an elegant solution and proof of the blocking method, see the recent article of [Marius Jonsson (former MSc student of the Computational Physics group)](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.98.043304)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a34f98",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Boltzmann Machines\n",
    "\n",
    "Why use a generative model rather than the more well known discriminative deep neural networks (DNN)? \n",
    "\n",
    "* Discriminitave methods have several limitations: They are mainly supervised learning methods, thus requiring labeled data. And there are tasks they cannot accomplish, like drawing new examples from an unknown probability distribution.\n",
    "\n",
    "* A generative model can learn to represent and sample from a probability distribution. The core idea is to learn a parametric model of the probability distribution from which the training data was drawn. As an example\n",
    "\n",
    "a. A model for images could learn to draw new examples of cats and dogs, given a training dataset of images of cats and dogs.\n",
    "\n",
    "b. Generate a sample of an ordered or disordered Ising model phase, having been given samples of such phases.\n",
    "\n",
    "c. Model the trial function for Monte Carlo calculations\n",
    "\n",
    "4. Both use gradient-descent based learning procedures for minimizing cost functions\n",
    "\n",
    "5. Energy based models don't use backpropagation and automatic differentiation for computing gradients, instead turning to Markov Chain Monte Carlo methods.\n",
    "\n",
    "6. DNNs often have several hidden layers. A restricted Boltzmann machine has only one hidden layer, however several RBMs can be stacked to make up Deep Belief Networks, of which they constitute the building blocks.\n",
    "\n",
    "History: The RBM was developed by amongst others Geoffrey Hinton, called by some the \"Godfather of Deep Learning\", working with the University of Toronto and Google.\n",
    "\n",
    "A BM is what we would call an undirected probabilistic graphical model\n",
    "with stochastic continuous or discrete units.\n",
    "\n",
    "It is interpreted as a stochastic recurrent neural network where the\n",
    "state of each unit(neurons/nodes) depends on the units it is connected\n",
    "to. The weights in the network represent thus the strength of the\n",
    "interaction between various units/nodes.\n",
    "\n",
    "It turns into a Hopfield network if we choose deterministic rather\n",
    "than stochastic units. In contrast to a Hopfield network, a BM is a\n",
    "so-called generative model. It allows us to generate new samples from\n",
    "the learned distribution.\n",
    "\n",
    "A standard BM network is divided into a set of observable and visible units $\\hat{x}$ and a set of unknown hidden units/nodes $\\hat{h}$.\n",
    "\n",
    "Additionally there can be bias nodes for the hidden and visible layers. These biases are normally set to $1$.\n",
    "\n",
    "BMs are stackable, meaning they cwe can train a BM which serves as input to another BM. We can construct deep networks for learning complex PDFs. The layers can be trained one after another, a feature which makes them popular in deep learning\n",
    "\n",
    "However, they are often hard to train. This leads to the introduction of so-called restricted BMs, or RBMS.\n",
    "Here we take away all lateral connections between nodes in the visible layer as well as connections between nodes in the hidden layer. The network is illustrated in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c8eb6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The network\n",
    "\n",
    "**The network layers**:\n",
    "1. A function $\\mathbf{x}$ that represents the visible layer, a vector of $M$ elements (nodes). This layer represents both what the RBM might be given as training input, and what we want it to be able to reconstruct. This might for example be the pixels of an image, the spin values of the Ising model, or coefficients representing speech.\n",
    "\n",
    "2. The function $\\mathbf{h}$ represents the hidden, or latent, layer. A vector of $N$ elements (nodes). Also called \"feature detectors\".\n",
    "\n",
    "The goal of the hidden layer is to increase the model's expressive power. We encode complex interactions between visible variables by introducing additional, hidden variables that interact with visible degrees of freedom in a simple manner, yet still reproduce the complex correlations between visible degrees in the data once marginalized over (integrated out).\n",
    "\n",
    "Examples of this trick being employed in physics: \n",
    "1. The Hubbard-Stratonovich transformation\n",
    "\n",
    "2. The introduction of ghost fields in gauge theory\n",
    "\n",
    "3. Shadow wave functions in Quantum Monte Carlo simulations\n",
    "\n",
    "**The network parameters, to be optimized/learned**:\n",
    "1. $\\mathbf{a}$ represents the visible bias, a vector of same length as $\\mathbf{x}$.\n",
    "\n",
    "2. $\\mathbf{b}$ represents the hidden bias, a vector of same lenght as $\\mathbf{h}$.\n",
    "\n",
    "3. $W$ represents the interaction weights, a matrix of size $M\\times N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc37e5",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Joint distribution\n",
    "\n",
    "The restricted Boltzmann machine is described by a Bolztmann distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bef02d",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto16\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tP_{rbm}(\\mathbf{x},\\mathbf{h}) = \\frac{1}{Z} e^{-\\frac{1}{T_0}E(\\mathbf{x},\\mathbf{h})},\n",
    "\\label{_auto16} \\tag{42}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6605c0ff",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $Z$ is the normalization constant or partition function, defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c6189e",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto17\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tZ = \\int \\int e^{-\\frac{1}{T_0}E(\\mathbf{x},\\mathbf{h})} d\\mathbf{x} d\\mathbf{h}.\n",
    "\\label{_auto17} \\tag{43}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc03e59",
   "metadata": {
    "editable": true
   },
   "source": [
    "It is common to ignore $T_0$ by setting it to one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed0891",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Network Elements, the energy function\n",
    "\n",
    "The function $E(\\mathbf{x},\\mathbf{h})$ gives the **energy** of a\n",
    "configuration (pair of vectors) $(\\mathbf{x}, \\mathbf{h})$. The lower\n",
    "the energy of a configuration, the higher the probability of it. This\n",
    "function also depends on the parameters $\\mathbf{a}$, $\\mathbf{b}$ and\n",
    "$W$. Thus, when we adjust them during the learning procedure, we are\n",
    "adjusting the energy function to best fit our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a51b41",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Defining different types of RBMs\n",
    "\n",
    "There are different variants of RBMs, and the differences lie in the types of visible and hidden units we choose as well as in the implementation of the energy function $E(\\mathbf{x},\\mathbf{h})$. The connection between the nodes in the two layers is given by the weights $w_{ij}$. \n",
    "\n",
    " Binary-Binary RBM:\n",
    "\n",
    "RBMs were first developed using binary units in both the visible and hidden layer. The corresponding energy function is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0b016",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto18\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE(\\mathbf{x}, \\mathbf{h}) = - \\sum_i^M x_i a_i- \\sum_j^N b_j h_j - \\sum_{i,j}^{M,N} x_i w_{ij} h_j,\n",
    "\\label{_auto18} \\tag{44}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f64a0b",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the binary values taken on by the nodes are most commonly 0 and 1.\n",
    "\n",
    " Gaussian-Binary RBM:\n",
    "\n",
    "Another varient is the RBM where the visible units are Gaussian while the hidden units remain binary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8933cdd",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto19\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE(\\mathbf{x}, \\mathbf{h}) = \\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma_i^2} - \\sum_j^N b_j h_j - \\sum_{i,j}^{M,N} \\frac{x_i w_{ij} h_j}{\\sigma_i^2}. \n",
    "\\label{_auto19} \\tag{45}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd889a3",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. RBMs are Useful when we model continuous data (i.e., we wish $\\mathbf{x}$ to be continuous)\n",
    "\n",
    "2. Requires a smaller learning rate, since there's no upper bound to the value a component might take in the reconstruction\n",
    "\n",
    "Other types of units include:\n",
    "1. Softmax and multinomial units\n",
    "\n",
    "2. Gaussian visible and hidden units\n",
    "\n",
    "3. Binomial units\n",
    "\n",
    "4. Rectified linear units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d7f0c",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cost function\n",
    "\n",
    "When working with a training dataset, the most common training approach is maximizing the log-likelihood of the training data. The log likelihood characterizes the log-probability of generating the observed data using our generative model. Using this method our cost function is chosen as the negative log-likelihood. The learning then consists of trying to find parameters that maximize the probability of the dataset, and is known as Maximum Likelihood Estimation (MLE).\n",
    "Denoting the parameters as $\\boldsymbol{\\theta} = a_1,...,a_M,b_1,...,b_N,w_{11},...,w_{MN}$, the log-likelihood is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d06966",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto20\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\mathcal{L}(\\{ \\theta_i \\}) = \\langle \\text{log} P_\\theta(\\boldsymbol{x}) \\rangle_{data} \n",
    "\\label{_auto20} \\tag{46}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240079ec",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto21\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= - \\langle E(\\boldsymbol{x}; \\{ \\theta_i\\}) \\rangle_{data} - \\text{log} Z(\\{ \\theta_i\\}),\n",
    "\\label{_auto21} \\tag{47}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d10528",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we used that the normalization constant does not depend on the data, $\\langle \\text{log} Z(\\{ \\theta_i\\}) \\rangle = \\text{log} Z(\\{ \\theta_i\\})$\n",
    "Our cost function is the negative log-likelihood, $\\mathcal{C}(\\{ \\theta_i \\}) = - \\mathcal{L}(\\{ \\theta_i \\})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199d09d",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Optimization / Training\n",
    "\n",
    "The training procedure of choice often is Stochastic Gradient Descent (SGD). It consists of a series of iterations where we update the parameters according to the equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55985571",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto22\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_k - \\eta \\nabla \\mathcal{C} (\\boldsymbol{\\theta}_k)\n",
    "\\label{_auto22} \\tag{48}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881418b8",
   "metadata": {
    "editable": true
   },
   "source": [
    "at each $k$-th iteration. There are a range of variants of the algorithm which aim at making the learning rate $\\eta$ more adaptive so the method might be more efficient while remaining stable.\n",
    "\n",
    "We now need the gradient of the cost function in order to minimize it. We find that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7bf90",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto23\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\frac{\\partial \\mathcal{C}(\\{ \\theta_i\\})}{\\partial \\theta_i}\n",
    "\t= \\langle \\frac{\\partial E(\\boldsymbol{x}; \\theta_i)}{\\partial \\theta_i} \\rangle_{data}\n",
    "\t+ \\frac{\\partial \\text{log} Z(\\{ \\theta_i\\})}{\\partial \\theta_i} \n",
    "\\label{_auto23} \\tag{49}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367ed01",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto24\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\langle O_i(\\boldsymbol{x}) \\rangle_{data} - \\langle O_i(\\boldsymbol{x}) \\rangle_{model},\n",
    "\\label{_auto24} \\tag{50}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04bea0",
   "metadata": {
    "editable": true
   },
   "source": [
    "where in order to simplify notation we defined the \"operator\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d14872b",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto25\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tO_i(\\boldsymbol{x}) = \\frac{\\partial E(\\boldsymbol{x}; \\theta_i)}{\\partial \\theta_i}, \n",
    "\\label{_auto25} \\tag{51}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed171f",
   "metadata": {
    "editable": true
   },
   "source": [
    "and used the statistical mechanics relationship between expectation values and the log-partition function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3df4d",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto26\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\langle O_i(\\boldsymbol{x}) \\rangle_{model} = \\text{Tr} P_\\theta(\\boldsymbol{x})O_i(\\boldsymbol{x}) = - \\frac{\\partial \\text{log} Z(\\{ \\theta_i\\})}{\\partial \\theta_i}.\n",
    "\\label{_auto26} \\tag{52}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ab156f",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data-dependent term in the gradient is known as the positive phase\n",
    "of the gradient, while the model-dependent term is known as the\n",
    "negative phase of the gradient. The aim of the training is to lower\n",
    "the energy of configurations that are near observed data points\n",
    "(increasing their probability), and raising the energy of\n",
    "configurations that are far from observed data points (decreasing\n",
    "their probability).\n",
    "\n",
    "The gradient of the negative log-likelihood cost function of a Binary-Binary RBM is then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2931fd16",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto27\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\frac{\\partial \\mathcal{C} (w_{ij}, a_i, b_j)}{\\partial w_{ij}} = \\langle x_i h_j \\rangle_{data} - \\langle x_i h_j \\rangle_{model} \n",
    "\\label{_auto27} \\tag{53}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd341dd",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto28\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial \\mathcal{C} (w_{ij}, a_i, b_j)}{\\partial a_{ij}} = \\langle x_i \\rangle_{data} - \\langle x_i \\rangle_{model} \n",
    "\\label{_auto28} \\tag{54}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0df1d34",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto29\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial \\mathcal{C} (w_{ij}, a_i, b_j)}{\\partial b_{ij}} = \\langle h_i \\rangle_{data} - \\langle h_i \\rangle_{model}. \n",
    "\\label{_auto29} \\tag{55}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0d7a0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto30\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\label{_auto30} \\tag{56}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b2883",
   "metadata": {
    "editable": true
   },
   "source": [
    "To get the expectation values with respect to the *data*, we set the visible units to each of the observed samples in the training data, then update the hidden units according to the conditional probability found before. We then average over all samples in the training data to calculate expectation values with respect to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a666053",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Kullback-Leibler relative entropy\n",
    "\n",
    "When the goal of the training is to approximate a probability\n",
    "distribution, as it is in generative modeling, another relevant\n",
    "measure is the **Kullback-Leibler divergence**, also known as the\n",
    "relative entropy or Shannon entropy. It is a non-symmetric measure of the\n",
    "dissimilarity between two probability density functions $p$ and\n",
    "$q$. If $p$ is the unkown probability which we approximate with $q$,\n",
    "we can measure the difference by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b88f7",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto31\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\text{KL}(p||q) = \\int_{-\\infty}^{\\infty} p (\\boldsymbol{x}) \\log \\frac{p(\\boldsymbol{x})}{q(\\boldsymbol{x})}  d\\boldsymbol{x}.\n",
    "\\label{_auto31} \\tag{57}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48f4a3",
   "metadata": {
    "editable": true
   },
   "source": [
    "Thus, the Kullback-Leibler divergence between the distribution of the\n",
    "training data $f(\\boldsymbol{x})$ and the model distribution $p(\\boldsymbol{x}|\n",
    "\\boldsymbol{\\theta})$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea6af8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto32\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\text{KL} (f(\\boldsymbol{x})|| p(\\boldsymbol{x}| \\boldsymbol{\\theta})) = \\int_{-\\infty}^{\\infty}\n",
    "\tf (\\boldsymbol{x}) \\log \\frac{f(\\boldsymbol{x})}{p(\\boldsymbol{x}| \\boldsymbol{\\theta})} d\\boldsymbol{x} \n",
    "\\label{_auto32} \\tag{58}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1065bc",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto33\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\int_{-\\infty}^{\\infty} f(\\boldsymbol{x}) \\log f(\\boldsymbol{x}) d\\boldsymbol{x} - \\int_{-\\infty}^{\\infty} f(\\boldsymbol{x}) \\log\n",
    "\tp(\\boldsymbol{x}| \\boldsymbol{\\theta}) d\\boldsymbol{x} \n",
    "\\label{_auto33} \\tag{59}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c99b58",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto34\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t%= \\mathbb{E}_{f(\\boldsymbol{x})} (\\log f(\\boldsymbol{x})) - \\mathbb{E}_{f(\\boldsymbol{x})} (\\log p(\\boldsymbol{x}| \\boldsymbol{\\theta}))\n",
    "\t= \\langle \\log f(\\boldsymbol{x}) \\rangle_{f(\\boldsymbol{x})} - \\langle \\log p(\\boldsymbol{x}| \\boldsymbol{\\theta}) \\rangle_{f(\\boldsymbol{x})} \n",
    "\\label{_auto34} \\tag{60}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d55fd1",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto35\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\langle \\log f(\\boldsymbol{x}) \\rangle_{data} + \\langle E(\\boldsymbol{x}) \\rangle_{data} + \\log Z \n",
    "\\label{_auto35} \\tag{61}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92a3542",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto36\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\langle \\log f(\\boldsymbol{x}) \\rangle_{data} + \\mathcal{C}_{LL} .\n",
    "\\label{_auto36} \\tag{62}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbf25e",
   "metadata": {
    "editable": true
   },
   "source": [
    "The first term is constant with respect to $\\boldsymbol{\\theta}$ since $f(\\boldsymbol{x})$ is independent of $\\boldsymbol{\\theta}$. Thus the Kullback-Leibler Divergence is minimal when the second term is minimal. The second term is the log-likelihood cost function, hence minimizing the Kullback-Leibler divergence is equivalent to maximizing the log-likelihood.\n",
    "\n",
    "To further understand generative models it is useful to study the\n",
    "gradient of the cost function which is needed in order to minimize it\n",
    "using methods like stochastic gradient descent. \n",
    "\n",
    "The partition function is the generating function of\n",
    "expectation values, in particular there are mathematical relationships\n",
    "between expectation values and the log-partition function. In this\n",
    "case we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ec429",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto37\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\langle \\frac{ \\partial E(\\boldsymbol{x}; \\theta_i) } { \\partial \\theta_i} \\rangle_{model}\n",
    "\t= \\int p(\\boldsymbol{x}| \\boldsymbol{\\theta}) \\frac{ \\partial E(\\boldsymbol{x}; \\theta_i) } { \\partial \\theta_i} d\\boldsymbol{x} \n",
    "\t= -\\frac{\\partial \\log Z(\\theta_i)}{ \\partial  \\theta_i} .\n",
    "\\label{_auto37} \\tag{63}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a88806",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here $\\langle \\cdot \\rangle_{model}$ is the expectation value over the model probability distribution $p(\\boldsymbol{x}| \\boldsymbol{\\theta})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b19bc",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Setting up for gradient descent calculations\n",
    "\n",
    "Using the previous relationship we can express the gradient of the cost function as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e381a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto38\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\frac{\\partial \\mathcal{C}_{LL}}{\\partial \\theta_i}\n",
    "\t= \\langle \\frac{ \\partial E(\\boldsymbol{x}; \\theta_i) } { \\partial \\theta_i} \\rangle_{data} + \\frac{\\partial \\log Z(\\theta_i)}{ \\partial  \\theta_i} \n",
    "\\label{_auto38} \\tag{64}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473e2e5",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto39\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\langle \\frac{ \\partial E(\\boldsymbol{x}; \\theta_i) } { \\partial \\theta_i} \\rangle_{data} - \\langle \\frac{ \\partial E(\\boldsymbol{x}; \\theta_i) } { \\partial \\theta_i} \\rangle_{model} \n",
    "\\label{_auto39} \\tag{65}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c8cb12",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto40\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t%= \\langle O_i(\\boldsymbol{x}) \\rangle_{data} - \\langle O_i(\\boldsymbol{x}) \\rangle_{model}\n",
    "\\label{_auto40} \\tag{66}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35f736",
   "metadata": {
    "editable": true
   },
   "source": [
    "This expression shows that the gradient of the log-likelihood cost\n",
    "function is a **difference of moments**, with one calculated from\n",
    "the data and one calculated from the model. The data-dependent term is\n",
    "called the **positive phase** and the model-dependent term is\n",
    "called the **negative phase** of the gradient. We see now that\n",
    "minimizing the cost function results in lowering the energy of\n",
    "configurations $\\boldsymbol{x}$ near points in the training data and\n",
    "increasing the energy of configurations not observed in the training\n",
    "data. That means we increase the model's probability of configurations\n",
    "similar to those in the training data.\n",
    "\n",
    "The gradient of the cost function also demonstrates why gradients of\n",
    "unsupervised, generative models must be computed differently from for\n",
    "those of for example FNNs. While the data-dependent expectation value\n",
    "is easily calculated based on the samples $\\boldsymbol{x}_i$ in the training\n",
    "data, we must sample from the model in order to generate samples from\n",
    "which to caclulate the model-dependent term. We sample from the model\n",
    "by using MCMC-based methods. We can not sample from the model directly\n",
    "because the partition function $Z$ is generally intractable.\n",
    "\n",
    "As in supervised machine learning problems, the goal is also here to\n",
    "perform well on **unseen** data, that is to have good\n",
    "generalization from the training data. The distribution $f(x)$ we\n",
    "approximate is not the **true** distribution we wish to estimate,\n",
    "it is limited to the training data. Hence, in unsupervised training as\n",
    "well it is important to prevent overfitting to the training data. Thus\n",
    "it is common to add regularizers to the cost function in the same\n",
    "manner as we discussed for say linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf6b550",
   "metadata": {
    "editable": true
   },
   "source": [
    "## RBMs for the quantum many body problem\n",
    "\n",
    "The idea of applying RBMs to quantum many body problems was presented by G. Carleo and M. Troyer, working with ETH Zurich and Microsoft Research.\n",
    "\n",
    "Some of their motivation included\n",
    "\n",
    "* The wave function $\\Psi$ is a monolithic mathematical quantity that contains all the information on a quantum state, be it a single particle or a complex molecule. In principle, an exponential amount of information is needed to fully encode a generic many-body quantum state.\n",
    "\n",
    "* There are still interesting open problems, including fundamental questions ranging from the dynamical properties of high-dimensional systems to the exact ground-state properties of strongly interacting fermions.\n",
    "\n",
    "* The difficulty lies in finding a general strategy to reduce the exponential complexity of the full many-body wave function down to its most essential features. That is\n",
    "\n",
    "a. Dimensional reduction\n",
    "\n",
    "b. Feature extraction\n",
    "\n",
    "* Among the most successful techniques to attack these challenges, artifical neural networks play a prominent role.\n",
    "\n",
    "* Want to understand whether an artifical neural network may adapt to describe a quantum system.\n",
    "\n",
    "Carleo and Troyer applied the RBM to the quantum mechanical spin lattice systems of the Ising model and Heisenberg model, with encouraging results. Our goal is to test the method on systems of moving particles. For the spin lattice systems it was natural to use a binary-binary RBM, with the nodes taking values of 1 and -1. For moving particles, on the other hand, we want the visible nodes to be continuous, representing position coordinates. Thus, we start by choosing a Gaussian-binary RBM, where the visible nodes are continuous and hidden nodes take on values of 0 or 1. If eventually we would like the hidden nodes to be continuous as well the rectified linear units seem like the most relevant choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d54b7",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Representing the wave function\n",
    "\n",
    "The wavefunction should be a probability amplitude depending on\n",
    " $\\boldsymbol{x}$. The RBM model is given by the joint distribution of\n",
    " $\\boldsymbol{x}$ and $\\boldsymbol{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d078f5",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto41\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "        F_{rbm}(\\mathbf{x},\\mathbf{h}) = \\frac{1}{Z} e^{-\\frac{1}{T_0}E(\\mathbf{x},\\mathbf{h})}.\n",
    "\\label{_auto41} \\tag{67}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f3a89",
   "metadata": {
    "editable": true
   },
   "source": [
    "To find the marginal distribution of $\\boldsymbol{x}$ we set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63366a37",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto42\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "        F_{rbm}(\\mathbf{x}) = \\sum_\\mathbf{h} F_{rbm}(\\mathbf{x}, \\mathbf{h}) \n",
    "\\label{_auto42} \\tag{68}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c0bb3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto43\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "                                = \\frac{1}{Z}\\sum_\\mathbf{h} e^{-E(\\mathbf{x}, \\mathbf{h})}.\n",
    "\\label{_auto43} \\tag{69}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a7a1ed",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now this is what we use to represent the wave function, calling it a neural-network quantum state (NQS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd3976",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto44\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "        \\Psi (\\mathbf{X}) = F_{rbm}(\\mathbf{x}) \n",
    "\\label{_auto44} \\tag{70}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18f0303",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto45\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "        = \\frac{1}{Z}\\sum_{\\boldsymbol{h}} e^{-E(\\mathbf{x}, \\mathbf{h})} \n",
    "\\label{_auto45} \\tag{71}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ed64b",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto46\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "        = \\frac{1}{Z} \\sum_{\\{h_j\\}} e^{-\\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma^2} + \\sum_j^N b_j h_j + \\sum_\\\n",
    "{i,j}^{M,N} \\frac{x_i w_{ij} h_j}{\\sigma^2}} \n",
    "\\label{_auto46} \\tag{72}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c8c58",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto47\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "        = \\frac{1}{Z} e^{-\\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma^2}} \\prod_j^N (1 + e^{b_j + \\sum_i^M \\frac{x\\\n",
    "_i w_{ij}}{\\sigma^2}}). \n",
    "\\label{_auto47} \\tag{73}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e200b3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto48\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\label{_auto48} \\tag{74}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9b34f",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Choose the cost function\n",
    "\n",
    "Now we don't necessarily have training data (unless we generate it by using some other method). However, what we do have is the variational principle which allows us to obtain the ground state wave function by minimizing the expectation value of the energy of a trial wavefunction (corresponding to the untrained NQS). Similarly to the traditional variational Monte Carlo method then, it is the local energy we wish to minimize. The gradient to use for the stochastic gradient descent procedure is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dff145",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto49\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tC_i = \\frac{\\partial \\langle E_L \\rangle}{\\partial \\theta_i}\n",
    "\t= 2(\\langle E_L \\frac{1}{\\Psi}\\frac{\\partial \\Psi}{\\partial \\theta_i} \\rangle - \\langle E_L \\rangle \\langle \\frac{1}{\\Psi}\\frac{\\partial \\Psi}{\\partial \\theta_i} \\rangle ),\n",
    "\\label{_auto49} \\tag{75}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ab05c",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the local energy is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf464a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto50\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE_L = \\frac{1}{\\Psi} \\hat{\\mathbf{H}} \\Psi.\n",
    "\\label{_auto50} \\tag{76}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21832b",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Mathematical details\n",
    "\n",
    "Because we are restricted to potential functions which are positive it\n",
    "is convenient to express them as exponentials, so that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa96471",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto51\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\phi_C (\\boldsymbol{x}_C) = e^{-E_C(\\boldsymbol{x}_C)}\n",
    "\\label{_auto51} \\tag{77}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a55d887",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $E(\\boldsymbol{x}_C)$ is called an *energy function*, and the\n",
    "exponential representation is the *Boltzmann distribution*. The\n",
    "joint distribution is defined as the product of potentials.\n",
    "\n",
    "The joint distribution of the random variables is then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b9d2d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p(\\boldsymbol{x}) = \\frac{1}{Z} \\prod_C \\phi_C (\\boldsymbol{x}_C) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7800c15f",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z} \\prod_C e^{-E_C(\\boldsymbol{x}_C)} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9df17cd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z} e^{-\\sum_C E_C(\\boldsymbol{x}_C)} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442ce6b9",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto52\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z} e^{-E(\\boldsymbol{x})}.\n",
    "\\label{_auto52} \\tag{78}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a5d64",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto53\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BM}(\\boldsymbol{x}, \\boldsymbol{h}) = \\frac{1}{Z_{BM}} e^{-\\frac{1}{T}E_{BM}(\\boldsymbol{x}, \\boldsymbol{h})} ,\n",
    "\\label{_auto53} \\tag{79}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd88e4",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the partition function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ced2a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto54\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tZ_{BM} = \\int \\int e^{-\\frac{1}{T} E_{BM}(\\tilde{\\boldsymbol{x}}, \\tilde{\\boldsymbol{h}})} d\\tilde{\\boldsymbol{x}} d\\tilde{\\boldsymbol{h}} .\n",
    "\\label{_auto54} \\tag{80}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37095d3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$T$ is a physics-inspired parameter named temperature and will be assumed to be 1 unless otherwise stated. The energy function of the Boltzmann machine determines the interactions between the nodes and is defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4236b4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_{BM}(\\boldsymbol{x}, \\boldsymbol{h}) = - \\sum_{i, k}^{M, K} a_i^k \\alpha_i^k (x_i)\n",
    "\t- \\sum_{j, l}^{N, L} b_j^l \\beta_j^l (h_j) \n",
    "\t- \\sum_{i,j,k,l}^{M,N,K,L} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (h_j) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44deb023",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto55\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t- \\sum_{i, m=i+1, k}^{M, M, K} \\alpha_i^k (x_i) v_{im}^k \\alpha_m^k (x_m)\n",
    "\t- \\sum_{j,n=j+1,l}^{N,N,L} \\beta_j^l (h_j) u_{jn}^l \\beta_n^l (h_n).\n",
    "\\label{_auto55} \\tag{81}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35edc4c6",
   "metadata": {
    "editable": true
   },
   "source": [
    "Here $\\alpha_i^k (x_i)$ and $\\beta_j^l (h_j)$ are one-dimensional\n",
    "transfer functions or mappings from the given input value to the\n",
    "desired feature value. They can be arbitrary functions of the input\n",
    "variables and are independent of the parameterization (parameters\n",
    "referring to weight and biases), meaning they are not affected by\n",
    "training of the model. The indices $k$ and $l$ indicate that there can\n",
    "be multiple transfer functions per variable.  Furthermore, $a_i^k$ and\n",
    "$b_j^l$ are the visible and hidden bias. $w_{ij}^{kl}$ are weights of\n",
    "the \\textbf{inter-layer} connection terms which connect visible and\n",
    "hidden units. $ v_{im}^k$ and $u_{jn}^l$ are weights of the\n",
    "\\textbf{intra-layer} connection terms which connect the visible units\n",
    "to each other and the hidden units to each other, respectively.\n",
    "\n",
    "We remove the intra-layer connections by setting $v_{im}$ and $u_{jn}$\n",
    "to zero. The expression for the energy of the RBM is then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2e1a5",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto56\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE_{RBM}(\\boldsymbol{x}, \\boldsymbol{h}) = - \\sum_{i, k}^{M, K} a_i^k \\alpha_i^k (x_i)\n",
    "\t- \\sum_{j, l}^{N, L} b_j^l \\beta_j^l (h_j) \n",
    "\t- \\sum_{i,j,k,l}^{M,N,K,L} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (h_j). \n",
    "\\label{_auto56} \\tag{82}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb3061",
   "metadata": {
    "editable": true
   },
   "source": [
    "resulting in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8ae6b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P_{RBM} (\\boldsymbol{x}) = \\int P_{RBM} (\\boldsymbol{x}, \\tilde{\\boldsymbol{h}})  d \\tilde{\\boldsymbol{h}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64349b8d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{RBM}} \\int e^{-E_{RBM} (\\boldsymbol{x}, \\tilde{\\boldsymbol{h}}) } d\\tilde{\\boldsymbol{h}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c941141",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{RBM}} \\int e^{\\sum_{i, k} a_i^k \\alpha_i^k (x_i)\n",
    "\t+ \\sum_{j, l} b_j^l \\beta_j^l (\\tilde{h}_j) \n",
    "\t+ \\sum_{i,j,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (\\tilde{h}_j)} \n",
    "\td\\tilde{\\boldsymbol{h}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73e29ee",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{RBM}} e^{\\sum_{i, k} a_i^k \\alpha_i^k (x_i)}\n",
    "\t\\int \\prod_j^N e^{\\sum_l b_j^l \\beta_j^l (\\tilde{h}_j) \n",
    "\t+ \\sum_{i,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (\\tilde{h}_j)} d\\tilde{\\boldsymbol{h}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda636ac",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{RBM}} e^{\\sum_{i, k} a_i^k \\alpha_i^k (x_i)}\n",
    "\t\\biggl( \\int e^{\\sum_l b_1^l \\beta_1^l (\\tilde{h}_1) + \\sum_{i,k,l} \\alpha_i^k (x_i) w_{i1}^{kl} \\beta_1^l (\\tilde{h}_1)} d \\tilde{h}_1 \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dbeec0",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\times \\int e^{\\sum_l b_2^l \\beta_2^l (\\tilde{h}_2) + \\sum_{i,k,l} \\alpha_i^k (x_i) w_{i2}^{kl} \\beta_2^l (\\tilde{h}_2)} d \\tilde{h}_2 \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c01218",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\times ... \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8aa1ff",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\times \\int e^{\\sum_l b_N^l \\beta_N^l (\\tilde{h}_N) + \\sum_{i,k,l} \\alpha_i^k (x_i) w_{iN}^{kl} \\beta_N^l (\\tilde{h}_N)} d \\tilde{h}_N \\biggr) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d4f33",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto57\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z_{RBM}} e^{\\sum_{i, k} a_i^k \\alpha_i^k (x_i)}\n",
    "\t\\prod_j^N \\int e^{\\sum_l b_j^l \\beta_j^l (\\tilde{h}_j) + \\sum_{i,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (\\tilde{h}_j)}  d\\tilde{h}_j\n",
    "\\label{_auto57} \\tag{83}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0348cd7",
   "metadata": {
    "editable": true
   },
   "source": [
    "Similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74d92e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P_{RBM} (\\boldsymbol{h}) = \\frac{1}{Z_{RBM}} \\int e^{-E_{RBM} (\\tilde{\\boldsymbol{x}}, \\boldsymbol{h})} d\\tilde{\\boldsymbol{x}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e26113",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto58\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z_{RBM}} e^{\\sum_{j, l} b_j^l \\beta_j^l (h_j)}\n",
    "\t\\prod_i^M \\int e^{\\sum_k a_i^k \\alpha_i^k (\\tilde{x}_i)\n",
    "\t+ \\sum_{j,k,l} \\alpha_i^k (\\tilde{x}_i) w_{ij}^{kl} \\beta_j^l (h_j)} d\\tilde{x}_i\n",
    "\\label{_auto58} \\tag{84}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c87ca0",
   "metadata": {
    "editable": true
   },
   "source": [
    "Using Bayes theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10657521",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P_{RBM} (\\boldsymbol{h}|\\boldsymbol{x}) = \\frac{P_{RBM} (\\boldsymbol{x}, \\boldsymbol{h})}{P_{RBM} (\\boldsymbol{x})} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21464dce",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{\\frac{1}{Z_{RBM}} e^{\\sum_{i, k} a_i^k \\alpha_i^k (x_i)\n",
    "\t+ \\sum_{j, l} b_j^l \\beta_j^l (h_j) \n",
    "\t+ \\sum_{i,j,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (h_j)}}\n",
    "\t{\\frac{1}{Z_{RBM}} e^{\\sum_{i, k} a_i^k \\alpha_i^k (x_i)}\n",
    "\t\\prod_j^N \\int e^{\\sum_l b_j^l \\beta_j^l (\\tilde{h}_j) + \\sum_{i,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (\\tilde{h}_j)}  d\\tilde{h}_j} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958c429",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto59\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\prod_j^N \\frac{e^{\\sum_l b_j^l \\beta_j^l (h_j) + \\sum_{i,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (h_j)} }\n",
    "\t{\\int e^{\\sum_l b_j^l \\beta_j^l (\\tilde{h}_j) + \\sum_{i,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (\\tilde{h}_j)}  d\\tilde{h}_j}\n",
    "\\label{_auto59} \\tag{85}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b78675",
   "metadata": {
    "editable": true
   },
   "source": [
    "Similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3730421",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "P_{RBM} (\\boldsymbol{x}|\\boldsymbol{h}) =  \\frac{P_{RBM} (\\boldsymbol{x}, \\boldsymbol{h})}{P_{RBM} (\\boldsymbol{h})} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b222eb6",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto60\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\prod_i^M \\frac{e^{\\sum_k a_i^k \\alpha_i^k (x_i)\n",
    "\t+ \\sum_{j,k,l} \\alpha_i^k (x_i) w_{ij}^{kl} \\beta_j^l (h_j)}}\n",
    "\t{\\int e^{\\sum_k a_i^k \\alpha_i^k (\\tilde{x}_i)\n",
    "\t+ \\sum_{j,k,l} \\alpha_i^k (\\tilde{x}_i) w_{ij}^{kl} \\beta_j^l (h_j)} d\\tilde{x}_i}\n",
    "\\label{_auto60} \\tag{86}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c613ec3",
   "metadata": {
    "editable": true
   },
   "source": [
    "The original RBM had binary visible and hidden nodes. They were\n",
    "showned to be universal approximators of discrete distributions.\n",
    "It was also shown that adding hidden units yields\n",
    "strictly improved modelling power. The common choice of binary values\n",
    "are 0 and 1. However, in some physics applications, -1 and 1 might be\n",
    "a more natural choice. We will here use 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3259c73",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto61\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE_{BB}(\\boldsymbol{x}, \\mathbf{h}) = - \\sum_i^M x_i a_i- \\sum_j^N b_j h_j - \\sum_{i,j}^{M,N} x_i w_{ij} h_j.\n",
    "\\label{_auto61} \\tag{87}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16138f0c",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto62\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BB}(\\boldsymbol{x}, \\boldsymbol{h}) = \\frac{1}{Z_{BB}} e^{\\sum_i^M a_i x_i + \\sum_j^N b_j h_j + \\sum_{ij}^{M,N} x_i w_{ij} h_j} \n",
    "\\label{_auto62} \\tag{88}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aa5d16",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto63\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z_{BB}} e^{\\boldsymbol{x}^T \\boldsymbol{a} + \\boldsymbol{b}^T \\boldsymbol{h} + \\boldsymbol{x}^T \\boldsymbol{W} \\boldsymbol{h}}\n",
    "\\label{_auto63} \\tag{89}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dca15fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the partition function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd46176",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto64\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tZ_{BB} = \\sum_{\\boldsymbol{x}, \\boldsymbol{h}} e^{\\boldsymbol{x}^T \\boldsymbol{a} + \\boldsymbol{b}^T \\boldsymbol{h} + \\boldsymbol{x}^T \\boldsymbol{W} \\boldsymbol{h}} .\n",
    "\\label{_auto64} \\tag{90}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c9067",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Marginal Probability Density Functions\n",
    "\n",
    "In order to find the probability of any configuration of the visible units we derive the marginal probability density function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e230302",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto65\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BB} (\\boldsymbol{x}) = \\sum_{\\boldsymbol{h}} p_{BB} (\\boldsymbol{x}, \\boldsymbol{h}) \n",
    "\\label{_auto65} \\tag{91}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313a9ae",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{BB}} \\sum_{\\boldsymbol{h}} e^{\\boldsymbol{x}^T \\boldsymbol{a} + \\boldsymbol{b}^T \\boldsymbol{h} + \\boldsymbol{x}^T \\boldsymbol{W} \\boldsymbol{h}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036760df",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{BB}} e^{\\boldsymbol{x}^T \\boldsymbol{a}} \\sum_{\\boldsymbol{h}} e^{\\sum_j^N (b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j})h_j} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63159fa",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{BB}} e^{\\boldsymbol{x}^T \\boldsymbol{a}} \\sum_{\\boldsymbol{h}} \\prod_j^N e^{ (b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j})h_j} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bdedc7",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{BB}} e^{\\boldsymbol{x}^T \\boldsymbol{a}} \\bigg ( \\sum_{h_1} e^{(b_1 + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast 1})h_1}\n",
    "\t\\times \\sum_{h_2} e^{(b_2 + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast 2})h_2} \\times \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b8ebda",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "... \\times \\sum_{h_2} e^{(b_N + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast N})h_N} \\bigg ) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5284b50",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{BB}} e^{\\boldsymbol{x}^T \\boldsymbol{a}} \\prod_j^N \\sum_{h_j} e^{(b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}) h_j} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc74c3c",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto66\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z_{BB}} e^{\\boldsymbol{x}^T \\boldsymbol{a}} \\prod_j^N (1 + e^{b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}}) .\n",
    "\\label{_auto66} \\tag{92}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e6b950",
   "metadata": {
    "editable": true
   },
   "source": [
    "A similar derivation yields the marginal probability of the hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c02fb3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto67\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BB} (\\boldsymbol{h}) = \\frac{1}{Z_{BB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M (1 + e^{a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}}) .\n",
    "\\label{_auto67} \\tag{93}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a57cf5",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Conditional Probability Density Functions\n",
    "\n",
    "We derive the probability of the hidden units given the visible units using Bayes' rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dede8a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p_{BB} (\\boldsymbol{h}|\\boldsymbol{x}) = \\frac{p_{BB} (\\boldsymbol{x}, \\boldsymbol{h})}{p_{BB} (\\boldsymbol{x})} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfba4f3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{ \\frac{1}{Z_{BB}}  e^{\\boldsymbol{x}^T \\boldsymbol{a} + \\boldsymbol{b}^T \\boldsymbol{h} + \\boldsymbol{x}^T \\boldsymbol{W} \\boldsymbol{h}} }\n",
    "\t        {\\frac{1}{Z_{BB}} e^{\\boldsymbol{x}^T \\boldsymbol{a}} \\prod_j^N (1 + e^{b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}})} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c5fdd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{  e^{\\boldsymbol{x}^T \\boldsymbol{a}} e^{ \\sum_j^N (b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j} ) h_j} }\n",
    "\t        { e^{\\boldsymbol{x}^T \\boldsymbol{a}} \\prod_j^N (1 + e^{b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}})} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b27ea3e",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\prod_j^N \\frac{ e^{(b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j} ) h_j}  }\n",
    "\t{1 + e^{b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be36b3a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto68\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\prod_j^N p_{BB} (h_j| \\boldsymbol{x}) .\n",
    "\\label{_auto68} \\tag{94}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea8339",
   "metadata": {
    "editable": true
   },
   "source": [
    "From this we find the probability of a hidden unit being \"on\" or \"off\":"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718ebc1",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto69\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BB} (h_j=1 | \\boldsymbol{x}) =   \\frac{ e^{(b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j} ) h_j}  }\n",
    "\t{1 + e^{b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}}} \n",
    "\\label{_auto69} \\tag{95}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a89f4",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto70\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t=  \\frac{ e^{(b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j} )}  }\n",
    "\t{1 + e^{b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}}} \n",
    "\\label{_auto70} \\tag{96}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e79c478",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto71\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t=  \\frac{ 1 }{1 + e^{-(b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j})} } ,\n",
    "\\label{_auto71} \\tag{97}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d188d3",
   "metadata": {
    "editable": true
   },
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465fc843",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto72\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BB} (h_j=0 | \\boldsymbol{x}) =\\frac{ 1 }{1 + e^{b_j + \\boldsymbol{x}^T \\boldsymbol{w}_{\\ast j}} } .\n",
    "\\label{_auto72} \\tag{98}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2369f",
   "metadata": {
    "editable": true
   },
   "source": [
    "Similarly we have that the conditional probability of the visible units given the hidden are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba12d38",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto73\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BB} (\\boldsymbol{x}|\\boldsymbol{h}) = \\prod_i^M \\frac{ e^{ (a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}) x_i} }{ 1 + e^{a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}} } \n",
    "\\label{_auto73} \\tag{99}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3d4e03",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto74\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\prod_i^M p_{BB} (x_i | \\boldsymbol{h}) .\n",
    "\\label{_auto74} \\tag{100}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142f6c0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto75\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tp_{BB} (x_i=1 | \\boldsymbol{h}) = \\frac{1}{1 + e^{-(a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} )}} \n",
    "\\label{_auto75} \\tag{101}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318e030",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto76\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\tp_{BB} (x_i=0 | \\boldsymbol{h}) = \\frac{1}{1 + e^{a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} }} .\n",
    "\\label{_auto76} \\tag{102}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2763f11",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Gaussian-Binary Restricted Boltzmann Machines\n",
    "\n",
    "Inserting into the expression for $E_{RBM}(\\boldsymbol{x},\\boldsymbol{h})$ in equation  results in the energy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d40d6a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "E_{GB}(\\boldsymbol{x}, \\boldsymbol{h}) = \\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma_i^2}\n",
    "\t- \\sum_j^N b_j h_j \n",
    "\t-\\sum_{ij}^{M,N} \\frac{x_i w_{ij} h_j}{\\sigma_i^2} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ef64b",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto77\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\vert\\vert\\frac{\\boldsymbol{x} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2 - \\boldsymbol{b}^T \\boldsymbol{h} \n",
    "\t- (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{W}\\boldsymbol{h} . \n",
    "\\label{_auto77} \\tag{103}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bdea1a",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Joint Probability Density Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9307b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p_{GB} (\\boldsymbol{x}, \\boldsymbol{h}) = \\frac{1}{Z_{GB}} e^{-\\vert\\vert\\frac{\\boldsymbol{x} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2 + \\boldsymbol{b}^T \\boldsymbol{h} \n",
    "\t+ (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{W}\\boldsymbol{h}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc01c6",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{- \\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma_i^2}\n",
    "\t+ \\sum_j^N b_j h_j \n",
    "\t+\\sum_{ij}^{M,N} \\frac{x_i w_{ij} h_j}{\\sigma_i^2}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053d9e5",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto78\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z_{GB}} \\prod_{ij}^{M,N} e^{-\\frac{(x_i - a_i)^2}{2\\sigma_i^2}\n",
    "\t+ b_j h_j \n",
    "\t+\\frac{x_i w_{ij} h_j}{\\sigma_i^2}} ,\n",
    "\\label{_auto78} \\tag{104}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d827969",
   "metadata": {
    "editable": true
   },
   "source": [
    "with the partition function given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb6f25",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto79\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tZ_{GB} = \\int \\sum_{\\tilde{\\boldsymbol{h}}}^{\\tilde{\\boldsymbol{H}}} e^{-\\vert\\vert\\frac{\\tilde{\\boldsymbol{x}} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2 + \\boldsymbol{b}^T \\tilde{\\boldsymbol{h}} \n",
    "\t+ (\\frac{\\tilde{\\boldsymbol{x}}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{W}\\tilde{\\boldsymbol{h}}} d\\tilde{\\boldsymbol{x}} .\n",
    "\\label{_auto79} \\tag{105}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1a843",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Marginal Probability Density Functions\n",
    "\n",
    "We proceed to find the marginal probability densitites of the\n",
    "Gaussian-binary RBM. We first marginalize over the binary hidden units\n",
    "to find $p_{GB} (\\boldsymbol{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284601bc",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p_{GB} (\\boldsymbol{x}) = \\sum_{\\tilde{\\boldsymbol{h}}}^{\\tilde{\\boldsymbol{H}}} p_{GB} (\\boldsymbol{x}, \\tilde{\\boldsymbol{h}}) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83738e3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} \\sum_{\\tilde{\\boldsymbol{h}}}^{\\tilde{\\boldsymbol{H}}} \n",
    "\te^{-\\vert\\vert\\frac{\\boldsymbol{x} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2 + \\boldsymbol{b}^T \\tilde{\\boldsymbol{h}} \n",
    "\t+ (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{W}\\tilde{\\boldsymbol{h}}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c27794",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto80\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z_{GB}} e^{-\\vert\\vert\\frac{\\boldsymbol{x} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2}\n",
    "\t\\prod_j^N (1 + e^{b_j + (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j}} ) .\n",
    "\\label{_auto80} \\tag{106}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edae76b8",
   "metadata": {
    "editable": true
   },
   "source": [
    "We next marginalize over the visible units. This is the first time we\n",
    "marginalize over continuous values. We rewrite the exponential factor\n",
    "dependent on $\\boldsymbol{x}$ as a Gaussian function before we integrate in\n",
    "the last step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd88e267",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p_{GB} (\\boldsymbol{h}) = \\int p_{GB} (\\tilde{\\boldsymbol{x}}, \\boldsymbol{h}) d\\tilde{\\boldsymbol{x}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ac454",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} \\int e^{-\\vert\\vert\\frac{\\tilde{\\boldsymbol{x}} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2 + \\boldsymbol{b}^T \\boldsymbol{h} \n",
    "\t+ (\\frac{\\tilde{\\boldsymbol{x}}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{W}\\boldsymbol{h}} d\\tilde{\\boldsymbol{x}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c31b30",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h} } \\int \\prod_i^M\n",
    "\te^{- \\frac{(\\tilde{x}_i - a_i)^2}{2\\sigma_i^2} + \\frac{\\tilde{x}_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}}{\\sigma_i^2} } d\\tilde{\\boldsymbol{x}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87ffcd",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h} }\n",
    "\t\\biggl( \\int e^{- \\frac{(\\tilde{x}_1 - a_1)^2}{2\\sigma_1^2} + \\frac{\\tilde{x}_1 \\boldsymbol{w}_{1\\ast}^T \\boldsymbol{h}}{\\sigma_1^2} } d\\tilde{x}_1 \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcc7999",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\times \\int e^{- \\frac{(\\tilde{x}_2 - a_2)^2}{2\\sigma_2^2} + \\frac{\\tilde{x}_2 \\boldsymbol{w}_{2\\ast}^T \\boldsymbol{h}}{\\sigma_2^2} } d\\tilde{x}_2 \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b041d85",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\times ... \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba7f8c",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "\\times \\int e^{- \\frac{(\\tilde{x}_M - a_M)^2}{2\\sigma_M^2} + \\frac{\\tilde{x}_M \\boldsymbol{w}_{M\\ast}^T \\boldsymbol{h}}{\\sigma_M^2} } d\\tilde{x}_M \\biggr) \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099dad4",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M\n",
    "\t\\int e^{- \\frac{(\\tilde{x}_i - a_i)^2 - 2\\tilde{x}_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}}{2\\sigma_i^2} } d\\tilde{x}_i \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9844f3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M\n",
    "\t\\int e^{- \\frac{\\tilde{x}_i^2 - 2\\tilde{x}_i(a_i + \\tilde{x}_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}) + a_i^2}{2\\sigma_i^2} } d\\tilde{x}_i \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f46e3",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M\n",
    "\t\\int e^{- \\frac{\\tilde{x}_i^2 - 2\\tilde{x}_i(a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}) + (a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 - (a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 + a_i^2}{2\\sigma_i^2} } d\\tilde{x}_i \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc31577",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M\n",
    "\t\\int e^{- \\frac{(\\tilde{x}_i - (a_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}))^2 - a_i^2 -2a_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} - (\\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 + a_i^2}{2\\sigma_i^2} } d\\tilde{x}_i \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5936a704",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M\n",
    "\te^{\\frac{2a_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} +(\\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 }{2\\sigma_i^2}}\n",
    "\t\\int e^{- \\frac{(\\tilde{x}_i - a_i - \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2}{2\\sigma_i^2}}\n",
    "\td\\tilde{x}_i \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47942ed7",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto81\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M\n",
    "\t\\sqrt{2\\pi \\sigma_i^2}\n",
    "\te^{\\frac{2a_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} +(\\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 }{2\\sigma_i^2}} .\n",
    "\\label{_auto81} \\tag{107}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b021583",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Conditional Probability Density Functions\n",
    "\n",
    "We finish by deriving the conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd19b68",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p_{GB} (\\boldsymbol{h}| \\boldsymbol{x}) = \\frac{p_{GB} (\\boldsymbol{x}, \\boldsymbol{h})}{p_{GB} (\\boldsymbol{x})} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1bb6b",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{\\frac{1}{Z_{GB}} e^{-\\vert\\vert\\frac{\\boldsymbol{x} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2 + \\boldsymbol{b}^T \\boldsymbol{h} \n",
    "\t+ (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{W}\\boldsymbol{h}}}\n",
    "\t{\\frac{1}{Z_{GB}} e^{-\\vert\\vert\\frac{\\boldsymbol{x} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2}\n",
    "\t\\prod_j^N (1 + e^{b_j + (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j}} ) }\n",
    "\t\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b441ef",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\prod_j^N \\frac{e^{(b_j + (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j})h_j } }\n",
    "\t{1 + e^{b_j + (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j}}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81baf679",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto82\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\prod_j^N p_{GB} (h_j|\\boldsymbol{x}).\n",
    "\\label{_auto82} \\tag{108}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ed29e",
   "metadata": {
    "editable": true
   },
   "source": [
    "The conditional probability of a binary hidden unit $h_j$ being on or off again takes the form of a sigmoid function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c10959",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p_{GB} (h_j =1 | \\boldsymbol{x}) = \\frac{e^{b_j + (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j} } }\n",
    "\t{1 + e^{b_j + (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j}}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c7a14",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto83\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{1 + e^{-b_j - (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j}}} \n",
    "\\label{_auto83} \\tag{109}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd418ac",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto84\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\tp_{GB} (h_j =0 | \\boldsymbol{x}) =\n",
    "\t\\frac{1}{1 + e^{b_j +(\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{w}_{\\ast j}}} .\n",
    "\\label{_auto84} \\tag{110}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c767d51",
   "metadata": {
    "editable": true
   },
   "source": [
    "The conditional probability of the continuous $\\boldsymbol{x}$ now has another form, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a85af",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "p_{GB} (\\boldsymbol{x}|\\boldsymbol{h})\n",
    "\t= \\frac{p_{GB} (\\boldsymbol{x}, \\boldsymbol{h})}{p_{GB} (\\boldsymbol{h})} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a2947",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\frac{\\frac{1}{Z_{GB}} e^{-\\vert\\vert\\frac{\\boldsymbol{x} -\\boldsymbol{a}}{2\\boldsymbol{\\sigma}}\\vert\\vert^2 + \\boldsymbol{b}^T \\boldsymbol{h} \n",
    "\t+ (\\frac{\\boldsymbol{x}}{\\boldsymbol{\\sigma}^2})^T \\boldsymbol{W}\\boldsymbol{h}}}\n",
    "\t{\\frac{1}{Z_{GB}} e^{\\boldsymbol{b}^T \\boldsymbol{h}} \\prod_i^M\n",
    "\t\\sqrt{2\\pi \\sigma_i^2}\n",
    "\te^{\\frac{2a_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} +(\\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 }{2\\sigma_i^2}}}\n",
    "\t\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a59043a",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\prod_i^M \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}}\n",
    "\t\\frac{e^{- \\frac{(x_i - a_i)^2}{2\\sigma_i^2} + \\frac{x_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}}{2\\sigma_i^2} }}\n",
    "\t{e^{\\frac{2a_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} +(\\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 }{2\\sigma_i^2}}}\n",
    "\t\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c8bff",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\prod_i^M \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}}\n",
    "\t\\frac{e^{-\\frac{x_i^2 - 2a_i x_i + a_i^2 - 2x_i \\boldsymbol{w}_{i\\ast}^T\\boldsymbol{h} }{2\\sigma_i^2} } }\n",
    "\t{e^{\\frac{2a_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} +(\\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2 }{2\\sigma_i^2}}}\n",
    "\t\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf89e8d",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\prod_i^M \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}}\n",
    "\te^{- \\frac{x_i^2 - 2a_i x_i + a_i^2 - 2x_i \\boldsymbol{w}_{i\\ast}^T\\boldsymbol{h}\n",
    "\t+ 2a_i \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h} +(\\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2}\n",
    "\t{2\\sigma_i^2} }\n",
    "\t\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbb22de",
   "metadata": {
    "editable": true
   },
   "source": [
    "$$\n",
    "= \\prod_i^M \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}}\n",
    "\te^{ - \\frac{(x_i - b_i - \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h})^2}{2\\sigma_i^2}} \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c0610",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto85\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\prod_i^M \\mathcal{N}\n",
    "\t(x_i | b_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}, \\sigma_i^2) \n",
    "\\label{_auto85} \\tag{111}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e85142",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto86\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\Rightarrow p_{GB} (x_i|\\boldsymbol{h}) = \\mathcal{N}\n",
    "\t(x_i | b_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}, \\sigma_i^2) .\n",
    "\\label{_auto86} \\tag{112}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbbe8c5",
   "metadata": {
    "editable": true
   },
   "source": [
    "The form of these conditional probabilities explains the name\n",
    "\"Gaussian\" and the form of the Gaussian-binary energy function. We see\n",
    "that the conditional probability of $x_i$ given $\\boldsymbol{h}$ is a normal\n",
    "distribution with mean $b_i + \\boldsymbol{w}_{i\\ast}^T \\boldsymbol{h}$ and variance\n",
    "$\\sigma_i^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b012951",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Neural Quantum States\n",
    "\n",
    "The wavefunction should be a probability amplitude depending on $\\boldsymbol{x}$. The RBM model is given by the joint distribution of $\\boldsymbol{x}$ and $\\boldsymbol{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401df5d",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto87\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tF_{rbm}(\\boldsymbol{x},\\mathbf{h}) = \\frac{1}{Z} e^{-\\frac{1}{T_0}E(\\boldsymbol{x},\\mathbf{h})}\n",
    "\\label{_auto87} \\tag{113}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52b4692",
   "metadata": {
    "editable": true
   },
   "source": [
    "To find the marginal distribution of $\\boldsymbol{x}$ we set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a5a7c",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto88\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tF_{rbm}(\\mathbf{x}) = \\sum_\\mathbf{h} F_{rbm}(\\mathbf{x}, \\mathbf{h}) \n",
    "\\label{_auto88} \\tag{114}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cbbf0a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto89\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\t\t\t= \\frac{1}{Z}\\sum_\\mathbf{h} e^{-E(\\mathbf{x}, \\mathbf{h})}\n",
    "\\label{_auto89} \\tag{115}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34769f87",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now this is what we use to represent the wave function, calling it a neural-network quantum state (NQS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6cd1d",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto90\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\Psi (\\mathbf{X}) = F_{rbm}(\\mathbf{x}) \n",
    "\\label{_auto90} \\tag{116}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9035d0a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto91\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z}\\sum_{\\boldsymbol{h}} e^{-E(\\mathbf{x}, \\mathbf{h})} \n",
    "\\label{_auto91} \\tag{117}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2d98e",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto92\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z} \\sum_{\\{h_j\\}} e^{-\\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma^2} + \\sum_j^N b_j h_j + \\sum_{i,j}^{M,N} \\frac{x_i w_{ij} h_j}{\\sigma^2}} \n",
    "\\label{_auto92} \\tag{118}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b650d8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto93\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{Z} e^{-\\sum_i^M \\frac{(x_i - a_i)^2}{2\\sigma^2}} \\prod_j^N (1 + e^{b_j + \\sum_i^M \\frac{x_i w_{ij}}{\\sigma^2}}) \n",
    "\\label{_auto93} \\tag{119}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f353cb5",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto94\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\label{_auto94} \\tag{120}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f936b13",
   "metadata": {
    "editable": true
   },
   "source": [
    "The above wavefunction is the most general one because it allows for\n",
    "complex valued wavefunctions. However it fundamentally changes the\n",
    "probabilistic foundation of the RBM, because what is usually a\n",
    "probability in the RBM framework is now a an amplitude. This means\n",
    "that a lot of the theoretical framework usually used to interpret the\n",
    "model, i.e. graphical models, conditional probabilities, and Markov\n",
    "random fields, breaks down. If we assume the wavefunction to be\n",
    "postive definite, however, we can use the RBM to represent the squared\n",
    "wavefunction, and thereby a probability. This also makes it possible\n",
    "to sample from the model using Gibbs sampling, because we can obtain\n",
    "the conditional probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8258ad6",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto95\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t|\\Psi (\\mathbf{X})|^2 = F_{rbm}(\\mathbf{X}) \n",
    "\\label{_auto95} \\tag{121}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae3de3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto96\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\Rightarrow \\Psi (\\mathbf{X}) = \\sqrt{F_{rbm}(\\mathbf{X})} \n",
    "\\label{_auto96} \\tag{122}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2f1b2",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto97\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{\\sqrt{Z}}\\sqrt{\\sum_{\\{h_j\\}} e^{-E(\\mathbf{X}, \\mathbf{h})}} \n",
    "\\label{_auto97} \\tag{123}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d79ef3",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto98\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{\\sqrt{Z}} \\sqrt{\\sum_{\\{h_j\\}} e^{-\\sum_i^M \\frac{(X_i - a_i)^2}{2\\sigma^2} + \\sum_j^N b_j h_j + \\sum_{i,j}^{M,N} \\frac{X_i w_{ij} h_j}{\\sigma^2}} }\n",
    "\\label{_auto98} \\tag{124}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f437de6",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto99\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{\\sqrt{Z}} e^{-\\sum_i^M \\frac{(X_i - a_i)^2}{4\\sigma^2}} \\sqrt{\\sum_{\\{h_j\\}} \\prod_j^N e^{b_j h_j + \\sum_i^M \\frac{X_i w_{ij} h_j}{\\sigma^2}}} \n",
    "\\label{_auto99} \\tag{125}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe81a7c",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto100\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{\\sqrt{Z}} e^{-\\sum_i^M \\frac{(X_i - a_i)^2}{4\\sigma^2}} \\sqrt{\\prod_j^N \\sum_{h_j}  e^{b_j h_j + \\sum_i^M \\frac{X_i w_{ij} h_j}{\\sigma^2}}} \n",
    "\\label{_auto100} \\tag{126}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42620017",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto101\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{\\sqrt{Z}} e^{-\\sum_i^M \\frac{(X_i - a_i)^2}{4\\sigma^2}} \\prod_j^N \\sqrt{e^0 + e^{b_j + \\sum_i^M \\frac{X_i w_{ij}}{\\sigma^2}}} \n",
    "\\label{_auto101} \\tag{127}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c74c19c",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto102\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{\\sqrt{Z}} e^{-\\sum_i^M \\frac{(X_i - a_i)^2}{4\\sigma^2}} \\prod_j^N \\sqrt{1 + e^{b_j + \\sum_i^M \\frac{X_i w_{ij}}{\\sigma^2}}} \n",
    "\\label{_auto102} \\tag{128}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46f6b9",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto103\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\label{_auto103} \\tag{129}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d5243",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Cost function\n",
    "\n",
    "This is where we deviate from what is common in machine\n",
    "learning. Rather than defining a cost function based on some dataset,\n",
    "our cost function is the energy of the quantum mechanical system. From\n",
    "the variational principle we know that minizing this energy should\n",
    "lead to the ground state wavefunction. As stated previously the local\n",
    "energy is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a019e1",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto104\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE_L = \\frac{1}{\\Psi} \\hat{\\mathbf{H}} \\Psi,\n",
    "\\label{_auto104} \\tag{130}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470cbcaa",
   "metadata": {
    "editable": true
   },
   "source": [
    "and the gradient is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2213a5a0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto105\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tG_i = \\frac{\\partial \\langle E_L \\rangle}{\\partial \\alpha_i}\n",
    "\t= 2(\\langle E_L \\frac{1}{\\Psi}\\frac{\\partial \\Psi}{\\partial \\alpha_i} \\rangle - \\langle E_L \\rangle \\langle \\frac{1}{\\Psi}\\frac{\\partial \\Psi}{\\partial \\alpha_i} \\rangle ),\n",
    "\\label{_auto105} \\tag{131}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b35529",
   "metadata": {
    "editable": true
   },
   "source": [
    "where $\\alpha_i = a_1,...,a_M,b_1,...,b_N,w_{11},...,w_{MN}$.\n",
    "\n",
    "We use that $\\frac{1}{\\Psi}\\frac{\\partial \\Psi}{\\partial \\alpha_i} \n",
    "\t= \\frac{\\partial \\ln{\\Psi}}{\\partial \\alpha_i}$,\n",
    "and find"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedd411",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto106\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\ln{\\Psi({\\mathbf{X}})} = -\\ln{Z} - \\sum_m^M \\frac{(X_m - a_m)^2}{2\\sigma^2}\n",
    "\t+ \\sum_n^N \\ln({1 + e^{b_n + \\sum_i^M \\frac{X_i w_{in}}{\\sigma^2}})}.\n",
    "\\label{_auto106} \\tag{132}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d01dc",
   "metadata": {
    "editable": true
   },
   "source": [
    "This gives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5c04ab",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto107\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\frac{\\partial }{\\partial a_m} \\ln\\Psi\n",
    "\t= \t\\frac{1}{\\sigma^2} (X_m - a_m) \n",
    "\\label{_auto107} \\tag{133}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731f310",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto108\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial }{\\partial b_n} \\ln\\Psi\n",
    "\t=\n",
    "\t\\frac{1}{e^{-b_n-\\frac{1}{\\sigma^2}\\sum_i^M X_i w_{in}} + 1} \n",
    "\\label{_auto108} \\tag{134}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaada84",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto109\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial }{\\partial w_{mn}} \\ln\\Psi\n",
    "\t= \\frac{X_m}{\\sigma^2(e^{-b_n-\\frac{1}{\\sigma^2}\\sum_i^M X_i w_{in}} + 1)}.\n",
    "\\label{_auto109} \\tag{135}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d458a",
   "metadata": {
    "editable": true
   },
   "source": [
    "If $\\Psi = \\sqrt{F_{rbm}}$ we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfde84",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto110\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\ln{\\Psi({\\mathbf{X}})} = -\\frac{1}{2}\\ln{Z} - \\sum_m^M \\frac{(X_m - a_m)^2}{4\\sigma^2}\n",
    "\t+ \\frac{1}{2}\\sum_n^N \\ln({1 + e^{b_n + \\sum_i^M \\frac{X_i w_{in}}{\\sigma^2}})},\n",
    "\\label{_auto110} \\tag{136}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc3354",
   "metadata": {
    "editable": true
   },
   "source": [
    "which results in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c4e1a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto111\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\frac{\\partial }{\\partial a_m} \\ln\\Psi\n",
    "\t= \t\\frac{1}{2\\sigma^2} (X_m - a_m) \n",
    "\\label{_auto111} \\tag{137}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbc0be",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto112\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial }{\\partial b_n} \\ln\\Psi\n",
    "\t=\n",
    "\t\\frac{1}{2(e^{-b_n-\\frac{1}{\\sigma^2}\\sum_i^M X_i w_{in}} + 1)} \n",
    "\\label{_auto112} \\tag{138}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e3dc9a",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto113\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial }{\\partial w_{mn}} \\ln\\Psi\n",
    "\t= \\frac{X_m}{2\\sigma^2(e^{-b_n-\\frac{1}{\\sigma^2}\\sum_i^M X_i w_{in}} + 1)}.\n",
    "\\label{_auto113} \\tag{139}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48c09a",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let us assume again that our Hamiltonian is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34801d05",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto114\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\hat{\\mathbf{H}} = \\sum_p^P (-\\frac{1}{2}\\nabla_p^2 + \\frac{1}{2}\\omega^2 r_p^2 ) + \\sum_{p<q} \\frac{1}{r_{pq}},\n",
    "\\label{_auto114} \\tag{140}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c16aa8b",
   "metadata": {
    "editable": true
   },
   "source": [
    "where the first summation term represents the standard harmonic\n",
    "oscillator part and the latter the repulsive interaction between two\n",
    "electrons. Natural units ($\\hbar=c=e=m_e=1$) are used, and $P$ is the\n",
    "number of particles. This gives us the following expression for the\n",
    "local energy ($D$ being the number of dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d9cc0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto115\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE_L = \\frac{1}{\\Psi} \\mathbf{H} \\Psi \n",
    "\\label{_auto115} \\tag{141}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c2dce0",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto116\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{\\Psi} (\\sum_p^P (-\\frac{1}{2}\\nabla_p^2 + \\frac{1}{2}\\omega^2 r_p^2 ) + \\sum_{p<q} \\frac{1}{r_{pq}}) \\Psi \n",
    "\\label{_auto116} \\tag{142}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93668ce",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto117\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= -\\frac{1}{2}\\frac{1}{\\Psi} \\sum_p^P \\nabla_p^2 \\Psi \n",
    "\t+ \\frac{1}{2}\\omega^2 \\sum_p^P  r_p^2  + \\sum_{p<q} \\frac{1}{r_{pq}} \n",
    "\\label{_auto117} \\tag{143}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f8aad",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto118\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= -\\frac{1}{2}\\frac{1}{\\Psi} \\sum_p^P \\sum_d^D \\frac{\\partial^2 \\Psi}{\\partial x_{pd}^2} + \\frac{1}{2}\\omega^2 \\sum_p^P  r_p^2  + \\sum_{p<q} \\frac{1}{r_{pq}} \n",
    "\\label{_auto118} \\tag{144}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fa16c8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto119\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t= \\frac{1}{2} \\sum_p^P \\sum_d^D (-(\\frac{\\partial}{\\partial x_{pd}} \\ln\\Psi)^2 -\\frac{\\partial^2}{\\partial x_{pd}^2} \\ln\\Psi + \\omega^2 x_{pd}^2)  + \\sum_{p<q} \\frac{1}{r_{pq}}. \n",
    "\\label{_auto119} \\tag{145}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e1ecc",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto120\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\label{_auto120} \\tag{146}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6789dbc7",
   "metadata": {
    "editable": true
   },
   "source": [
    "Letting each visible node in the Boltzmann machine \n",
    "represent one coordinate of one particle, we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae80b9c4",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto121\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\tE_L =\n",
    "\t\\frac{1}{2} \\sum_m^M (-(\\frac{\\partial}{\\partial v_m} \\ln\\Psi)^2 -\\frac{\\partial^2}{\\partial v_m^2} \\ln\\Psi + \\omega^2 v_m^2)  + \\sum_{p<q} \\frac{1}{r_{pq}},\n",
    "\\label{_auto121} \\tag{147}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9045254",
   "metadata": {
    "editable": true
   },
   "source": [
    "where we have that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200004fe",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto122\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\frac{\\partial}{\\partial x_m} \\ln\\Psi\n",
    "\t= - \\frac{1}{\\sigma^2}(x_m - a_m) + \\frac{1}{\\sigma^2} \\sum_n^N \\frac{w_{mn}}{e^{-b_n - \\frac{1}{\\sigma^2}\\sum_i^M x_i w_{in}} + 1} \n",
    "\\label{_auto122} \\tag{148}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b3cec",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto123\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial^2}{\\partial x_m^2} \\ln\\Psi\n",
    "\t= - \\frac{1}{\\sigma^2} + \\frac{1}{\\sigma^4}\\sum_n^N \\omega_{mn}^2 \\frac{e^{b_n + \\frac{1}{\\sigma^2}\\sum_i^M x_i w_{in}}}{(e^{b_n + \\frac{1}{\\sigma^2}\\sum_i^M x_i w_{in}} + 1)^2}.\n",
    "\\label{_auto123} \\tag{149}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740f8e0",
   "metadata": {
    "editable": true
   },
   "source": [
    "We now have all the expressions neeeded to calculate the gradient of\n",
    "the expected local energy with respect to the RBM parameters\n",
    "$\\frac{\\partial \\langle E_L \\rangle}{\\partial \\alpha_i}$.\n",
    "\n",
    "If we use $\\Psi = \\sqrt{F_{rbm}}$ we obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ec595",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto124\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\t\\frac{\\partial}{\\partial x_m} \\ln\\Psi\n",
    "\t= - \\frac{1}{2\\sigma^2}(x_m - a_m) + \\frac{1}{2\\sigma^2} \\sum_n^N\n",
    " \t\\frac{w_{mn}}{e^{-b_n-\\frac{1}{\\sigma^2}\\sum_i^M x_i w_{in}} + 1}\n",
    "\t\n",
    "\\label{_auto124} \\tag{150}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484908d8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto125\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\t\\frac{\\partial^2}{\\partial x_m^2} \\ln\\Psi\n",
    "\t= - \\frac{1}{2\\sigma^2} + \\frac{1}{2\\sigma^4}\\sum_n^N \\omega_{mn}^2 \\frac{e^{b_n + \\frac{1}{\\sigma^2}\\sum_i^M x_i w_{in}}}{(e^{b_n + \\frac{1}{\\sigma^2}\\sum_i^M x_i w_{in}} + 1)^2}.\n",
    "\\label{_auto125} \\tag{151}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99deb924",
   "metadata": {
    "editable": true
   },
   "source": [
    "The difference between this equation and the previous one is that we multiply by a factor $1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0631524",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Python version for the two non-interacting particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef184fdc",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 2-electron VMC code for 2dim quantum dot with importance sampling\n",
    "# Using gaussian rng for new positions and Metropolis- Hastings \n",
    "# Added restricted boltzmann machine method for dealing with the wavefunction\n",
    "# RBM code based heavily off of:\n",
    "# https://github.com/CompPhysics/ComputationalPhysics2/tree/gh-pages/doc/Programs/BoltzmannMachines/MLcpp/src/Pycode/ob\n",
    "from math import exp, sqrt\n",
    "from random import random, seed, normalvariate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "# Trial wave function for the 2-electron quantum dot in two dims\n",
    "def WaveFunction(r,a,b,w):\n",
    "    sigma=1.0\n",
    "    sig2 = sigma**2\n",
    "    Psi1 = 0.0\n",
    "    Psi2 = 1.0\n",
    "    Q = Qfac(r,b,w)\n",
    "    \n",
    "    for iq in range(NumberParticles):\n",
    "        for ix in range(Dimension):\n",
    "            Psi1 += (r[iq,ix]-a[iq,ix])**2\n",
    "            \n",
    "    for ih in range(NumberHidden):\n",
    "        Psi2 *= (1.0 + np.exp(Q[ih]))\n",
    "        \n",
    "    Psi1 = np.exp(-Psi1/(2*sig2))\n",
    "\n",
    "    return Psi1*Psi2\n",
    "\n",
    "# Local energy  for the 2-electron quantum dot in two dims, using analytical local energy\n",
    "def LocalEnergy(r,a,b,w):\n",
    "    sigma=1.0\n",
    "    sig2 = sigma**2\n",
    "    locenergy = 0.0\n",
    "    \n",
    "    Q = Qfac(r,b,w)\n",
    "\n",
    "    for iq in range(NumberParticles):\n",
    "        for ix in range(Dimension):\n",
    "            sum1 = 0.0\n",
    "            sum2 = 0.0\n",
    "            for ih in range(NumberHidden):\n",
    "                sum1 += w[iq,ix,ih]/(1+np.exp(-Q[ih]))\n",
    "                sum2 += w[iq,ix,ih]**2 * np.exp(Q[ih]) / (1.0 + np.exp(Q[ih]))**2\n",
    "    \n",
    "            dlnpsi1 = -(r[iq,ix] - a[iq,ix]) /sig2 + sum1/sig2\n",
    "            dlnpsi2 = -1/sig2 + sum2/sig2**2\n",
    "            locenergy += 0.5*(-dlnpsi1*dlnpsi1 - dlnpsi2 + r[iq,ix]**2)\n",
    "            \n",
    "    if(interaction==True):\n",
    "        for iq1 in range(NumberParticles):\n",
    "            for iq2 in range(iq1):\n",
    "                distance = 0.0\n",
    "                for ix in range(Dimension):\n",
    "                    distance += (r[iq1,ix] - r[iq2,ix])**2\n",
    "                    \n",
    "                locenergy += 1/sqrt(distance)\n",
    "                \n",
    "    return locenergy\n",
    "\n",
    "# Derivate of wave function ansatz as function of variational parameters\n",
    "def DerivativeWFansatz(r,a,b,w):\n",
    "    \n",
    "    sigma=1.0\n",
    "    sig2 = sigma**2\n",
    "    \n",
    "    Q = Qfac(r,b,w)\n",
    "    \n",
    "    WfDer = np.empty((3,),dtype=object)\n",
    "    WfDer = [np.copy(a),np.copy(b),np.copy(w)]\n",
    "    \n",
    "    WfDer[0] = (r-a)/sig2\n",
    "    WfDer[1] = 1 / (1 + np.exp(-Q))\n",
    "    \n",
    "    for ih in range(NumberHidden):\n",
    "        WfDer[2][:,:,ih] = w[:,:,ih] / (sig2*(1+np.exp(-Q[ih])))\n",
    "            \n",
    "    return  WfDer\n",
    "\n",
    "# Setting up the quantum force for the two-electron quantum dot, recall that it is a vector\n",
    "def QuantumForce(r,a,b,w):\n",
    "\n",
    "    sigma=1.0\n",
    "    sig2 = sigma**2\n",
    "    \n",
    "    qforce = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    sum1 = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    \n",
    "    Q = Qfac(r,b,w)\n",
    "    \n",
    "    for ih in range(NumberHidden):\n",
    "        sum1 += w[:,:,ih]/(1+np.exp(-Q[ih]))\n",
    "    \n",
    "    qforce = 2*(-(r-a)/sig2 + sum1/sig2)\n",
    "    \n",
    "    return qforce\n",
    "    \n",
    "def Qfac(r,b,w):\n",
    "    Q = np.zeros((NumberHidden), np.double)\n",
    "    temp = np.zeros((NumberHidden), np.double)\n",
    "    \n",
    "    for ih in range(NumberHidden):\n",
    "        temp[ih] = (r*w[:,:,ih]).sum()\n",
    "        \n",
    "    Q = b + temp\n",
    "    \n",
    "    return Q\n",
    "    \n",
    "# Computing the derivative of the energy and the energy \n",
    "def EnergyMinimization(a,b,w):\n",
    "\n",
    "    NumberMCcycles= 10000\n",
    "    # Parameters in the Fokker-Planck simulation of the quantum force\n",
    "    D = 0.5\n",
    "    TimeStep = 0.05\n",
    "    # positions\n",
    "    PositionOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    PositionNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    # Quantum force\n",
    "    QuantumForceOld = np.zeros((NumberParticles,Dimension), np.double)\n",
    "    QuantumForceNew = np.zeros((NumberParticles,Dimension), np.double)\n",
    "\n",
    "    # seed for rng generator \n",
    "    seed()\n",
    "    energy = 0.0\n",
    "    DeltaE = 0.0\n",
    "\n",
    "    EnergyDer = np.empty((3,),dtype=object)\n",
    "    DeltaPsi = np.empty((3,),dtype=object)\n",
    "    DerivativePsiE = np.empty((3,),dtype=object)\n",
    "    EnergyDer = [np.copy(a),np.copy(b),np.copy(w)]\n",
    "    DeltaPsi = [np.copy(a),np.copy(b),np.copy(w)]\n",
    "    DerivativePsiE = [np.copy(a),np.copy(b),np.copy(w)]\n",
    "    for i in range(3): EnergyDer[i].fill(0.0)\n",
    "    for i in range(3): DeltaPsi[i].fill(0.0)\n",
    "    for i in range(3): DerivativePsiE[i].fill(0.0)\n",
    "\n",
    "    \n",
    "    #Initial position\n",
    "    for i in range(NumberParticles):\n",
    "        for j in range(Dimension):\n",
    "            PositionOld[i,j] = normalvariate(0.0,1.0)*sqrt(TimeStep)\n",
    "    wfold = WaveFunction(PositionOld,a,b,w)\n",
    "    QuantumForceOld = QuantumForce(PositionOld,a,b,w)\n",
    "\n",
    "    #Loop over MC MCcycles\n",
    "    for MCcycle in range(NumberMCcycles):\n",
    "        #Trial position moving one particle at the time\n",
    "        for i in range(NumberParticles):\n",
    "            for j in range(Dimension):\n",
    "                PositionNew[i,j] = PositionOld[i,j]+normalvariate(0.0,1.0)*sqrt(TimeStep)+\\\n",
    "                                       QuantumForceOld[i,j]*TimeStep*D\n",
    "            wfnew = WaveFunction(PositionNew,a,b,w)\n",
    "            QuantumForceNew = QuantumForce(PositionNew,a,b,w)\n",
    "            \n",
    "            GreensFunction = 0.0\n",
    "            for j in range(Dimension):\n",
    "                GreensFunction += 0.5*(QuantumForceOld[i,j]+QuantumForceNew[i,j])*\\\n",
    "                                      (D*TimeStep*0.5*(QuantumForceOld[i,j]-QuantumForceNew[i,j])-\\\n",
    "                                      PositionNew[i,j]+PositionOld[i,j])\n",
    "      \n",
    "            GreensFunction = exp(GreensFunction)\n",
    "            ProbabilityRatio = GreensFunction*wfnew**2/wfold**2\n",
    "            #Metropolis-Hastings test to see whether we accept the move\n",
    "            if random() <= ProbabilityRatio:\n",
    "                for j in range(Dimension):\n",
    "                    PositionOld[i,j] = PositionNew[i,j]\n",
    "                    QuantumForceOld[i,j] = QuantumForceNew[i,j]\n",
    "                wfold = wfnew\n",
    "        #print(\"wf new:        \", wfnew)\n",
    "        #print(\"force on 1 new:\", QuantumForceNew[0,:])\n",
    "        #print(\"pos of 1 new:  \", PositionNew[0,:])\n",
    "        #print(\"force on 2 new:\", QuantumForceNew[1,:])\n",
    "        #print(\"pos of 2 new:  \", PositionNew[1,:])\n",
    "        DeltaE = LocalEnergy(PositionOld,a,b,w)\n",
    "        DerPsi = DerivativeWFansatz(PositionOld,a,b,w)\n",
    "        \n",
    "        DeltaPsi[0] += DerPsi[0]\n",
    "        DeltaPsi[1] += DerPsi[1]\n",
    "        DeltaPsi[2] += DerPsi[2]\n",
    "        \n",
    "        energy += DeltaE\n",
    "\n",
    "        DerivativePsiE[0] += DerPsi[0]*DeltaE\n",
    "        DerivativePsiE[1] += DerPsi[1]*DeltaE\n",
    "        DerivativePsiE[2] += DerPsi[2]*DeltaE\n",
    "            \n",
    "    # We calculate mean values\n",
    "    energy /= NumberMCcycles\n",
    "    DerivativePsiE[0] /= NumberMCcycles\n",
    "    DerivativePsiE[1] /= NumberMCcycles\n",
    "    DerivativePsiE[2] /= NumberMCcycles\n",
    "    DeltaPsi[0] /= NumberMCcycles\n",
    "    DeltaPsi[1] /= NumberMCcycles\n",
    "    DeltaPsi[2] /= NumberMCcycles\n",
    "    EnergyDer[0]  = 2*(DerivativePsiE[0]-DeltaPsi[0]*energy)\n",
    "    EnergyDer[1]  = 2*(DerivativePsiE[1]-DeltaPsi[1]*energy)\n",
    "    EnergyDer[2]  = 2*(DerivativePsiE[2]-DeltaPsi[2]*energy)\n",
    "    return energy, EnergyDer\n",
    "\n",
    "\n",
    "#Here starts the main program with variable declarations\n",
    "NumberParticles = 2\n",
    "Dimension = 2\n",
    "NumberHidden = 2\n",
    "\n",
    "interaction=False\n",
    "\n",
    "# guess for parameters\n",
    "a=np.random.normal(loc=0.0, scale=0.001, size=(NumberParticles,Dimension))\n",
    "b=np.random.normal(loc=0.0, scale=0.001, size=(NumberHidden))\n",
    "w=np.random.normal(loc=0.0, scale=0.001, size=(NumberParticles,Dimension,NumberHidden))\n",
    "# Set up iteration using stochastic gradient method\n",
    "Energy = 0\n",
    "EDerivative = np.empty((3,),dtype=object)\n",
    "EDerivative = [np.copy(a),np.copy(b),np.copy(w)]\n",
    "# Learning rate eta, max iterations, need to change to adaptive learning rate\n",
    "eta = 0.001\n",
    "MaxIterations = 50\n",
    "iter = 0\n",
    "np.seterr(invalid='raise')\n",
    "Energies = np.zeros(MaxIterations)\n",
    "EnergyDerivatives1 = np.zeros(MaxIterations)\n",
    "EnergyDerivatives2 = np.zeros(MaxIterations)\n",
    "\n",
    "while iter < MaxIterations:\n",
    "    Energy, EDerivative = EnergyMinimization(a,b,w)\n",
    "    agradient = EDerivative[0]\n",
    "    bgradient = EDerivative[1]\n",
    "    wgradient = EDerivative[2]\n",
    "    a -= eta*agradient\n",
    "    b -= eta*bgradient \n",
    "    w -= eta*wgradient \n",
    "    Energies[iter] = Energy\n",
    "    print(\"Energy:\",Energy)\n",
    "    #EnergyDerivatives1[iter] = EDerivative[0] \n",
    "    #EnergyDerivatives2[iter] = EDerivative[1]\n",
    "    #EnergyDerivatives3[iter] = EDerivative[2] \n",
    "\n",
    "\n",
    "    iter += 1\n",
    "\n",
    "#nice printout with Pandas\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "pd.set_option('max_columns', 6)\n",
    "data ={'Energy':Energies}#,'A Derivative':EnergyDerivatives1,'B Derivative':EnergyDerivatives2,'Weights Derivative':EnergyDerivatives3}\n",
    "\n",
    "frame = pd.DataFrame(data)\n",
    "print(frame)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
